@ARTICLE{Basavarajeshwari2018-ri,
  title     = "A Survey on weed Detection using Image Processing",
  author    = "{Basavarajeshwari} and Madhavanavar, S P",
  abstract  = "A Survey on weed Detection using Image Processing - written by
               Basavarajeshwari, Prof. S. P. Madhavanavar published on
               2018/04/24 download full article with reference data and
               citations",
  journal   = "International Journal of Engineering Research \& Technology",
  publisher = "IJERT-International Journal of Engineering Research \&
               Technology",
  volume    =  5,
  number    =  6,
  month     =  apr,
  year      =  2018,
  url       = "https://www.ijert.org/research/a-survey-on-weed-detection-using-image-processing-IJERTCONV5IS06011.pdf",
  issn      = "2278-0181"
}

@ARTICLE{Hamuda2016-dw,
  title     = "A survey of image processing techniques for plant extraction and
               segmentation in the field",
  author    = "Hamuda, E and Glavin, M and Jones, E",
  abstract  = "In this review, we present a comprehensive and critical survey
               on image-based plant segmentation techniques. In this context,
               ``segmentation'' refers to the process of classifying an image
               into plant and non-plant pixels. Good performance in this
               process is crucial for further analysis of the plant such as
               plant classification (i.e. identifying the plant as either crop
               or weed), and effective action based on this analysis, e.g.
               precision application of herbicides in smart agriculture
               applications. The survey briefly discusses pre-processing of
               images, before focusing on segmentation. The segmentation stage
               involves the segmentation of plant against the background
               (identifying plant from a background of soil and other
               residues). Three primary plant extraction algorithms, namely,
               (i) colour index-based segmentation, (ii) threshold-based
               segmentation, (iii) learning-based segmentation are discussed.
               Based on its prevalence in the literature, this review focuses
               in particular on colour index-based approaches. Therefore, a
               detailed discussion of the segmentation performance of colour
               index-based approaches is presented, based on studies from the
               literature conducted in the recent past, particularly from 2008
               to 2015. Finally, we identify the challenges and some
               opportunities for future developments in this space.
               \copyright{} 2016 Elsevier B.V.",
  journal   = "Comput. Electron. Agric.",
  publisher = "Elsevier B.V.",
  volume    =  125,
  pages     = "184--199",
  year      =  2016,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969174961&doi=10.1016%2fj.compag.2016.04.024&partnerID=40&md5=f2f1093d3d7096ea81b8da16a8110f4d",
  keywords  = "Colour index-based segmentation; Learning-based segmentation;
               Plant extraction; Plant pixels; Segmentation quality;
               Threshold-based segmentation; Color; Extraction; Image
               segmentation; Pixels; Surveys; Image processing technique;
               Learning-based segmentation; Plant classification; Plant
               extraction; Precision applications; Segmentation performance;
               Segmentation quality; Segmentation techniques; Image processing;
               algorithm; color; crop processing; field survey; herbicide;
               image processing; pixel; plant extract; precision; segmentation;
               threshold;585;segmentation",
  issn      = "0168-1699",
  doi       = "10.1016/j.compag.2016.04.024"
}

@MISC{Various_undated-cz,
  title        = "{YIQ} Wikipedia Article",
  booktitle    = "Wikipedia",
  author       = "{various}",
  url          = "https://en.wikipedia.org/wiki/YIQ",
  howpublished = "\url{https://en.wikipedia.org/wiki/YIQ}"
}

@BOOK{Muller2016-ui,
  title     = "Introduction to Machine Learning with Python",
  author    = "M{\"u}ller, Andreas C and Guido, Sarah",
  publisher = "O'Reilly Media",
  edition   =  1,
  month     =  nov,
  year      =  2016,
  isbn      = "9781449369415"
}

@ARTICLE{Otsu1979-io,
  title    = "A Threshold Selection Method from {Gray-Level} Histograms",
  author   = "Otsu, N",
  journal  = "IEEE Trans. Syst. Man Cybern.",
  volume   =  9,
  number   =  1,
  pages    = "62--66",
  month    =  jan,
  year     =  1979,
  url      = "http://dx.doi.org/10.1109/TSMC.1979.4310076",
  keywords = "Histograms;Marine vehicles;Radar tracking;Least squares
              approximation;Surveillance;Target tracking;Gaussian
              distribution;Displays;Q measurement;Sea measurements;585;image
              processing",
  issn     = "0018-9472, 2168-2909",
  doi      = "10.1109/TSMC.1979.4310076"
}

@ARTICLE{Monteiro2021-sk,
  title     = "A new alternative to determine weed control in agricultural
               systems based on artificial neural networks ({ANNs})",
  author    = "Monteiro, A L and Souza, Freitas and Lins, H A and Te{\'o}filo,
               T M D S and Barros J{\'u}nior, A P and Silva, D V and Mendon{\c
               c}a, V",
  abstract  = "Weed control is a necessary practice to avoid crop yield losses.
               Therefore, farmers should answer the following question: when to
               start weed control? Currently, there are no learning models to
               assist the producer to answer this question. Thus, the
               objectives were to: 1) evaluate the ability of artificial neural
               networks (ANNs) to estimate the beginning of weed control for
               different classes of acceptable yield losses; 2) validate a new
               alternative for modeling and predicting competition between
               weeds and crops. ANNs determined the ideal moment to control
               weeds based on non-destructive and destructive variables. The
               inputs C3/C4 ratio, coexistence period, density of weeds, and
               crop (categorical variable to differentiate sesame and melon)
               provided accuracy and F-score values above 0.95 during training,
               validation, and testing steps for ANN in non-destructive method.
               When using the destructive variables, C3/C4 ratio plus
               coexistence period, fresh matter of weeds, and crop provided
               accuracy and F-score values above 0.90 during training,
               validation, and testing steps. The combination of
               non-destructive and destructive inputs also generated an ANN
               with high accuracy and F-score, above 0.95, during training,
               validation, and testing steps. Machine learning can be used in
               crop-weed competition modeling. \copyright{} 2021 Elsevier B.V.",
  journal   = "Field Crops Res.",
  publisher = "Elsevier B.V.",
  volume    =  263,
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099622811&doi=10.1016%2fj.fcr.2021.108075&partnerID=40&md5=460bcd2ef6e727c29048a987c1715a96",
  keywords  = "Artificial intelligence; Decision making; Modeling; Weed
               interference; accuracy assessment; artificial neural network;
               crop yield; farming system; machine learning; nondestructive
               testing; weed control; yield response; Sesamum indicum",
  issn      = "0378-4290",
  doi       = "10.1016/j.fcr.2021.108075"
}

@ARTICLE{Flores2021-fk,
  title     = "Distinguishing seedling volunteer corn from soybean through
               greenhouse color, color-infrared, and fused images using machine
               and deep learning",
  author    = "Flores, P and Zhang, Z and Igathinathane, C and Jithin, M and
               Naik, D and Stenger, J and Ransom, J and Kiran, R",
  abstract  = "Volunteer corn (VC; Zea mays L.), as a weed in corn-soybean
               (Glycine max (L.) Merr.) rotation, has negatively impacted
               soybean production by reducing yield, lowering grain quality,
               and increasing the production costs. To assess the level of VC
               infestation to guide chemical applications, farmers usually rely
               on field visual observation. Since the field visual inspection
               is labor-intensive, time-consuming, and subjective, an automatic
               solution to differentiate VC from soybeans is required. As a
               first step toward that goal, this study aimed to develop a
               solution to differentiate those crops at seedling stage under
               greenhouse conditions. Color RGB and color-infrared (CIR) images
               of VC and soybean seedlings were collected in a greenhouse. A
               fused image dataset was created by blending the RGB and CIR
               image datasets. The top 20 extracted relevant features and the
               image datasets were fed into four different machine learning
               (ML) classifiers and four deep learning (DL) algorithms,
               respectively. All ML classifiers resulted in the highest
               accuracies on the fused images, with support vector machine
               (SVM) outperforming the other classifiers. Similarly, all the DL
               algorithms had a superior performance on the fused images, with
               GoogLeNet as the best algorithm. Overall, GoogLeNet was selected
               for its high accuracy 99.9\%, reasonable computation time (0.02
               s per plant), and simple and direct application. The application
               of fused images along with GoogLeNet can be used as a novel tool
               to automatically distinguish VC from soybean. Future research
               should focus on field testing this methodology in a real-time
               mode. \copyright{} 2021 Elsevier B.V.",
  journal   = "Ind. Crops Prod.",
  publisher = "Elsevier B.V.",
  volume    =  161,
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099201868&doi=10.1016%2fj.indcrop.2020.113223&partnerID=40&md5=e0377ffac0a6fd0fb90ecf844494501d",
  keywords  = "Deep learning; Image fusion; Image registration; Image
               segmentation; Machine learning; Soybean; Volunteer corn; Amino
               acids; Classification (of information); Color; Greenhouses;
               Learning systems; Nitrogen fixation; Support vector machines;
               Chemical applications; Greenhouse conditions; Relevant features;
               Soybean (Glycine max (L.) Merr.); Soybean production; Soybean
               seedlings; Visual inspection; Visual observations; Deep
               learning; algorithm; automation; food quality; greenhouse
               ecosystem; image analysis; machine learning; seeding; soybean;
               support vector machine; weed; Glycine max; Zea mays",
  issn      = "0926-6690",
  doi       = "10.1016/j.indcrop.2020.113223"
}

@ARTICLE{Sohail2021-cj,
  title     = "A review on machine vision and image processing techniques for
               weed detection in agricultural crops",
  author    = "Sohail, R and Nawaz, Q and Hamid, I and Gilani, S M M and
               Mumtaz, I and Mateen, A and Nawaz, J",
  abstract  = "The advancement in the field of precision agriculture has opened
               doors for site-specific weed management. There is a growing need
               to control the amount of herbicide sprayed on weeds to reduce
               economic and environmental losses. In the field of precision
               agriculture, incorporation of machine learning techniques has
               enabled the farmers to automate the process of controlling weed
               using an adequate number of herbicides for different species
               in-situ. This study aims to explore various parameters of
               Computer Vision and Machine Learning algorithms and methods used
               by researchers to develop Artificial Intelligence models to
               remove weeds from agricultural fields. More than twenty
               state-of-the-art algorithms have been studied in this paper. We
               categorized these algorithms into five categories based on
               different features i.e. visual, shape, spatial, and spectral. At
               the end of this study, a comprehensive table is presented
               containing details of algorithms in terms of limitations and
               accuracy. \copyright{} 2021, University of Agriculture. All
               rights reserved.",
  journal   = "Pakistan Journal of Agricultural Sciences",
  publisher = "University of Agriculture",
  volume    =  58,
  number    =  1,
  pages     = "187--204",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099593950&doi=10.21162%2fPAKJAS%2f21.305&partnerID=40&md5=e2a7aba39d94f23a2e7f35556813a4b1",
  keywords  = "Image processing; Machine vision; Robotic weed control; Weed
               detection",
  issn      = "0552-9034",
  doi       = "10.21162/PAKJAS/21.305"
}

@PROCEEDINGS{Beeharry2020-nn,
  title      = "Performance of {ANN} and {AlexNet} for weed detection using
                {UAV-based} images",
  author     = "Beeharry, Y and Bassoo, V",
  editor     = "{Pudaruth S.} and {Mungur A.} and {Ah King R.T.F.} and {Fowdur
                T.P.} and {Bojkovic Z.} and {Milovanovic D.} and {Hurbungs V.}",
  abstract   = "Unmanned Aerial Vehicles (UAVs) have become an integral part of
                several real-world applications. Their combination with other
                evolving paradigms such as image recognition using machine
                learning or deep learning algorithms has contributed to the
                suitability for use in smart agriculture and weed detection
                applications. In this paper, the performances of the Artificial
                Neural Network (ANN) and AlexNet algorithms for weed detection
                using UAV-based images have been studied. An image dataset
                containing 15336 segments with the following breakdown: 3249 of
                soil, 7376 of soybean, 3520 grass and 1191 of broadleaf weeds
                has been used. The partitioning for train and test sets has
                been done in the ratio of 70:30. Simulation results show that
                the conventional ANN algorithm provide an accuracy of 48.09\%
                while the AlexNet algorithms gives an accuracy 99.8\% on the
                test dataset. \copyright{} 2020 IEEE.",
  publisher  = "Institute of Electrical and Electronics Engineers Inc.",
  year       =  2020,
  url        = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099571177&doi=10.1109%2fELECOM49001.2020.9296994&partnerID=40&md5=d5ab3b49d9fd7a33fd2f26e383c2ca09",
  keywords   = "AlexNet; Artificial Neural Network; weed detection;
                Agricultural robots; Aircraft detection; Antennas; Deep
                learning; Image recognition; Neural networks; Statistical
                tests; Unmanned aerial vehicles (UAV); Weed control; ANN
                algorithm; Broadleaf weeds; Image datasets; Integral part;
                Real-world; Smart agricultures; Test sets; Weed detection;
                Learning algorithms",
  conference = "3rd International Conference on Emerging Trends in Electrical,
                Electronic and Communications Engineering, ELECOM 2020",
  isbn       = "9781728157078",
  doi        = "10.1109/ELECOM49001.2020.9296994"
}

@PROCEEDINGS{Perez-Ortiz2017-pg,
  title      = "Machine learning paradigms for weed mapping via unmanned aerial
                vehicles",
  author     = "Perez-Ortiz, M and Gutierrez, P A and Pena, J M and
                Torres-Sanchez, J and Lopez-Granados, F and Hervas-Martinez, C",
  abstract   = "This paper presents a novel strategy for weed monitoring, using
                images taken with unmanned aerial vehicles (UAVs) and concepts
                of image analysis and machine learning. Weed control in
                precision agriculture designs site-specific treatments based on
                the coverage of weeds, where the key is to provide precise weed
                maps timely. Most traditional remote platforms, e.g. piloted
                planes or satellites, are, however, not suitable for early weed
                monitoring, given their low temporal and spatial resolutions,
                as opposed to he ultra-high spatial resolution of UAVs. The
                system here proposed makes use of UAV-imagery and is based on:
                1) Divide the image, 2) compute and binarise the vegetation
                indexes, 3) detect crop rows, 4) optimise the parameters and 4)
                learn a classification model. Since crops are usually organised
                in rows, the use of a crop row detection algorithm helps to
                separate properly weed and crop pixels, which is a common
                handicap given the spectral similitude of both. Several
                artificial intelligence paradigms are compared in this paper to
                identify the most suitable strategy for this topic (i.e.
                unsupervised, supervised and semi-supervised approaches). Our
                experiments also study the effect of different parameteres: the
                flight altitude, the sensor and the use of previously trained
                models at a different height. Our results show that 1) very
                promising performance can be obtained, even when using very few
                labelled data and 2) the classification model can be learnt in
                a subplot of the experimental field at low altitude and then
                applied to the whole field at a higher height, which simplifies
                the whole process. These results motivate the use of this
                strategy to design weed monitoring strategies for early
                post-emergence weed control. \copyright{} 2016 IEEE.",
  publisher  = "Institute of Electrical and Electronics Engineers Inc.",
  year       =  2017,
  url        = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015991782&doi=10.1109%2fSSCI.2016.7849987&partnerID=40&md5=bc4aab58904adb41c5f577a715b76d0e",
  keywords   = "Artificial intelligence; Crops; Learning systems; Unmanned
                aerial vehicles (UAV); Classification models; Crop row
                detection; Different heights; Flight altitudes; Monitoring
                strategy; Novel strategies; Precision Agriculture; Temporal and
                spatial; Weed control",
  conference = "2016 IEEE Symposium Series on Computational Intelligence, SSCI
                2016",
  isbn       = "9781509042401",
  doi        = "10.1109/SSCI.2016.7849987"
}

@PROCEEDINGS{Espinoza2020-es,
  title      = "Weed identification and removal using machine learning
                techniques and unmanned ground vehicles",
  author     = "Espinoza, M A M and Le, C Z and Raheja, A and Bhandari, S",
  editor     = "{Thomasson J.A.} and {Torres-Rua A.F.}",
  abstract   = "This paper presents the use of unmanned ground vehicle (UGV)
                and machine learning techniques for the identification removal
                of weeds in lettuce crop. In recent years, breakthroughs in
                deep learning, computer vision, and miniaturization of
                electronic devices have paved the way for use of unmanned
                systems and machine learning techniques for applications that
                are dull, dirty, and dangerous for humans including
                agricultural applications. Unmanned systems and machine
                learning techniques have potential to transform and modernize
                how the crops are grown and cared. One of the problems every
                farmer encounters is invasive weeds that can kill or hinder the
                growth of crops by stealing water, nutrients, and sunlight from
                the plants. Herbicides are used to kill and stop the growth of
                weeds. However, use of herbicides increases the cost of
                production, is labor intensive, and exposes human to dangerous
                chemicals. Manually removing the weeds is also very labor
                intensive. Using machine learning techniques and UGVs for the
                identification and removal of weeds will reduce the cost of
                production, human exposure to dangerous chemicals, and
                dependence on human labor. Models were trained using YOLO,
                Faster R-CNN, and SSD Mobile object detection techniques. For
                the training of machine learning models, images of the weeds in
                an experimental lettuce plot was collected throughout the
                growing season. Validation of the developed models was
                performed using different data sets than the training data sets
                in the same plot as well as a different plot. The identified
                weeds were then removed using the UGV through teleoperation.
                \copyright{} 2020 SPIE.",
  publisher  = "SPIE",
  volume     =  11414,
  year       =  2020,
  url        = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089075752&doi=10.1117%2f12.2557625&partnerID=40&md5=2fdd9ed15e473720280303442772ae45",
  keywords   = "CNN,SSD; Machine Learning; Robotics; UGV; Weed Removal; Weeds;
                YOLO; Agricultural robots; Crops; Deep learning; Ground
                vehicles; Herbicides; Intelligent vehicle highway systems;
                Object detection; Weed control; Cost of productions; Electronic
                device; Identification and removal; Machine learning models;
                Machine learning techniques; Training data sets; Unmanned
                ground vehicles; Weed identification; Learning systems",
  conference = "Autonomous Air and Ground Sensing Systems for Agricultural
                Optimization and Phenotyping V 2020",
  isbn       = "9781510636057",
  doi        = "10.1117/12.2557625"
}

@MISC{noauthor_undated-xq,
  title        = "Paperpile",
  url          = "https://paperpile.com/app/p/da8a0891-8580-0eb5-9d66-3438a62cdebe",
  howpublished = "\url{https://paperpile.com/app/p/da8a0891-8580-0eb5-9d66-3438a62cdebe}",
  note         = "Accessed: 2021-2-14"
}

@PROCEEDINGS{Perez-Ortiz2017-wj,
  title      = "Machine learning paradigms for weed mapping via unmanned aerial
                vehicles",
  author     = "Perez-Ortiz, M and Gutierrez, P A and Pena, J M and
                Torres-Sanchez, J and Lopez-Granados, F and Hervas-Martinez, C",
  abstract   = "This paper presents a novel strategy for weed monitoring, using
                images taken with unmanned aerial vehicles (UAVs) and concepts
                of image analysis and machine learning. Weed control in
                precision agriculture designs site-specific treatments based on
                the coverage of weeds, where the key is to provide precise weed
                maps timely. Most traditional remote platforms, e.g. piloted
                planes or satellites, are, however, not suitable for early weed
                monitoring, given their low temporal and spatial resolutions,
                as opposed to he ultra-high spatial resolution of UAVs. The
                system here proposed makes use of UAV-imagery and is based on:
                1) Divide the image, 2) compute and binarise the vegetation
                indexes, 3) detect crop rows, 4) optimise the parameters and 4)
                learn a classification model. Since crops are usually organised
                in rows, the use of a crop row detection algorithm helps to
                separate properly weed and crop pixels, which is a common
                handicap given the spectral similitude of both. Several
                artificial intelligence paradigms are compared in this paper to
                identify the most suitable strategy for this topic (i.e.
                unsupervised, supervised and semi-supervised approaches). Our
                experiments also study the effect of different parameteres: the
                flight altitude, the sensor and the use of previously trained
                models at a different height. Our results show that 1) very
                promising performance can be obtained, even when using very few
                labelled data and 2) the classification model can be learnt in
                a subplot of the experimental field at low altitude and then
                applied to the whole field at a higher height, which simplifies
                the whole process. These results motivate the use of this
                strategy to design weed monitoring strategies for early
                post-emergence weed control. \copyright{} 2016 IEEE.",
  publisher  = "Institute of Electrical and Electronics Engineers Inc.",
  year       =  2017,
  url        = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015991782&doi=10.1109%2fSSCI.2016.7849987&partnerID=40&md5=bc4aab58904adb41c5f577a715b76d0e",
  keywords   = "Artificial intelligence; Crops; Learning systems; Unmanned
                aerial vehicles (UAV); Classification models; Crop row
                detection; Different heights; Flight altitudes; Monitoring
                strategy; Novel strategies; Precision Agriculture; Temporal and
                spatial; Weed control",
  conference = "2016 IEEE Symposium Series on Computational Intelligence, SSCI
                2016",
  isbn       = "9781509042401",
  doi        = "10.1109/SSCI.2016.7849987"
}

@ARTICLE{Pantazi2016-yx,
  title    = "Active learning system for weed species recognition based on
              hyperspectral sensing",
  author   = "Pantazi, Xanthoula-Eirini and Moshou, Dimitrios and Bravo, Cedric",
  abstract = "Weeds have a devastating impact in crop production and yield in
              general. Current practice uses uniform application of herbicides
              leading to high costs and degradation of the environment and the
              field productivity. Site-specific treatments can be regarded as
              solutions either for reducing inputs or enable alternative
              non-chemical treatments. However, site-specific treatment needs
              accurate targeting through sensing. A new machine learning method
              is proposed, which discriminates between crop and weed species
              relying on their spectral reflectance differences. Spectral
              features were extracted from a hyperspectral imaging system that
              was mounted on a robotic platform. The proposed machine learning
              method suggests active learning by combining novelty detection
              and incremental class augmentation. Novelty detection was based
              on one-class classifiers constructed by neural networks. Best
              results for the active learning were obtained for the one-class
              MOG (mixture of Gaussians) and one-class SOM (self-organising
              map) classifiers when compared with one-class support vector
              machines and the auto-encoder network. The SOM and MOG
              performance in crop recognition was found to be 100\% and 100\%
              respectively. The recognition performance for different weed
              species varied between 31\% and 98\% (MOG) and 53\%--94\% (SOM).",
  journal  = "Biosystems Eng.",
  volume   =  146,
  pages    = "193--202",
  month    =  jun,
  year     =  2016,
  url      = "https://www.sciencedirect.com/science/article/pii/S1537511016000143",
  keywords = "Spectrograph; Self-organising map; Mixture of Gaussians;
              One-class classifier; Auto-encoder network; Support vector
              machines",
  issn     = "1537-5110",
  doi      = "10.1016/j.biosystemseng.2016.01.014"
}

@MISC{noauthor_undated-te,
  title = "fulltext.pdf"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hunt2013-ih,
  title    = "A visible band index for remote sensing leaf chlorophyll content
              at the canopy scale",
  author   = "Hunt, E Raymond and Doraiswamy, Paul C and McMurtrey, James E and
              Daughtry, Craig S T and Perry, Eileen M and Akhmedov, Bakhyt",
  abstract = "Leaf chlorophyll content is an important variable for
              agricultural remote sensing because of its close relationship to
              leaf nitrogen content. The triangular greenness index (TGI) was
              developed based on the area of a triangle surrounding the
              spectral features of chlorophyll with points at (670nm, R670),
              (550nm, R550), and (480nm, R480), where R$\lambda$ is the
              spectral reflectance at wavelengths of 670, 550 and 480,
              respectively. The equation is
              TGI=−0.5[(670−480)(R670−R550)−(670−550)(R670−R480)]. In 1999,
              investigators funded by NASA's Earth Observations
              Commercialization and Applications Program collaborated on a
              nitrogen fertilization experiment with irrigated maize in
              Nebraska. Airborne Visible/Infrared Imaging Spectrometer (AVIRIS)
              data and Landsat 5 Thematic Mapper (TM) data were acquired along
              with leaf chlorophyll meter and other data on three dates in July
              during late vegetative growth and early reproductive growth. TGI
              was consistently correlated with plot-averaged chlorophyll-meter
              values at the spectral resolutions of AVIRIS, Landsat TM, and
              digital cameras. Simulations using the Scattering by Arbitrarily
              Inclined Leaves (SAIL) canopy model indicate an interaction among
              TGI, leaf area index (LAI) and soil type at low crop LAI, whereas
              at high LAI and canopy closure, TGI was only affected by leaf
              chlorophyll content. Therefore, TGI may be the best spectral
              index to detect crop nitrogen requirements with low-cost digital
              cameras mounted on low-altitude airborne platforms.",
  journal  = "Int. J. Appl. Earth Obs. Geoinf.",
  volume   =  21,
  pages    = "103--112",
  month    =  apr,
  year     =  2013,
  url      = "https://www.sciencedirect.com/science/article/pii/S0303243412001791",
  keywords = "Spectral indices; Triangular greenness index (TGI); Airborne
              Visible/Infrared Imaging Spectrometer (AVIRIS); PROSPECT; SAIL;
              Landsat Thematic Mapper (TM); Nitrogen fertilization;585",
  issn     = "0303-2434",
  doi      = "10.1016/j.jag.2012.07.020"
}

@ARTICLE{Osorio2020-bt,
  title     = "A Deep Learning Approach for Weed Detection in Lettuce Crops
               Using Multispectral Images",
  author    = "Osorio, Kavir and Puerto, Andr{\'e}s and Pedraza, Cesar and
               Jamaica, David and Rodr{\'\i}guez, Leonardo",
  abstract  = "Weed management is one of the most important aspects of crop
               productivity; knowing the amount and the locations of weeds has
               been a problem that experts have faced for several decades. This
               paper presents three methods for weed estimation based on deep
               learning image processing in lettuce crops, and we compared them
               to visual estimations by experts. One method is based on support
               vector machines (SVM) using histograms of oriented gradients
               (HOG) as feature descriptor. The second method was based in
               YOLOV3 (you only look once V3), taking advantage of its robust
               architecture for object detection, and the third one was based
               on Mask R-CNN (region based convolutional neural network) in
               order to get an instance segmentation for each individual. These
               methods were complemented with a NDVI index (normalized
               difference vegetation index) as a background subtractor for
               removing non photosynthetic objects. According to chosen
               metrics, the machine and deep learning methods had F1-scores of
               88\%, 94\%, and 94\% respectively, regarding to crop detection.
               Subsequently, detected crops were turned into a binary mask and
               mixed with the NDVI background subtractor in order to detect
               weed in an indirect way. Once the weed image was obtained, the
               coverage percentage of weed was calculated by classical image
               processing methods. Finally, these performances were compared
               with the estimations of a set from weed experts through a
               Bland--Altman plot, intraclass correlation coefficients (ICCs)
               and Dunn's test to obtain statistical measurements between every
               estimation (machine-human); we found that these methods improve
               accuracy on weed coverage estimation and minimize subjectivity
               in human-estimated data.",
  journal   = "AgriEngineering",
  publisher = "Multidisciplinary Digital Publishing Institute",
  volume    =  2,
  number    =  3,
  pages     = "471--488",
  month     =  aug,
  year      =  2020,
  url       = "https://www.mdpi.com/2624-7402/2/3/32",
  language  = "en",
  doi       = "10.3390/agriengineering2030032"
}

@ARTICLE{Hamuda2017-nf,
  title    = "Automatic crop detection under field conditions using the {HSV}
              colour space and morphological operations",
  author   = "Hamuda, Esmael and Mc Ginley, Brian and Glavin, Martin and Jones,
              Edward",
  abstract = "Developing an automatic weeding system requires robust detection
              of the exact location of the crop to be protected from damage.
              Computer vision techniques can be an effective means of
              determining plant location. In this paper, a novel algorithm
              based on colour features and morphological erosion and dilation
              is proposed. This process segments cauliflower crop regions in
              the image from weeds and soil under natural illumination (cloudy,
              partially cloudy, and sunny). The proposed algorithm uses the HSV
              colour space for discriminating crop, weeds and soil. The region
              of interest (ROI) is defined by filtering each of the HSV
              channels between certain values (minimum and maximum threshold
              values). The region is then further refined by using a
              morphological erosion and dilation process. The moment method is
              applied to determine the position and mass distribution of
              objects in video sequences, as well as to track crops. The
              performance of the algorithm was assessed by comparing the
              obtained results with those of ground truth methods (manual
              annotation). A sensitivity of 98.91\% and precision of 99.04\%
              was achieved.",
  journal  = "Comput. Electron. Agric.",
  volume   =  133,
  pages    = "97--107",
  month    =  feb,
  year     =  2017,
  url      = "https://www.sciencedirect.com/science/article/pii/S0168169916303714",
  keywords = "Morphological; Natural illumination; HSV colour space; Crop
              detection;image processing",
  issn     = "0168-1699",
  doi      = "10.1016/j.compag.2016.11.021"
}

@ARTICLE{Siemens2020-ds,
  title    = "High Speed Centimeter Scale Resolution Sprayers for Precision
              Weed Control in Vegetable Crops",
  author   = "Siemens, M C",
  journal  = "AZ Veg IPM Update",
  volume   =  11,
  number   =  8,
  month    =  apr,
  year     =  2020,
  keywords = "weeding systems"
}

@ARTICLE{Chandel2021-jv,
  title     = "An integrated inter- and intra-row weeding system for row crops",
  author    = "Chandel, N S and Chandel, A K and Roul, A K and Solanki, K R and
               Mehta, C R",
  abstract  = "Weeding is critical to eliminate non-native plants that compete
               with main crops and adversely affect their production quality
               and quantity. Numerous prototypes exist for inter-row weeding
               but very limited for intra-row weed eradication. This study
               developed a tractor drawn integrated inter- and intra-row
               weeding (IIIRW) system for field crops. Active rotary tines were
               used for intra-row weeding and passive tines for inter-row
               weeding. Optimum operational configurations were obtained with
               rigorous repeated soil bin experiments, and developed system was
               evaluated for three growing seasons (2017--19) in field grown
               maize (Zea mays L.) and pigeon pea (Cajanus cajan (L.) Millsp.)
               crops. Optimum ratios of intra-row tine rotary speed to forward
               speed (u/v) were in the ranges of 0.8--1.3 that lead to weed
               mortality of 88.4 \% (Buried: 8.5 \%, Uprooted: 79.9 \%),
               negligible intact weeds, and plant damage (Pd) within 6 \%. Sole
               inter-row weeding operation resulted up to 78.1 \% of weed
               mortality (Buried: 18.1 \%, Uprooted: 60.0 \%) and negligible
               Pd. Overall weed mortality with the IIIRW system was 92.8 \%
               (Buried: 9.5 \%, Uprooted: 83.3 \%) in maize and 84.1 \%
               (Buried: 7.6 \%, Uprooted: 76.5 \%) in pigeon pea crops. Results
               suggest suitability of the IIIRW system for a range of similar
               crops for field capacity in ranges of 0.22--0.26 ha/h at
               recommended operating speeds within 0.50--0.56 m/s. The IIIRW
               system requires a single prime mover and could be potentially
               economical and efficient technology for field weeding
               operations. \copyright{} 2021 Elsevier Ltd",
  journal   = "Crop Prot.",
  publisher = "Elsevier Ltd",
  volume    =  145,
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103758089&doi=10.1016%2fj.cropro.2021.105642&partnerID=40&md5=4cae681b782ad8ba769c43fe1585bfaa",
  keywords  = "Crop damage; Economical operation; Inter and intra-row weeds;
               Mechanical weeding; Weed mortality; crop plant; detection
               method; instrumentation; legume; mortality; weed; Cajanus cajan;
               Zea mays;weeding systems",
  issn      = "0261-2194",
  doi       = "10.1016/j.cropro.2021.105642"
}

@ARTICLE{Chen2019-wg,
  title     = "Vegetable crop row extraction method based on accumulation
               threshold of Hough Transformation",
  author    = "Chen, Z and Li, W and Zhang, W and Li, Y and Li, M and Li, H",
  abstract  = "Agricultural machinery field automatic navigation technology is
               widely used in farming, sowing, weeding, fertilizing, spraying,
               harvesting and other agricultural production process. This
               technology can improve the efficiency of the mechanical
               efficiency and reduce the missing areas of operation, labor
               intensity and the complexity of the operation. Because machine
               vision can be used to obtain and perceive the relative position
               information of crop rows, current crop growth status and field
               environment in real time, it is widely applied in online crop
               detection and identification. In this paper, a method based on
               automatic accumulation threshold of Hough Transformation was
               presented in order to improve the adaptability of the crop row
               recognition algorithm for different kinds and growth periods of
               vegetables with machine vision. The method was composed of image
               preprocessing, feature point detection, optimal accumulation
               threshold acquisition and crop row extraction. Firstly, to
               reduce the adverse effects of light change and restrain the
               background noise, a* component of Lab color model was selected
               for transforming RGB image to grayscale image. Optimal adaptive
               threshold and morphology close-open operation was applied for
               minimizing error segmentation probability and eliminating
               irrelevant detail. Secondly, the feature points of crop rows
               were extracted by sectionalized vertical projection method. The
               original image was divided into several horizontal segments and
               target pixel ratio and vertical projection width were used as
               double threshold in the luminance projection view of each
               segment to determine the location of feature points and
               distinguish noise. Thirdly, the Hough transformation method with
               different accumulative thresholds was performed to fit straight
               lines for all feature points in the image coordinate system,
               then they were all converted to Hough space accumulator as
               points. These points were clustered into the same number as crop
               rows by K-means clustering method. According to the camera
               projection, the optimal accumulator threshold was acquired by
               the position relation of clustering centroid and minimum
               inter-class variance. Finally, the fitting line parameters of
               real crop rows were the clustering centroid parameters of the
               accumulation space under the optimal accumulation threshold,
               then the parameters were converted into the crop lines in the
               image coordinate system. The crop row identification tests of
               lettuce and cabbage were carried out in the greenhouse and filed
               according to the conditions of crops in different growing
               periods, different weed densities, and different light
               conditions in the field. The greenhouse experiment showed that
               the algorithm can effectively identify crop rows with an average
               recognition accuracy of 97.1\% for two crops of different growth
               periods under different weed densities. The outdoor experiment
               showed that the algorithm can also identify crop rows with
               94.6\% recognition accuracy under different row numbers and
               light conditions. Time consumption for optimal accumulator
               threshold algorithm and crop rows extraction algorithm were no
               more than 1.5 and 0.2 s, and the average accuracy rate of crop
               row detection was achieved 95.8\%. In view of the practical
               application of field operations, as the environmental parameters
               basically do not change significantly in a short time, the
               optimal accumulation threshold was only needed to be obtained
               once, which can ensure the time consumption of algorithm was
               about 0.2 s. \copyright{} 2019, Editorial Department of the
               Transactions of the Chinese Society of Agricultural Engineering.
               All right reserved.",
  journal   = "Nongye Gongcheng Xuebao/Transactions of the Chinese Society of
               Agricultural Engineering",
  publisher = "Chinese Society of Agricultural Engineering",
  volume    =  35,
  number    =  22,
  pages     = "314--322",
  year      =  2019,
  url       = "https://www.scopus.com/record/display.uri?eid=2-s2.0-85079348543&origin=resultslist&sort=plf-f&src=s&sid=7ff83019f5390ac8a8ce07580d57738d&sot=b&sdt=b&sl=35&s=TITLE-ABS-KEY%28weed+detection+ratio%29&relpos=17&citeCnt=2&searchTerm=",
  keywords  = "Algorithms; Crop row recognition; Hough transform; K-means
               clustering; Machine vision; Navigation; Precision agriculture;
               Algorithms; Computer vision; Crops; Efficiency; Extraction; Fits
               and tolerances; Greenhouses; Hough transforms; Image
               segmentation; Navigation; Precision agriculture; Vegetables;
               Accumulation threshold; Agricultural productions; Detection and
               identifications; Environmental parameter; Feature point
               detection; Greenhouse experiments; K-means clustering method;
               Mechanical efficiency; K-means clustering;image processing",
  issn      = "1002-6819"
}

@ARTICLE{Lin2017-xq,
  title     = "Detection of corn and weed species by the combination of
               spectral, shape and textural features",
  author    = "Lin, F and Zhang, D and Huang, Y and Wang, X and Chen, X",
  abstract  = "Accurate detection of weeds in farmland can help reduce
               pesticide use and protect the agricultural environment. To
               develop intelligent equipment for weed detection, this study
               used an imaging spectrometer system, which supports micro-scale
               plant feature analysis by acquiring high-resolution hyper
               spectral images of corn and a number of weed species in the
               laboratory. For the analysis, the object-oriented classification
               system with segmentation and decision tree algorithms was
               utilized on the hyper spectral images to extract shape and
               texture features of eight species of plant leaves, and then, the
               spectral identification characteristics of different species
               were determined through sensitive waveband selection and using
               vegetation indices calculated from the sensitive band data of
               the images. On the basis of the comparison and analysis of the
               combined characteristics of spectra, shape, and texture, it was
               determined that the spectral characteristics of the ratio
               vegetation index of R677/R710 and the normalized difference
               vegetation index, shape features of shape index, area, and
               length, as well as the texture feature of the entropy index
               could be used to build a discrimination model for corn and weed
               species. Results of the model evaluation showed that the Global
               Accuracy and the Kappa coefficient of the model were both over
               95\%. In addition, spectral and shape features can be regarded
               as the preferred characteristics to develop a device of weed
               identification from the view of accessibility to crop/weeds
               discriminant features, according to different roles of various
               features in classifying plants. Therefore, the results of this
               study provide valuable information for the portable device
               development of intelligent weed detection. \copyright{} 2017 by
               the authors. Licensee MDPI, Basel, Switzerland.",
  journal   = "Sustainability (Switzerland)",
  publisher = "MDPI AG",
  volume    =  9,
  number    =  8,
  year      =  2017,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026824347&doi=10.3390%2fsu9081335&partnerID=40&md5=fae4e8c733e19d3d32edd65993c456b2",
  keywords  = "Corn; Decision tree; Hyper spectral imaging; Object-oriented;
               Weed; accessibility; accuracy assessment; agricultural land;
               algorithm; decision making; detection method; discriminant
               analysis; entropy; maize; NDVI; shape; spectral analysis;
               spectrometer; texture; weed; Zea mays;reviewed",
  issn      = "2071-1050",
  doi       = "10.3390/su9081335"
}

@ARTICLE{El-Faki2000-lh,
  title     = "Weed detection using color machine vision",
  author    = "El-Faki, M S and Zhang, N and Peterson, D E",
  abstract  = "Many weed species have reddish stems, but stems of wheat and
               soybean are green. These color features were used in this study
               to establish a simple weed-detection method using a color
               machine-vision system. This method is more practical than
               texture- or shape-based methods because of its low sensitivity
               to canopy overlap, leaf orientation, camera focusing, and wind
               effect. Four types of relative color indices formed by RGB gray
               levels were designed. The most effective combinations of these
               color indices were selected using a statistical method. These
               combinations were used as the input variables for a statistical
               classifier based on discriminant analysis (DA) and two
               artificial neural-network (NN) classifiers. These classifiers
               were trained and tested using three weed species. (Johnsongrass,
               redroot pigweed, and yellow foxtail) with soybean and three weed
               species (wild buckwheat, cheat, and field bindweed) with wheat.
               Preprocessing and postprocessing algorithms were developed to
               shorten the processing time and to reduce noise. The results
               showed that the statistical DA classifier was more accurate than
               the NN classifiers in classification accuracy. The least-square
               means of the classification rates using the DA classifiers for
               soybean and wheat were 54.9\% and 62.2\%, respectively. The
               misclassification rates for most weed species were below 3\%.
               Because the reddish colors on the stems of some weed species
               vary as the plants grow, an in-field calibration procedure will
               be needed to make the classifiers more adaptive to different
               circumstances. Many weed species have reddish stems, but stems
               of wheat and soybean are green. These color features were used
               in this study to establish a simple weed-detection method using
               a color machine-vision system. This method is more practical
               than texture- or shape-based methods because of its low
               sensitivity to canopy overlap, leaf orientation, camera
               focusing, and wind effect. Four types of relative color indices
               formed by RGB gray levels were designed. The most effective
               combinations of these color indices were selected using a
               statistical method. These combinations were used as the input
               variables for a statistical classifier based on discriminant
               analysis (DA) and two artificial neural-network (NN)
               classifiers. These classifiers were trained and tested using
               three weed species. (Johnsongrass, redroot pigweed, and yellow
               foxtail) with soybean and three weed species (wild buckwheat,
               cheat, and field bindweed) with wheat. Preprocessing and
               postprocessing algorithms were developed to shorten the
               processing time and to reduce noise. The results showed that the
               statistical DA classifier was more accurate than the NN
               classifiers in classification accuracy. The least-square means
               of the classification rates using the DA classifiers for soybean
               and wheat were 54.9\% and 62.2\%, respectively. The
               misclassification rates for most weed species were below 3\%.
               Because the reddish colors on the stems of some weed species
               vary as the plants grow, an in-field calibration procedure will
               be needed to make the classifiers more adaptive to different
               circumstances.",
  journal   = "Trans. ASAE",
  publisher = "ASAE",
  volume    =  43,
  number    =  6,
  pages     = "1969--1978",
  year      =  2000,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034473205&partnerID=40&md5=e0134c79bd1e86417cea41fa1fb0e936",
  address   = "St. Joseph, MI, United States",
  keywords  = "Color; Discriminant analysis; Machine vision; Precision
               agriculture; Sensor; Weed; Algorithms; Color image processing;
               Computer vision; Neural networks; Pattern recognition;
               Discriminant analysis; Weed detection; Weed control;weed
               discrimination",
  issn      = "0001-2351"
}

@ARTICLE{Elstone2020-gf,
  title     = "High speed crop and weed identification in lettuce fields for
               precision weeding",
  author    = "Elstone, L and How, K Y and Brodie, S and Ghazali, M Z and
               Heath, W P and Grieve, B",
  abstract  = "Precision weeding can significantly reduce or even eliminate the
               use of herbicides in farming. To achieve high-precision,
               individual targeting of weeds, high-speed, low-cost plant
               identification is essential. Our system using the red, green,
               and near-infrared reflectance, combined with a size
               differentiation method, is used to identify crops and weeds in
               lettuce fields. Illumination is provided by LED arrays at 525,
               650, and 850 nm, and images are captured in a single-shot using
               a modified RGB camera. A kinematic stereo method is utilised to
               compensate for parallax error in images and provide accurate
               location data of plants. The system was verified in field trials
               across three lettuce fields at varying growth stages from 0.5 to
               10 km/h. In-field results showed weed and crop identification
               rates of 56\% and 69\%, respectively. Post-trial processing
               resulted in average weed and crop identifications of 81\% and
               88\%, respectively. \copyright{} 2020 by the authors. Licensee
               MDPI, Basel, Switzerland.",
  journal   = "Sensors",
  publisher = "MDPI AG",
  volume    =  20,
  number    =  2,
  year      =  2020,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078004407&doi=10.3390%2fs20020455&partnerID=40&md5=2ffd3c6fdb09c92a85a92acb98bdf1a6",
  keywords  = "Kinetic stereo imaging; Multispectral imaging; Plant detection;
               Precision weeding; Crops; Geometrical optics; Infrared devices;
               Crop identification; Differentiation methods; Multispectral
               imaging; Near infra-red reflectances; Plant detections; Plant
               identification; Precision weeding; Stereo imaging; Stereo image
               processing; article; crop; field study; growth curve; human;
               illumination; infrared radiation; lettuce; nonhuman; velocity;
               weed;weed discrimination",
  issn      = "1424-8220",
  doi       = "10.3390/s20020455",
  pmc       = "31947520"
}

@ARTICLE{Hemming2001-ue,
  title     = "Computer-vision-based weed identification under field conditions
               using controlled lighting",
  author    = "Hemming, J and Rath, T",
  abstract  = "The methods of digital image analysis were used to develop an
               identification system for weeds in crops. Two vegetable crops
               (cabbage and carrots) and a number of naturally occurring weed
               species were used to develop the classification algorithms.
               Considering the rougher environment, special attention was given
               to the open-field experiments. The images were obtained with a
               device that provided controlled lighting conditions. The
               analysis was carried out off-line. Eight different morphological
               features and three colour features were calculated for each
               single object to build a joint feature space. On the basis of
               sample data sets of each class, statistics were carried out to
               determine the features, which are suitable for discrimination. A
               membership function based on a fuzzy logic approach was formed
               and used for the classification. The experiments showed that
               colour features can help to increase the classification
               accuracy. Moreover, colour was used successfully for the
               segmentation procedure of plants and soil. Depending on growth
               stage, weed density and method of calculation between 51 and
               95\% of the plants were classified correctly. Problems still
               exists by separating and allocating single plants in plant
               stands where the plants have grown together. Compared to other
               studies the plant identification system presented is an
               improvement, especially considering that the experiments were
               carried out under field conditions. \copyright{} 2001 Silsoe
               Research Institute.",
  journal   = "J. Agric. Eng. Res.",
  publisher = "Academic Press",
  volume    =  78,
  number    =  3,
  pages     = "233--243",
  year      =  2001,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002811038&doi=10.1006%2fjaer.2000.0639&partnerID=40&md5=11eb6f8f661ae8a2b94ddcf758f67b99",
  keywords  = "image processing",
  issn      = "0021-8634",
  doi       = "10.1006/jaer.2000.0639"
}

@PROCEEDINGS{Zhang2006-lm,
  title      = "Crop/weed discrimination using near-infrared reflectance
                spectroscopy ({NIRS})",
  author     = "Zhang, Y and He, Y",
  abstract   = "The traditional uniform herbicide application often results in
                an over chemical residues on soil, crop plants and agriculture
                produce, which have imperiled the environment and food
                security. Near-infrared reflectance spectroscopy (NIRS) offers
                a promising means for weed detection and site-specific
                herbicide application. In laboratory, a total of 90 samples (30
                for each species) of the detached leaves of two weeds, i.e.,
                threeseeded mercury (Acalypha australis L.) and fourleafed
                duckweed (Marsilea quadrifolia L.), and one crop soybean
                (Glycine max) was investigated for NIRS on 325-1075 nm using a
                field spectroradiometer. 20 absorbance samples of each species
                after pretreatment were exported and the lacked Y variables
                were assigned independent values for partial least squares
                (PLS) analysis. During the combined principle component
                analysis (PCA) on 400-1000 nm, the PC1 and PC2 could together
                explain over 91\% of the total variance and detect the three
                plant species with 98.3\% accuracy. The full-cross validation
                results of PLS, i.e., standard error of prediction (SEP) 0.247,
                correlation coefficient (r) 0.954 and root mean square error of
                prediction (RMSEP) 0.245, indicated an optimum model for weed
                identification. By predicting the remaining 10 samples of each
                species in the PLS model, the results with deviation presented
                a 100\% crop/weed detection rate. Thus, it could be concluded
                that PLS was an available alternative of for qualitative weed
                discrimination on NIRS.",
  volume     = "6047 II",
  year       =  2006,
  url        = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749660146&doi=10.1117%2f12.710957&partnerID=40&md5=c967c2b300ec31e5b6908f6dc68d3e2c",
  keywords   = "Near-infrared reflectance spectra; Partial least squares; Plant
                recognition; Site-specific weed management; Near-infrared
                reflectance spectra; Partial least squares; Plant recognition;
                Site-specific weed management; Crops; Herbicides; Least squares
                approximations; Plants (botany); Principal component analysis;
                Weed control; Infrared spectroscopy; Farm Crops; Herbicides;
                Infrared Spectroscopy; Plants; Weed Control;weed discrimination",
  conference = "4th International Conference on Photonics and Imaging in
                Biology and Medicine",
  location   = "Tianjin",
  isbn       = "9780819460806",
  doi        = "10.1117/12.710957"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Honig2021-df,
  title        = "Farmworkers face a life-and-death commute to Arizona's
                  lettuce fields",
  booktitle    = "Food and Environment Reporting Network",
  author       = "Honig, Esther",
  abstract     = "It's one in the morning and the stars are out as hundreds of
                  people shuffle slowly along the wall that marks the U.S.
                  border in the small Mexican city of San Luis R{\'\i}o
                  Colorado. In heavy boots and wide…",
  month        =  apr,
  year         =  2021,
  url          = "https://thefern.org/2021/04/farmworkers-face-a-life-and-death-commute-to-arizonas-lettuce-fields/",
  howpublished = "\url{https://thefern.org/2021/04/farmworkers-face-a-life-and-death-commute-to-arizonas-lettuce-fields/}",
  note         = "Accessed: 2022-2-3",
  language     = "en"
}

@INCOLLECTION{Brivot1996-af,
  title     = "Segmentation of plants and weeds using infrared images",
  booktitle = "Acta Horticulturae",
  author    = "Brivot, R and Marchant, J A",
  abstract  = "The work presented here is part of a project whose goal is to
               guide automatically a vehicle along rows of crops in order to
               target herbicide or pesticide accurately on weeds or plants.
               This paper deals with the segmentation of near-infrared images
               for discriminating plants, weeds, and soil. The algorithm
               described has been developed with a real-time parallel
               implementation and a real agricultural environment in mind. This
               algorithm uses techniques based on hysteresis thresholding and
               region labelling methods, blob-filtering and mathematical
               morphology. It can provide information on the size and the
               position of plants and weed patches as well as information that
               could be used either for guiding the vehicle or tracking plants
               and weeds. Successful segmentation has been done on several
               image sequences in diffuse light conditions. We show that it is
               possible to discriminate plants, weeds, and soil for different
               fields of view.",
  publisher = "International Society for Horticultural Science",
  volume    =  406,
  pages     = "165--172",
  year      =  1996,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0013424884&doi=10.17660%2fActaHortic.1996.406.16&partnerID=40&md5=4066a07c2f9ea08f2704ccc101dbcb68"
}

@ARTICLE{Kamath2020-mx,
  title     = "Crop and weed discrimination using laws' texture masks",
  author    = "Kamath, R and Balachandra, M and Prabhu, S",
  abstract  = "Computers have become an integral part of human lives. Computers
               are used in almost every field even in agriculture. Technologies
               like computer vision-based pattern recognition are being used to
               detect diseases and pests like weeds affecting the crop. The
               Weeds are unwanted plants growing among crops competing for
               nutrients, water, and sunlight. It can significantly reduce the
               quality and yield of the crops incurring a huge loss to the
               farmers. This paper investigates the use of texture features
               extracted from Laws' texture masks for discrimination of Carrot
               crops and weeds in digital images. Laws' texture method is one
               of the popular methods used to extract texture features in
               medical image processing, though not much explored in
               plant-based images or agricultural images. This experiment was
               carried out on two categories of benchmark digital image
               datasets of Carrot crop and Carrot weed respectively, which are
               publicly available. A total of 70 texture features were
               extracted. The dimensionality reduction technique was used to
               get the optimal features. These features were then used to train
               the Random Forest classifier. The results and observations from
               the experiment showed that the classifier achieved above 94\%
               accuracy. \copyright{} 2020, Chinese Society of Agricultural
               Engineering. All rights reserved.",
  journal   = "International Journal of Agricultural and Biological Engineering",
  publisher = "Chinese Society of Agricultural Engineering",
  volume    =  13,
  number    =  1,
  pages     = "191--197",
  year      =  2020,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081009680&doi=10.25165%2fj.ijabe.20201301.4920&partnerID=40&md5=1fccce9c4eac30676cf336ee8bab310d",
  keywords  = "Classifier; Crop; Precision agriculture; Texture analysis; Weed",
  issn      = "1934-6344"
}

@INCOLLECTION{Sujith2021-gv,
  title     = "Classification of plant leaf using shape and texture features",
  booktitle = "4th International Conference on Inventive Communication and
               Computational Technologies, {ICICCT} 2020",
  author    = "Sujith, A and Neethu, R",
  editor    = "{Ranganathan G.} and {Chen J.} and {Rocha A.}",
  abstract  = "Plants are mainly classified based on their characteristics of
               plant components such as leaves, flower, stem, root, seed, etc.
               Feature or characteristics is an essential fact for plant
               classification. A good feature extraction technique can help to
               extract quality features that give clear information to
               discriminate against each class. Computer engineers can help
               botanists to identify plants and their species through advanced
               computational techniques with the stipulated time. The proposed
               method gives efficient hybrid feature extraction using the PHOG,
               LBP, and GLCM feature extraction techniques. The fused feature
               vector is normalized and reduced size by Neighborhood Components
               Analysis (NCA). The efficient feature extraction and feature
               selection techniques have helped to improve the classification
               performance and reduced the model complexity. Two benchmark
               plant dataset Flavia and Swedish Leaves used to evaluate the
               proposed work. The primary contributions of this paper are
               introducing a multi-feature fusion shape and texture method for
               plant leaf image classification. The experimental result shows
               the average accuracy of the proposed method is 98.23\%, and the
               average computational complexity is 147.98 s. \copyright{} The
               Editor(s) (if applicable) and The Author(s), under exclusive
               license to Springer Nature Singapore Pte Ltd 2021.",
  publisher = "Springer Science and Business Media Deutschland GmbH",
  volume    =  145,
  pages     = "269--282",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092080888&doi=10.1007%2f978-981-15-7345-3_22&partnerID=40&md5=f92582e3689f8f5ec3bc7353a4113168",
  keywords  = "Gray level co-occurrence matrix; Local binary pattern;
               Neighborhood components analysis; Plant classification; Pyramid
               histogram of oriented gradients;weed discrimination",
  isbn      = "9789811573446",
  doi       = "10.1007/978-981-15-7345-3\_22"
}

@ARTICLE{Yang2021-oc,
  title     = "Plant leaf recognition by integrating shape and texture features",
  author    = "Yang, C",
  abstract  = "Plant leaf identification is a significant challenge in the
               fields of computer vision and pattern recognition. This article
               presents a new approach to plant leaf identification, one that
               integrates shape and texture characteristics. First, we
               introduce the shape and texture features used by the proposed
               plant leaf recognition method. The proposed multiscale triangle
               descriptor (MTD) is employed to characterize the shape
               information of a plant leaf, and the local binary pattern
               histogram Fourier (LBP-HF) is used as the texture feature. Then,
               the shape and texture features of a leaf image are combined by
               weighted distance measurement, where L1 distance and chi-square
               distance are used for shape and texture features, respectively.
               The proposed approach provides a robust descriptor for the task
               of plant leaf recognition by combining the complementary MTD and
               LBP-HF features. The proposed approach has been thoroughly
               evaluated on three benchmark leaf datasets, including the
               Flavia, Swedish and MEW2012 leaf datasets. Our method achieves
               77.6\%, 85.7\%, and 67.5\% retrieval accuracy on the Flavia,
               Swedish and MEW2012 leaf datasets, respectively, while the
               corresponding classification accuracy is 99.1\%, 98.4\%, 95.6\%.
               The recognition performance of our method is better or
               comparable to prior state-of-the-art plant leaf recognition
               method. \copyright{} 2020",
  journal   = "Pattern Recognit.",
  publisher = "Elsevier Ltd",
  volume    =  112,
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099478543&doi=10.1016%2fj.patcog.2020.107809&partnerID=40&md5=b0e8efbb8fe5fada80171a23a489b260",
  keywords  = "Local binary pattern; Multiscale triangle descriptor; Plant leaf
               recognition; Shape descriptor; Texture feature; Classification
               (of information); Textures; Chi Square distance; Classification
               accuracy; Local binary patterns; Retrieval accuracy; Shape and
               textures; Shape information; State of the art; Texture features;
               Pattern recognition;weed discrimination",
  issn      = "0031-3203",
  doi       = "10.1016/j.patcog.2020.107809"
}

@MISC{Hall-Beyer_undated-rc,
  title        = "{GLCM} Tutorial",
  author       = "Hall-Beyer, Mryka",
  url          = "http://dx.doi.org/10.11575/PRISM/33280",
  howpublished = "\url{http://dx.doi.org/10.11575/PRISM/33280}",
  note         = "Accessed: 2021-6-21",
  doi          = "10.11575/PRISM/33280"
}

@INCOLLECTION{Montalvo2016-yo,
  title     = "Identification of plant textures in agricultural images by
               principal component analysis",
  booktitle = "11th International Conference on Hybrid Artificial Intelligent
               Systems, {HAIS} 2016",
  author    = "Montalvo, M and Guijarro, M and Guerrero, J M and Ribeiro, {\'A}",
  editor    = "{Martinez-Alvarez F.} and {Troncoso A.} and {Quintian H.} and
               {Corchado E.}",
  abstract  = "In precision agriculture the extraction of green parts is a very
               important task. One of the biggest issues, when it comes to
               computer vision, is image segmentation, which has motivated the
               research conducted in this work. Our goal is the segmentation of
               vegetative and soil parts in the images. For this proposal a
               novel method of segmentation is defined in which different
               vegetation indices are calculated and through the reduction of
               components by principal component analysis (PCA) we obtain an
               enhanced greyscale image. Finally, by Otsu thresholding, we
               binarize the grayscale image isolating the green parts from the
               other elements in the image. \copyright{} Springer International
               Publishing Switzerland 2016.",
  publisher = "Springer Verlag",
  volume    =  9648,
  pages     = "391--401",
  year      =  2016,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964036740&doi=10.1007%2f978-3-319-32034-2_33&partnerID=40&md5=a6843a72b7feb95dce515571d1d10454",
  keywords  = "Agricultural images; Precision agriculture; Principal component
               analysis; Segmentation image; Thresholding; Agriculture;
               Artificial intelligence; Computer vision; Image analysis; Image
               segmentation; Intelligent systems; Agricultural images;
               Gray-scale images; Grey scale images; Otsu thresholding;
               Precision Agriculture; Segmentation images; Thresholding;
               Vegetation index; Principal component analysis;reviewed",
  isbn      = "9783319320335",
  doi       = "10.1007/978-3-319-32034-2\_33"
}

@ARTICLE{Chaki2015-bc,
  title     = "Plant leaf recognition using texture and shape features with
               neural classifiers",
  author    = "Chaki, J and Parekh, R and Bhattacharya, S",
  abstract  = "Abstract This paper proposes a novel methodology of
               characterizing and recognizing plant leaves using a combination
               of texture and shape features. Texture of the leaf is modeled
               using Gabor filter and gray level co-occurrence matrix (GLCM)
               while shape of the leaf is captured using a set of curvelet
               transform coefficients together with invariant moments. Since
               these features are in general sensitive to the orientation and
               scaling of the leaf image, a pre-processing stage prior to
               feature extraction is applied to make corrections for varying
               translation, rotation and scaling factors. Efficacy of the
               proposed methods is studied by using two neural classifiers: a
               neuro-fuzzy controller (NFC) and a feed-forward back-propagation
               multi-layered perceptron (MLP) to discriminate between 31
               classes of leaves. The features have been applied individually
               as well as in combination to investigate how recognition
               accuracies can be improved. Experimental results demonstrate
               that the proposed approach is effective in recognizing leaves
               with varying texture, shape, size and orientations to an
               acceptable degree. \copyright{} 2015 Elsevier B.V. All rights
               reserved.",
  journal   = "Pattern Recognit. Lett.",
  publisher = "Elsevier",
  volume    =  58,
  pages     = "61--68",
  year      =  2015,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925386662&doi=10.1016%2fj.patrec.2015.02.010&partnerID=40&md5=e14376e23185d1f11eb229149fcd2d61",
  keywords  = "Curvelet transform; Feed-forward back-propagation multi-layered
               perceptron; Gabor filter; Gray level co-occurrence matrix;
               Invariant moments; Neuro-fuzzy controller; Backpropagation;
               Feature extraction; Fuzzy filters; Gabor filters; Plants
               (botany); Textures; Curvelet transforms; Gray level
               co-occurrence matrix; Invariant moment; Multi-layered
               Perceptron; Neuro-fuzzy controller; Fuzzy inference",
  issn      = "0167-8655",
  doi       = "10.1016/j.patrec.2015.02.010"
}

@ARTICLE{Chaki2015-gf,
  title     = "Plant leaf recognition using texture and shape features with
               neural classifiers",
  author    = "Chaki, J and Parekh, R and Bhattacharya, S",
  abstract  = "Abstract This paper proposes a novel methodology of
               characterizing and recognizing plant leaves using a combination
               of texture and shape features. Texture of the leaf is modeled
               using Gabor filter and gray level co-occurrence matrix (GLCM)
               while shape of the leaf is captured using a set of curvelet
               transform coefficients together with invariant moments. Since
               these features are in general sensitive to the orientation and
               scaling of the leaf image, a pre-processing stage prior to
               feature extraction is applied to make corrections for varying
               translation, rotation and scaling factors. Efficacy of the
               proposed methods is studied by using two neural classifiers: a
               neuro-fuzzy controller (NFC) and a feed-forward back-propagation
               multi-layered perceptron (MLP) to discriminate between 31
               classes of leaves. The features have been applied individually
               as well as in combination to investigate how recognition
               accuracies can be improved. Experimental results demonstrate
               that the proposed approach is effective in recognizing leaves
               with varying texture, shape, size and orientations to an
               acceptable degree. \copyright{} 2015 Elsevier B.V. All rights
               reserved.",
  journal   = "Pattern Recognit. Lett.",
  publisher = "Elsevier",
  volume    =  58,
  pages     = "61--68",
  year      =  2015,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925386662&doi=10.1016%2fj.patrec.2015.02.010&partnerID=40&md5=e14376e23185d1f11eb229149fcd2d61",
  keywords  = "Curvelet transform; Feed-forward back-propagation multi-layered
               perceptron; Gabor filter; Gray level co-occurrence matrix;
               Invariant moments; Neuro-fuzzy controller; Backpropagation;
               Feature extraction; Fuzzy filters; Gabor filters; Plants
               (botany); Textures; Curvelet transforms; Gray level
               co-occurrence matrix; Invariant moment; Multi-layered
               Perceptron; Neuro-fuzzy controller; Fuzzy inference",
  issn      = "0167-8655",
  doi       = "10.1016/j.patrec.2015.02.010"
}

@ARTICLE{Concepcion2020-qo,
  title   = "Lettuce Canopy Area Measurement Using Static Supervised Neural
             Networks Based on Numerical Image Textural Feature Analysis of
             Haralick and Gray Level {Co-Occurrence} Matrix",
  author  = "Concepcion, II, Ronnie S and Lauguico, Sandy C and Alejandrino,
             Jonnel D and Dadios, Elmer P and Sybingco, Edwin",
  journal = "Malang",
  volume  =  42,
  number  =  3,
  pages   = "472--486",
  month   =  oct,
  year    =  2020,
  url     = "http://dx.doi.org/10.17503/agrivita.v42i3.2528",
  doi     = "10.17503/agrivita.v42i3.2528"
}

@ARTICLE{Raja2020-wi,
  title     = "Real-time weed-crop classification and localisation technique
               for robotic weed control in lettuce",
  author    = "Raja, R and Nguyen, T T and Slaughter, D C and Fennimore, S A",
  abstract  = "Robotic weed control for vegetables is necessary to increase
               crop productivity, avoid intensive hand weeding as labour
               shortages in developed countries such as United States has led
               to a surge in food production costs. However, development of a
               reliable, intelligent robotic system for weed control in
               real-time for vegetables still remains a challenging task. The
               main issue arises while distinguishing crops from weeds in
               real-time. In this paper, a novel technique to crop signalling
               to distinguish crops from in-row weeds in complex natural
               scenarios, such as high weed densities commonly found on organic
               farms, in real-time using machine vision is presented. Crop
               signalling is a simple and low-cost technique in which a
               signalling compound is produced by or applied to the crop and
               where the signalling compound is machine readable and helps to
               create visual features that uniquely distinguish the crops from
               weeds. The crop and weed mapping algorithm presented here were
               specially designed and developed for a vision-based weeding
               robot equipped with a micro-jet herbicide-spraying system for
               weed control in a lettuce field. The proposed technique involves
               weed/crop mapping and decision making. Experimental results show
               that the crop detection accuracy was 99.75\%, and 98.11\% of
               sprayable weeds were detected. The proposed technique is highly
               accurate, reliable and more robust than other sensor-based
               techniques presented in the literature. \copyright{} 2020 IAgrE",
  journal   = "Biosystems Eng.",
  publisher = "Academic Press",
  volume    =  192,
  pages     = "257--274",
  year      =  2020,
  url       = "http://dx.doi.org/10.1016/j.biosystemseng.2020.02.002",
  keywords  = "Automatic weed control; crop signalling; machine vision;
               precision agriculture; robotics; Computer vision; Conformal
               mapping; Costs; Crops; Decision making; Intelligent robots;
               Precision agriculture; Robotics; Vegetables; Crop
               classification; Crop productivity; Detection accuracy; Developed
               countries; Food production; Intelligent robotic systems; Novel
               techniques; Spraying system; Weed control;reviewed",
  issn      = "1537-5110",
  doi       = "10.1016/j.biosystemseng.2020.02.002"
}

@ARTICLE{Gomathi2020-pj,
  title     = "Meta-heuristic based trained deep convolutional neural network
               for crop/weed classification",
  author    = "Gomathi, N and Jagtap, A M",
  abstract  = "Computer vision and camera sensors are hopeful technologies for
               capturing information and processing to facilitate autonomous
               cultivation with machine learning. Nowadays, field robots are
               widely utilized, which autonomously navigates in fields tasks
               for advanced developments. However, manual activities are also
               required for certain needs, for instance, controlling weed in
               organic carrot farming is carried out manually and it is
               essential to evade considerable crop yield loss. This paper
               makes an attempt to introduce a new automatic crop/weed
               classification under three major phases: (i) Pre-processing (ii)
               Feature Extraction and (iii) Classification. Initially, the
               images are converted to greyscale images under pre-processing
               stage. Further, from the pre-processed image, the features like
               ``Grey Level Co-occurrence Matrix (GLCM) and Grey Level
               Runlength Matrix (GLRM) based texture features'' are extracted.
               Finally, the classification is done by the hybrid classifiers,
               where both the Deep Convolutional Neural Network (DCNN) and
               Neural Network (NN) is incorporated. Finally, both the
               classified outputs are ORed to get the final classification
               output. Moreover, in order to enhance the performance of
               proposed work, it is planned to tune the hidden neurons of NN
               optimally via a new improved Moth Search Algorithm (MSA) and is
               named as Moth Search with new Step Length evaluation (MS-SL).
               Finally, the performance of proposed work is evaluated over
               other state-of-the-art models with respect to certain
               performance measures. \copyright{} 2020, World Academy of
               Research in Science and Engineering. All rights reserved.",
  journal   = "International Journal of Emerging Trends in Engineering Research",
  publisher = "World Academy of Research in Science and Engineering",
  volume    =  8,
  number    =  7,
  pages     = "3915--3926",
  year      =  2020,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090297627&doi=10.30534%2fijeter%2f2020%2f161872020&partnerID=40&md5=4d864dcdcaf85499c6f0714982e3410f",
  keywords  = "Crop classification; DCNN; GLCM; GLRM; Moth Search
               Algorithm;glcm;reviewed",
  issn      = "2347-3983",
  doi       = "10.30534/ijeter/2020/161872020"
}

@ARTICLE{Sabzi2020-af,
  title    = "An automatic visible-range video weed detection, segmentation and
              classification prototype in potato field",
  author   = "Sabzi, Sajad and Abbaspour-Gilandeh, Yousef and Arribas, Juan
              Ignacio",
  abstract = "Weeds might be defined as destructive plants that grow and
              compete with agricultural crops in order to achieve water and
              nutrients. Uniform spray of herbicides is nowadays a common cause
              in crops poisoning, environment pollution and high cost of
              herbicide consumption. Site-specific spraying is a possible
              solution for the problems that occur with uniform spray in
              fields. For this reason, a machine vision prototype is proposed
              in this study based on video processing and meta-heuristic
              classifiers for online identification and classification of
              Marfona potato plant (Solanum tuberosum) and 4299 samples from
              five weed plant varieties: Malva neglecta (mallow), Portulaca
              oleracea (purslane), Chenopodium album L (lamb's quarters),
              Secale cereale L (rye) and Xanthium strumarium (coklebur). In
              order to properly train the machine vision system, various videos
              taken from two Marfona potato fields within a surface of six
              hectares are used. After extraction of texture features based on
              the gray level co-occurrence matrix (GLCM), color features,
              spectral descriptors of texture, moment invariants and shape
              features, six effective discriminant features were selected: the
              standard deviation of saturation (S) component in HSV color
              space, difference of first and seventh moment invariants, mean
              value of hue component (H) in HSI color space, area to length
              ratio, average blue-difference chrominance (Cb) component in
              YCbCr color space and standard deviation of in-phase (I)
              component in YIQ color space. Classification results show a high
              accuracy of 98\% correct classification rate (CCR) over the test
              set, being able to properly identify potato plant from previously
              mentioned five different weed varieties. Finally, the machine
              vision prototype was tested in field under real conditions and
              was able to properly detect, segment and classify weed from
              potato plant at a speed of up to 0.15 m/s.",
  journal  = "Heliyon",
  volume   =  6,
  number   =  5,
  pages    = "e03685",
  month    =  may,
  year     =  2020,
  url      = "http://dx.doi.org/10.1016/j.heliyon.2020.e03685",
  keywords = "Agricultural engineering; Agricultural soil science; Agricultural
              technology; Agriculture; Classification; Computational
              intelligence; Computer engineering; Computer simulation; Food
              engineering; Food science; Horticulture; Machine vision;
              Meta-heuristic algorithms; Plant competition; Site-specific
              spraying; Video processing; Video processing.;glcm",
  language = "en",
  issn     = "2405-8440",
  pmid     = "32490222",
  doi      = "10.1016/j.heliyon.2020.e03685",
  pmc      = "PMC7260593"
}

@MISC{Wirth2004-li,
  title     = "Shape Analysis and Measurement",
  author    = "Wirth, Michael A",
  year      =  2004,
  url       = "http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf",
  keywords  = "reviewed",
  copyright = "2004"
}

@PROCEEDINGS{Andujar2013-ot,
  title      = "Weed-crop discrimination using {LiDAR} measurements",
  author     = "And{\'u}jar, D and Moreno, H and Valero, C and Gerhards, R and
                Griepentrog, H W",
  abstract   = "In this paper, we propose a new approach for discriminating
                maize and weed plants from soil surface, evaluating the
                accuracy and performance of a LiDAR sensor for vegetation
                detection using distance and reflection values. Field
                measurements were conducted in a maize field at growth stage
                BBCH 12-14. Static measurements were taken at different
                sampling areas with different weed densities. Regression
                analyses were carried out to assess the capabilities of the
                system for vegetation and soil measurement. A high relationship
                between LiDAR measured distance (LiDAR heights) and actual
                height was found. A binary logistic regression was used to
                predict the presence or absence of vegetation. The results
                permitted the discrimination of vegetation from the soil with
                accuracy up to 95\%. This technique offers significant promise
                for the development of real-time spatially selective weed
                control techniques, either as the sole weed detection system or
                in combination with other detection tools.",
  year       =  2013,
  url        = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893416174&partnerID=40&md5=2fd8355844d3f81a6dace79420c0da04",
  keywords   = "Laser scanning; Plant height; Reflection; Weed detection;
                Binary logistic regression; Control techniques; Field
                measurement; Laser scanning; Lidar measurements; Plant height;
                Static measurements; Weed detection; Agriculture; Optical
                radar; Reflection; Regression analysis; Vegetation; Weed
                control",
  conference = "9th European Conference on Precision Agriculture, ECPA 2013",
  location   = "Lleida, Catalonia",
  isbn       = "9789086862245"
}

@ARTICLE{Shahbazi2021-kr,
  title     = "Comparison of crop and weed height, for potential
               differentiation of weed patches at harvest",
  author    = "Shahbazi, N and Flower, K C and Callow, J N and Mian, A and
               Ashworth, M B and Beckie, H J",
  abstract  = "Weeds and weed control are major production costs in global
               agriculture, with increasing challenges associated with
               herbicide-based management because of concerns with chemical
               residue and herbicide resistance. Non-chemical weed management
               may address these challenges but requires the ability to
               differentiate weeds from crops. Harvest is an ideal opportunity
               for the differentiation of weeds that grow taller than the crop,
               however, the ability to differentiate late-season weeds from the
               crop is unknown. Weed mapping enables farmers to locate weed
               patches, evaluate the success of previous weed management
               strategies, and assist with planning for future herbicide
               applications. The aim of this study was to determine whether
               weed patches could be differentiated from the crop plants, based
               on height differences. Field surveys were carried out before
               crop harvest in 2018 and 2019, where a total of 86 and 105 weedy
               patches were manually assessed respectively. The results of this
               study demonstrated that across the 191 assessed weedy patches,
               in 97\% of patches with Avena fatua (wild oat) plants, 86\% with
               Raphanus raphanistrum (wild radish) plants and 92\% with Sonchus
               oleraceus L. (sow thistles) plants it was possible to
               distinguish the weeds taller than the 95\% of the crop plants.
               Future work should be dedicated to the assessment of the ability
               of remote sensing methods such as Light Detection and Ranging to
               detect and map late-season weed species based on the results
               from this study on crop and weed height differences.
               \copyright{} 2020 European Weed Research Society",
  journal   = "Weed Res.",
  publisher = "Blackwell Publishing Ltd",
  volume    =  61,
  number    =  1,
  pages     = "25--34",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097017406&doi=10.1111%2fwre.12450&partnerID=40&md5=9100bbbcdff8dafcf5ee83f8c55d1674",
  keywords  = "height; late-season weed control; site-specific weed management;
               weed-crop differentiation; cereal; comparative study; crop
               plant; differentiation; field survey; harvesting; height;
               herbicide; lidar; mapping method; remote sensing; weed; weed
               control; Avena fatua; Raphanus raphanistrum; Raphanus sativus;
               Sonchus oleraceus",
  issn      = "0043-1737",
  doi       = "10.1111/wre.12450"
}

@ARTICLE{Barati2011-oj,
  title    = "Comparison the accuracies of different spectral indices for
              estimation of vegetation cover fraction in sparse vegetated areas",
  author   = "Barati, Susan and Rayegani, Behzad and Saati, Mehdi and Sharifi,
              Alireza and Nasri, Masoud",
  abstract = "Quantitative estimation of canopy biophysical variables are very
              important in different studies such as meteorology, agriculture
              and ecology, so knowledge of the spatial and temporal
              distribution of these variables would be highly beneficial.
              Meanwhile, remote sensing is known as an important source of
              information to estimate fractional vegetation cover in large
              areas. Today spectral indices have been very popular in the
              remote sensing of vegetation features. But often reflections of
              soil and rocks are much more than reflections of sparse
              vegetation in these areas, that makes separation of plant signals
              difficult. So in this study measured fractional vegetation cover
              of a desert area were evaluated with 20 vegetation indices in
              five different categories as the most appropriate category, or
              indicator for desert vegetation to be identified. The five
              categories were including: (1) conventional ratio and
              differential indices such as NDVI; (2) indices corrected and
              derived from the traditional indicators such as NDVIc and GNDVI;
              (3) soil reflectance adjusted indices such as SAVI; (4) triangle
              indices based on three discreet bands in their equation (Green,
              Red and NIR) like TVI; and (5) non-conventional ratio and
              differential indices such as CI. According to the results of this
              research, DVI index with 0.668 the coefficient of determination
              (R2) showed the best fractional vegetation cover estimation. But
              according to the sparse vegetation in desert areas and the
              results of this research it seems none of these indicators alone
              can accurately estimate the percentage of vegetation cover,
              however, to do a proper estimation it is possible to enter data
              of these indices in a multivariate regression model. Using this
              method enabled us to increase the coefficient of determination of
              fractional vegetation cover estimation model up to 0.797.",
  journal  = "Egypt. J. Remote Sens. Space Sci.",
  volume   =  14,
  number   =  1,
  pages    = "49--56",
  month    =  jun,
  year     =  2011,
  url      = "https://www.sciencedirect.com/science/article/pii/S1110982311000147",
  keywords = "Vegetation cover fraction; Remote sensing; LISS III; Vegetation
              indices",
  issn     = "1110-9823",
  doi      = "10.1016/j.ejrs.2011.06.001"
}

@MISC{Various_undated-lg,
  title        = "{CyVerse} Documentation",
  author       = "{Various}",
  url          = "https://learning.cyverse.org/_/downloads/foss/en/foss-2020-spring/pdf/",
  howpublished = "\url{https://learning.cyverse.org/_/downloads/foss/en/foss-2020-spring/pdf/}"
}

@MISC{Various_undated-oj,
  title        = "{CircleCI} Documentation",
  author       = "{Various}",
  url          = "https://circleci.com/docs/2.0/configuration-reference/",
  howpublished = "\url{https://circleci.com/docs/2.0/configuration-reference/}"
}

@MISC{Various_undated-yv,
  title        = "{HSL} and {HSV}",
  booktitle    = "Wikipedia",
  author       = "{Various}",
  url          = "https://en.wikipedia.org/wiki/HSL_and_HSV",
  howpublished = "\url{https://en.wikipedia.org/wiki/HSL_and_HSV}"
}

@INCOLLECTION{Sheeba2021-pd,
  title     = "A Comparison Study on Various Continuous Integration Tools in
               Software Development",
  booktitle = "4th International Conference on Information and Communication
               Technology for Intelligent {Systems,ICTIS} 2020",
  author    = "{Sheeba} and Shidaganti, G and Gosar, A P",
  editor    = "{Joshi A.} and {Khosravy M.} and {Gupta N.}",
  abstract  = "Continuous integration (CI) frameworks are currently the basis
               for a few software development projects that reduce the time and
               cost of the software. Most of the companies provide CI tools
               with similar facilities and some companies build their own CI
               tool. However, it does not mean that the costliest product is
               better than a low-cost or open-source device. Generally, all of
               these tools are intended to make the Product Building Software
               Process easy and automated by quality assurance and time
               reduction. In spite of this fact, ongoing integration tools have
               their own merits and demerits, so it is very important and
               sometimes difficult to choose the right CI tool for a project.
               The wrong choice of tools can reduce the overall flexibility and
               quality of the software. A few continuous integration tools,
               such as Jenkins, TravisCI, Codeship, Bamboo, TeamCity and
               CircleCI, which implement CI practices, are generally adopted by
               programmers, developers. The main objective of this paper is to
               demonstrate the analysis, usefulness and comparison of selected
               tools and to help in selecting the most compatible CI
               implementation tool that meets project requirements.
               \copyright{} 2021, The Editor(s) (if applicable) and The
               Author(s), under exclusive license to Springer Nature Singapore
               Pte Ltd.",
  publisher = "Springer Science and Business Media Deutschland GmbH",
  volume    =  141,
  pages     = "65--76",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096450028&doi=10.1007%2f978-981-15-7106-0_7&partnerID=40&md5=2c7c1f0fbfe2113290377747fc59fedf",
  keywords  = "CI tool; Continuous integration; Continuous integration
               framework; Software development projects; Software project",
  isbn      = "9789811571053",
  doi       = "10.1007/978-981-15-7106-0\_7"
}

@PROCEEDINGS{Liao2020-xv,
  title      = "Modelling {CI/CD} Pipeline through {Agent-Based} Simulation",
  author     = "Liao, Q",
  editor     = "{Vieira M.} and {Madeira H.} and {Antunes N.} and {Zheng Z.}",
  abstract   = "The need for rapid and efficient software development pushes
                the demand for automation in the phases of build, test, and
                release. Thereby, the methodology of Continuous Integration and
                Continuous Deployment (CI/CD) emerges, which then gives birth
                to a set of CI/CD enabling services, such as Travis CI and
                Jenkins. Those services facilitate the automatic compilation,
                connection tracking, and packaging of new features. They not
                only incorporate playgrounds for testing and functionality
                verification but also enable the final delivery.Poor
                understanding and execution in CI/CD operations can result in
                slowing and even halting the pace of a software project. Many
                bottlenecks of CI/CD pipeline might occur due to its incorrect
                configurations, i.e. the inadequate level of automation, the
                unsuitable load capacity and the suboptimal queueing strategy.
                However, understanding the actual CI/CD pipeline is hard since
                its performance varies significantly with different hosting
                machines, technologies and plugins. On the other hand, finding
                a way to analyse and improve the settings of CI/CD pipeline
                brings great managerial and economic benefits since an optimal
                configuration implies the eventual high efficiency. To that
                end, this study attempts to design a model that can not only
                capture the abstraction of the pipeline but also provides a
                testing environment for the impersonal influencers of CI/CD
                performance. The current study, therefore, aims to contribute
                (1) a pipeline model based on the logic of the queueing system
                and enabled by agent-based simulation, and (2) an experimental
                environment which allows the testing of different settings and
                operation scenarios. \copyright{} 2020 IEEE.",
  publisher  = "Institute of Electrical and Electronics Engineers Inc.",
  year       =  2020,
  url        = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099854360&doi=10.1109%2fISSREW51248.2020.00059&partnerID=40&md5=a6801c3b2d534a7dc4cd1016223e47d5",
  keywords   = "Agent-based Modelling; CI/CD; Multi-agent Simulation; Pipeline
                Simulation; Queueing System",
  conference = "31st IEEE International Symposium on Software Reliability
                Engineering Workshops, ISSREW 2020",
  isbn       = "9781728198705",
  doi        = "10.1109/ISSREW51248.2020.00059"
}

@ARTICLE{Msibi2021-to,
  title    = "High pesticide inhalation exposure from multiple spraying sources
              amongst applicators in Eswatini, Southern Africa",
  author   = "Msibi, Sithembiso S and Chen, Chung-Yu and Chang, Cheng-Ping and
              Chen, Chiou-Jong and Chiang, Su-Yin and Wu, Kuen-Yuh",
  abstract = "BACKGROUND: Serious concerns surround the potential risks
              resulting from inhalation exposure to pesticides amongst
              agricultural workers when mixing and applying these compounds. In
              Eswatini (formerly known as Swaziland), Southern Africa,
              pesticides are widely used to improve the yield and quality of
              sugar cane production, the largest contributor to the country's
              economy. We assessed applicators' inhalation exposures from
              multiple spraying sources to four commonly used herbicides in
              Eswatini. RESULTS: Analysis of 76 personal air samples by liquid
              chromatography with tandem mass spectrometry (LC-MS/MS) revealed
              four pesticides: ametryn, atrazine, pendimethalin and
              2,4-dichlorophenoxyacetic acid, with mean concentrations of
              36.91, 21.57, 31.05 and 0.89 $\mu$g m-3 , respectively. These
              inhalation exposures are much higher than those recorded in
              previous similar studies. CONCLUSION: Although all applicators in
              this study used personal protective equipment (PPE), they
              nevertheless recorded high levels of inhalation exposure to
              commonly used pesticides. Our findings suggest that in addition
              to observing mandated regular changing and cleaning practices
              with PPE for ultimate personal protection, pesticide applicators
              should distance themselves from each other when spraying to
              effectively reduce their exposure to pesticides from multiple
              spraying sources. Further studies are needed to determine the
              optimal spraying distance between pesticide applicators.
              \copyright{} 2021 Society of Chemical Industry.",
  journal  = "Pest Manag. Sci.",
  volume   =  77,
  number   =  10,
  pages    = "4303--4312",
  month    =  oct,
  year     =  2021,
  url      = "http://dx.doi.org/10.1002/ps.6459",
  keywords = "Africa; Eswatini; applicators; inhalation exposure; multiple
              spraying sources; pesticides;herbicides and health",
  language = "en",
  issn     = "1526-498X, 1526-4998",
  pmid     = "33942970",
  doi      = "10.1002/ps.6459"
}

@ARTICLE{Rydz2021-ar,
  title    = "Estimating Exposure to Three Commonly Used, Potentially
              Carcinogenic Pesticides (Chlorolathonil, 2,4-D, and Glyphosate)
              Among Agricultural Workers in Canada",
  author   = "Rydz, Ela and Larsen, Kristian and Peters, Cheryl E",
  abstract = "OBJECTIVES: Certain pesticides have been associated with adverse
              health outcomes including cancer and reproductive harms. However,
              little is known about the prevalence of occupational pesticide
              exposure among agricultural workers in Canada. The purpose of
              this study was to estimate the prevalence and likelihood of
              occupational exposure to pesticides in Canada's agricultural
              industry, using three commonly used, potentially carcinogenic
              pesticides [chlorothalonil, 2,4-dichlorophenoxyacetic acid
              (2,4-D), and glyphosate] as an example. METHODS: Estimates were
              calculated using the Canadian Census of Population and the Census
              of Agriculture. The number of workers and the proportion of farms
              applying 'herbicides' or 'fungicides' by farm type was estimated
              using survey data from the Census of Agriculture. These values
              were multiplied to yield the potential number of workers at risk
              of exposure. Likelihood of exposure (i.e. exposed, probably
              exposed, and possibly exposed) was then qualitatively assigned
              using information on crop type, primary expected tasks, crop
              production practices, and residue transfer data. Additional
              agricultural workers who are at risk of exposure but not captured
              by the Census of Agriculture were identified using the 2016
              Census of Population. RESULTS: An estimated range of 37 700-55
              800 workers (11-13\% of agricultural workers) were exposed to
              glyphosate in Canada while 30 800-43 600 workers (9-11\%) and
              9000-14 100 (2.9-3.2\%) were exposed to 2,4-D and chlorothalonil,
              respectively. Approximately 70-75\% of workers at risk of
              exposure were considered probably or possibly exposed to any of
              the pesticides. Glyphosate exposure was most common among workers
              in oilseed (29\% of oilseed farm workers exposed) and dry
              pea/bean farms (28\%), along with those providing support
              activities for farms (31\%). 2,4-D exposure was most common in
              corn (28\%), other grain (28\%), and soybean farms (27\%), while
              chlorothalonil exposure was more likely among greenhouse,
              nursery, and floriculture workers (42\%), workers on farms (28\%,
              for occupations not captured by the Census of Agriculture,
              specifically), and those providing support activities for farms
              (20\%). Regional variations broadly reflected differences in farm
              types by province. CONCLUSIONS: This study estimated the
              prevalence of occupational exposure to three pesticides in
              Canada. Seasonal and temporary agricultural workers, which were
              captured by the Census of Agriculture, contributed to many
              additionally exposed workers. A large percent of the workers who
              were considered at risk of exposure were considered probably or
              possibly exposed, indicating a need for enhanced data collection
              and availability on pesticide use data in Canada. The study's
              methods can be applied to estimate workers' exposures to other
              pesticides within the agricultural industry.",
  journal  = "Ann Work Expo Health",
  volume   =  65,
  number   =  4,
  pages    = "377--389",
  month    =  may,
  year     =  2021,
  url      = "http://dx.doi.org/10.1093/annweh/wxaa109",
  keywords = "2, 4-D; agriculture; chlorothalonil; glyphosate; occupational
              exposure; pesticides;herbicides and health",
  language = "en",
  issn     = "2398-7316, 2398-7308",
  pmid     = "33336237",
  doi      = "10.1093/annweh/wxaa109"
}

@ARTICLE{Silva-Madera2021-cx,
  title     = "Pesticide Contamination in Drinking and Surface Water in the
               Cienega, Jalisco, Mexico",
  author    = "Silva-Madera, R J and Salazar-Flores, J and Peregrina-Lucano, A
               A and Mendoza-Michel, J and Ceja-G{\'a}lvez, H R and
               Rojas-Bravo, D and Reyna-Villela, M Z and Torres-S{\'a}nchez, E
               D",
  abstract  = "Sixty percent of global agricultural production depends on the
               use of pesticides, despite their adverse effects on human health
               and the ecosystem. In Mexico, the application of these products
               has been exacerbated, including pesticides already banned in
               other countries. The objective of this study was to determine
               pesticide concentrations in samples of water purification plants
               and surface water from the Cienega area of Jalisco, Mexico. A
               survey of 119 farmers with occupational exposure to pesticides
               was carried out in order to obtain information on the most
               frequently used pesticides. Subsequently, 51 samples taken at 7
               different sites were analyzed using liquid chromatography and
               mass-mass spectrometry. The most frequently used pesticides were
               organophosphates (28.87\%), pyrethroids (12.89\%), and the
               herbicide paraquat (31.95\%). In surface water, the prevalent
               pesticides were glyphosate (56.96--510.46 ppb) and malathion
               (311.76--863.49 ppb). Glyphosate levels were higher than the
               limits acceptable in daily water intake in Cumuato. Malathion
               levels exceeded the limits permissible by EPA in water
               purification plants in urban public establishments (100 ppb for
               children, and 200 ppb for adults). In addition, a
               multidimensional scaling analysis showed that the sampled sites
               could be grouped into 2 different bodies of water, based on
               similarities in their glyphosate concentrations (stress =
               0.005), while the concentrations of malathion were heterogeneous
               (stress = 0.001). \copyright{} 2021, The Author(s).",
  journal   = "Water Air Soil Pollut.",
  publisher = "Springer Science and Business Media Deutschland GmbH",
  volume    =  232,
  number    =  2,
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099950709&doi=10.1007%2fs11270-021-04990-y&partnerID=40&md5=321232d9101012746bb00cd7019ec677",
  keywords  = "Cienega-Jalisco; HPLC-MS/MS; Pesticides; Surface water; Water
               purification plants; Agricultural robots; Agriculture;
               Herbicides; Liquid chromatography; Mass spectrometry; Potable
               water; Purification; Water treatment plants; Adverse effect;
               Agricultural productions; Herbicide paraquat; Multidimensional
               scaling analysis; Occupational exposure; Pesticide
               concentrations; Pesticide contaminations; Water purification
               plants; Surface waters; drinking water; glyphosate; malathion;
               organophosphate; paraquat; pesticide; pyrethroid; concentration
               (composition); drinking water; glyphosate; liquid
               chromatography; malathion; mass spectrometry; occupational
               exposure; surface water; water pollution; water treatment plant;
               agricultural worker; Article; concentration (parameter); fluid
               intake; human; Jalisco; liquid chromatography-mass spectrometry;
               occupational exposure; surface water hydrology; urban area;
               water contamination; water management; water sampling; Jalisco;
               Mexico [North America];herbicides and health",
  issn      = "0049-6979",
  doi       = "10.1007/s11270-021-04990-y"
}

@ARTICLE{Pedroso2021-bk,
  title    = "Cancer and occupational exposure to pesticides: a bibliometric
              study of the past 10 years",
  author   = "Pedroso, Thays Millena Alves and Benvindo-Souza, Marcelino and de
              Ara{\'u}jo Nascimento, Felipe and Woch, J{\'u}lia and Dos Reis,
              Fabiana Gon{\c c}alves and de Melo E Silva, Daniela",
  abstract = "Occupational exposure to pesticides has been identified as a
              major trigger of the development of cancer. Pesticides can cause
              intoxication in the individuals who manipulate them through
              either inhalation, ingestion, or dermal contact. Given this, we
              investigated the association between the incidence of cancer and
              occupational exposure to pesticides through a bibliometric
              analysis of the studies published between 2011 and 2020, based on
              62 papers selected from the Scopus database. The results
              indicated an exponential increase in the number of studies
              published over the past decade, with most of the research being
              conducted in the USA, France, India, and Brazil, although a
              further 17 nations were also involved in the research on the
              association between cancer and pesticides. The principal classes
              of pesticides investigated in relation to their role in
              intoxication and cancer were insecticides, herbicides, and
              fungicides. The types of cancer reported most frequently were
              multiple myeloma, bladder cancer, non-Hodgkin's lymphoma,
              prostate cancer, leukemia, and breast cancer. Despite the known
              association between pesticides and cancer, studies are still
              relatively scarce in comparison with the global scale of the use
              of these xenobiotic substances, which is related to the
              increasing demand for agricultural products throughout the world.",
  journal  = "Environ. Sci. Pollut. Res. Int.",
  month    =  oct,
  year     =  2021,
  url      = "http://dx.doi.org/10.1007/s11356-021-17031-2",
  keywords = "Agriculture; Cancer; DNA; Diseases; Farm workers; Health;
              Pesticides;herbicides and health",
  language = "en",
  issn     = "0944-1344, 1614-7499",
  pmid     = "34668133",
  doi      = "10.1007/s11356-021-17031-2",
  pmc      = "PMC8525621"
}

@ARTICLE{Macfarlane2008-am,
  title    = "Training and other predictors of personal protective equipment
              use in Australian grain farmers using pesticides",
  author   = "Macfarlane, E and Chapman, A and Benke, G and Meaklim, J and Sim,
              M and McNeil, J",
  abstract = "OBJECTIVES: To investigate patterns of use of personal protective
              equipment (PPE) to reduce pesticide exposure in a sample of
              Australian farmers and also to assess the influence of possible
              predictive factors. METHODS: A cross-sectional survey of 1102
              farmers recruited through the Victorian Farmers Federation (VFF)
              was conducted. A written questionnaire was filled out by
              participants at VFF meetings attended by a visiting research
              assistant. Participants answered questions about frequency of
              pesticide use and PPE items they usually used when doing two
              different pesticide-related tasks, mixing and application, of
              each of four classes of pesticides. They also answered questions
              about personal characteristics, farm characteristics, farming
              activities, career and health. RESULTS: Nearly all surveyed
              farmers had ever used pesticides, and over 87\% had used
              Herbicides or Animal Health Products in the previous 12 months.
              Non-use of PPE was frequently reported, with up to 10-40\% of
              farmers routinely using no PPE at all when using pesticides.
              Across all pesticide classes, PPE use was higher for pesticide
              mixing than for application. In multivariate analyses PPE use
              appeared to be most strongly associated with younger age and farm
              chemical training. CONCLUSIONS: PPE use across all pesticide
              classes was poor, indicating the possibility of clinically
              significant pesticide exposure in many farmers. Given that PPE
              use was found to be associated with farm chemical training, the
              authors suggest that training is likely to be an important
              intervention for reducing farmers' pesticide exposure. Poor
              uptake of farm chemical training by farmers and the aging farming
              workforce are causes for concern in the light of these findings.",
  journal  = "Occup. Environ. Med.",
  volume   =  65,
  number   =  2,
  pages    = "141--146",
  month    =  feb,
  year     =  2008,
  url      = "http://dx.doi.org/10.1136/oem.2007.034843",
  language = "en",
  issn     = "1351-0711, 1470-7926",
  pmid     = "17704194",
  doi      = "10.1136/oem.2007.034843"
}

@MISC{US_Bureau_of_Labor_Statistics2021-yi,
  title        = "Occupational Employment and Wages in Yuma --- May 2020 :
                  Western Information Office : {U.S}. Bureau of Labor
                  Statistics",
  booktitle    = "{U.S}. Bureau of Labor Statistics",
  author       = "{US Bureau of Labor Statistics}",
  abstract     = "Workers in the Yuma, AZ Metropolitan Statistical Area had an
                  average (mean) hourly wage of $20.75 in May 2020, 23 percent
                  below the nationwide average of $27.07.",
  month        =  jun,
  year         =  2021,
  url          = "https://www.bls.gov/regions/west/news-release/occupationalemploymentandwages_yuma.htm",
  howpublished = "\url{https://www.bls.gov/regions/west/news-release/occupationalemploymentandwages_yuma.htm}",
  note         = "Accessed: 2022-1-28",
  keywords     = "herbicides and health;field labor",
  language     = "en"
}

@MISC{noauthor_undated-tt,
  title       = "pypylon: The official python wrapper for the pylon Camera
                 Software Suite",
  abstract    = "The official python wrapper for the pylon Camera Software
                 Suite - basler/pypylon: The official python wrapper for the
                 pylon Camera Software Suite",
  institution = "Github",
  url         = "https://github.com/basler/pypylon",
  language    = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Wikipedia_contributors2022-qd,
  title        = "{YCbCr}",
  booktitle    = "Wikipedia, The Free Encyclopedia",
  author       = "{Wikipedia contributors}",
  abstract     = "YCbCr, Y′CbCr, or Y Pb/Cb Pr/Cr, also written as YCBCR or
                  Y′CBCR, is a family of color spaces used as a part of the
                  color image pipeline in video and digital photography
                  systems. Y′ is the luma component and CB and CR are the
                  blue-difference and red-difference chroma components. Y′
                  (with prime) is distinguished from Y, which is luminance,
                  meaning that light intensity is nonlinearly encoded based on
                  gamma corrected RGB primaries.",
  month        =  jan,
  year         =  2022,
  url          = "https://en.wikipedia.org/w/index.php?title=YCbCr&oldid=1069029896",
  howpublished = "\url{https://en.wikipedia.org/w/index.php?title=YCbCr&oldid=1069029896}",
  note         = "Accessed: NA-NA-NA"
}

@MISC{Siemens2021-vn,
  author       = "Siemens, Mark",
  editor       = "McGinnis, Evan",
  abstract     = "Labor costs in Yuma, AZ",
  month        =  aug,
  year         =  2021,
  howpublished = "personal communication"
}
