@ARTICLE{Zualkernan2023-cn,
  title     = "Machine Learning for Precision Agriculture Using Imagery from
               Unmanned Aerial Vehicles ({UAVs}): A Survey",
  author    = "Zualkernan, I and Abuhani, D A and Hussain, M H and Khan, J and
               ElMohandes, M",
  journal   = "Drones",
  publisher = "MDPI",
  volume    =  7,
  number    =  6,
  abstract  = "Unmanned aerial vehicles (UAVs) are increasingly being integrated
               into the domain of precision agriculture, revolutionizing the
               agricultural landscape. Specifically, UAVs are being used in
               conjunction with machine learning techniques to solve a variety
               of complex agricultural problems. This paper provides a careful
               survey of more than 70 studies that have applied machine learning
               techniques utilizing UAV imagery to solve agricultural problems.
               The survey examines the models employed, their applications, and
               their performance, spanning a wide range of agricultural tasks,
               including crop classification, crop and weed detection, cropland
               mapping, and field segmentation. Comparisons are made among
               supervised, semi-supervised, and unsupervised machine learning
               approaches, including traditional machine learning classifiers,
               convolutional neural networks (CNNs), single-stage detectors,
               two-stage detectors, and transformers. Lastly, future
               advancements and prospects for UAV utilization in precision
               agriculture are highlighted and discussed. The general findings
               of the paper demonstrate that, for simple classification
               problems, traditional machine learning techniques, CNNs, and
               transformers can be used, with CNNs being the optimal choice. For
               segmentation tasks, UNETs are by far the preferred approach. For
               detection tasks, two-stage detectors delivered the best
               performance. On the other hand, for dataset augmentation and
               enhancement, generative adversarial networks (GANs) were the most
               popular choice. © 2023 by the authors.",
  year      =  2023,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163795263&doi=10.3390%2fdrones7060382&partnerID=40&md5=8a522e9913af6b11667f581422f6bcf5",
  keywords  = "agriculture; CNN; deep learning; GANs; machine learning;
               precision farming; transformers; UAVs",
  doi       = "10.3390/drones7060382",
  issn      = "2504-446X"
}

@ARTICLE{Kwak2019-ta,
  title     = "Impact of texture information on crop classification with machine
               learning and {UAV} images",
  author    = "Kwak, G-H and Park, N-W",
  journal   = "Applied Sciences (Switzerland)",
  publisher = "MDPI AG",
  volume    =  9,
  number    =  4,
  abstract  = "Unmanned aerial vehicle (UAV) images that can provide thematic
               information at much higher spatial and temporal resolutions than
               satellite images have great potential in crop classification. Due
               to the ultra-high spatial resolution of UAV images, spatial
               contextual information such as texture is often used for crop
               classification. From a data availability viewpoint, it is not
               always possible to acquire time-series UAV images due to limited
               accessibility to the study area. Thus, it is necessary to improve
               classification performance for situations when a single or
               minimum number of UAV images are available for crop
               classification. In this study, we investigate the potential of
               gray-level co-occurrence matrix (GLCM)-based texture information
               for crop classification with time-series UAV images and machine
               learning classifiers including random forest and support vector
               machine. In particular, the impact of combining texture and
               spectral information on the classification performance is
               evaluated for cases that use only one UAV image or multi-temporal
               images as input. A case study of crop classification in Anbandegi
               of Korea was conducted for the above comparisons. The best
               classification accuracy was achieved when multi-temporal UAV
               images which can fully account for the growth cycles of crops
               were combined with GLCM-based texture features. However, the
               impact of the utilization of texture information was not
               significant. In contrast, when one August UAV image was used for
               crop classification, the utilization of texture information
               significantly affected the classification performance.
               Classification using texture features extracted from GLCM with
               larger kernel size significantly improved classification
               accuracy, an improvement of 7.72\%p in overall accuracy for the
               support vector machine classifier, compared with classification
               based solely on spectral information. These results indicate the
               usefulness of texture information for classification of
               ultra-high-spatial-resolution UAV images, particularly when
               acquisition of time-series UAV images is difficult and only one
               UAV image is used for crop classification. © 2019 by the authors.",
  year      =  2019,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061603571&doi=10.3390%2fapp9040643&partnerID=40&md5=222f4c0c7b4a2cdac09ffb038d9df819",
  keywords  = "Crop; Gray-level co-occurrence matrix; Machine learning; Texture;
               Unmanned aerial vehicle",
  doi       = "10.3390/app9040643",
  issn      = "2076-3417"
}

@ARTICLE{Rozenberg2023-bh,
  title     = "Using a low-cost unmanned aerial vehicle for mapping giant
               smutgrass in bahiagrass pastures",
  author    = "Rozenberg, G and Dias, J L C S and Anderson, W M and Sellers, B A
               and Boughton, R K and Piccolo, M B and Blank, L",
  journal   = "Precis. Agric.",
  publisher = "Springer",
  volume    =  24,
  number    =  3,
  pages     = "971--985",
  abstract  = "Grasses within the Sporobolus genus have been classified as
               problematic weeds of pastures in many countries. In Florida,
               giant smutgrass is the most common and troublesome weedy
               Sporobolus grass. The use of unmanned aerial vehicles (UAVs) for
               mapping, combined with site-specific weed control has the
               potential to optimize giant smutgrass management and decrease the
               use of herbicides. In this research, RGB ortho-mosaics captured
               from a simple UAV were examined to detect and map giant smutgrass
               in bahiagrass pastures in Florida. Two sampling dates (May and
               August) and four flight altitudes (50, 75, 100 and 120 m) were
               investigated for optimal classification accuracy. Spectral,
               texture and combined (spectral and texture) analyses served as
               the basis for supervised (random forest) and unsupervised (k
               means) classifications. Giant smutgrass cover was successfully
               mapped and best evaluated by integrating the combined analysis
               with supervised algorithm, reaching a correlation of 0.91 with
               the ground truth cover. Flight altitude had a negative
               relationship with giant smutgrass detection; however,
               satisfactory results were also obtained from 120 m with an
               average correlation of 0.76 when using combined supervised
               classification. Additionally, both sampling dates were found
               adequate for giant smutgrass mapping. These findings demonstrate
               that low-cost UAV platforms can successfully be used to generate
               accurate giant smutgrass infestations maps, allowing for
               site-specific management in bahiagrass pastures. Results from
               this work also broaden the general knowledge on the impacts that
               different settings and parameters (e.g. time of the year,
               altitude and image-analyses methods) can have on aerial image
               classification. © 2022, The Author(s), under exclusive licence to
               Springer Science+Business Media, LLC, part of Springer Nature.",
  year      =  2023,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145191550&doi=10.1007%2fs11119-022-09982-4&partnerID=40&md5=d0972489d74210950d1a440020b9c8c2",
  keywords  = "Classification; Drone; Site-specific weed management; Weed
               detection; aerial photograph; interspecific competition; mapping
               method; pasture; pesticide resistance; remote sensing; weed
               control; Florida [United States]",
  doi       = "10.1007/s11119-022-09982-4",
  issn      = "1385-2256"
}

@MISC{USDA2023-wb,
  title        = "{USDA}/{NASS} 2023 State Agriculture Overview for Arizona",
  author       = "{USDA}",
  year         =  2023,
  howpublished = "\url{https://www.nass.usda.gov/Quick\_Stats/Ag\_Overview/stateOverview.php?state=ARIZONA}",
  note         = "Accessed: 2025--",
  language     = "en"
}

@ARTICLE{Basavarajeshwari2018-ri,
  title     = "A Survey on weed Detection using Image Processing",
  author    = "{Basavarajeshwari} and Madhavanavar, S P",
  journal   = "International Journal of Engineering Research \& Technology",
  publisher = "IJERT-International Journal of Engineering Research \& Technology",
  volume    =  5,
  number    =  6,
  abstract  = "A Survey on weed Detection using Image Processing - written by
               Basavarajeshwari, Prof. S. P. Madhavanavar published on
               2018/04/24 download full article with reference data and
               citations",
  month     =  apr,
  year      =  2018,
  url       = "https://www.ijert.org/research/a-survey-on-weed-detection-using-image-processing-IJERTCONV5IS06011.pdf",
  issn      = "2278-0181"
}

@ARTICLE{Hamuda2016-dw,
  title     = "A survey of image processing techniques for plant extraction and
               segmentation in the field",
  author    = "Hamuda, E and Glavin, M and Jones, E",
  journal   = "Comput. Electron. Agric.",
  publisher = "Elsevier B.V.",
  volume    =  125,
  pages     = "184--199",
  abstract  = "In this review, we present a comprehensive and critical survey on
               image-based plant segmentation techniques. In this context,
               ``segmentation'' refers to the process of classifying an image
               into plant and non-plant pixels. Good performance in this process
               is crucial for further analysis of the plant such as plant
               classification (i.e. identifying the plant as either crop or
               weed), and effective action based on this analysis, e.g.
               precision application of herbicides in smart agriculture
               applications. The survey briefly discusses pre-processing of
               images, before focusing on segmentation. The segmentation stage
               involves the segmentation of plant against the background
               (identifying plant from a background of soil and other residues).
               Three primary plant extraction algorithms, namely, (i) colour
               index-based segmentation, (ii) threshold-based segmentation,
               (iii) learning-based segmentation are discussed. Based on its
               prevalence in the literature, this review focuses in particular
               on colour index-based approaches. Therefore, a detailed
               discussion of the segmentation performance of colour index-based
               approaches is presented, based on studies from the literature
               conducted in the recent past, particularly from 2008 to 2015.
               Finally, we identify the challenges and some opportunities for
               future developments in this space. © 2016 Elsevier B.V.",
  year      =  2016,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969174961&doi=10.1016%2fj.compag.2016.04.024&partnerID=40&md5=f2f1093d3d7096ea81b8da16a8110f4d",
  keywords  = "Colour index-based segmentation; Learning-based segmentation;
               Plant extraction; Plant pixels; Segmentation quality;
               Threshold-based segmentation; Color; Extraction; Image
               segmentation; Pixels; Surveys; Image processing technique;
               Learning-based segmentation; Plant classification; Plant
               extraction; Precision applications; Segmentation performance;
               Segmentation quality; Segmentation techniques; Image processing;
               algorithm; color; crop processing; field survey; herbicide; image
               processing; pixel; plant extract; precision; segmentation;
               threshold",
  doi       = "10.1016/j.compag.2016.04.024",
  issn      = "0168-1699"
}

@INPROCEEDINGS{Dian_Bah2017-kd,
  title     = "Weeds detection in {UAV} imagery using {SLIC} and the hough
               transform",
  author    = "Dian Bah, M and Hafiane, Adel and Canals, Raphael",
  booktitle = "2017 Seventh International Conference on Image Processing Theory,
               Tools and Applications (IPTA)",
  publisher = "IEEE",
  pages     = "1--6",
  abstract  = "Traditional weeds controlling tended to be spraying herbicides in
               all the fields. Such method not only requires huge quantities of
               herbicides but impact environment and humans health. In this
               paper, we propose a new method of crop/weeds discrimination using
               imagery provided by an unmanned aerial vehicle (UAV). This method
               is based on the vegetation skeleton, the Hough transform and the
               spatial relationship of superpixels created by the simple linear
               iterative clustering (SLIC). The combination of the spatial
               relationship of superpixels and their positions in the detected
               crop lines allows to detect intraline weeds. Our method shows its
               robustness in presence of weed patches close to crop lines as
               well as for the detection of crop lines as for weed detection.",
  month     =  nov,
  year      =  2017,
  url       = "http://dx.doi.org/10.1109/IPTA.2017.8310102",
  doi       = "10.1109/IPTA.2017.8310102",
  isbn      = "9781538618424,9781538618417",
  issn      = "2154-512X"
}

@ARTICLE{Illingworth1988-nw,
  title    = "A survey of the hough transform",
  author   = "Illingworth, J and Kittler, J",
  journal  = "Computer Vision, Graphics, and Image Processing",
  volume   =  44,
  number   =  1,
  pages    = "87--116",
  abstract = "We present a comprehensive review of the Hough transform, HT, in
              image processing and computer vision. It has long been recognized
              as a technique of almost unique promise for shape and motion
              analysis in images containing noisy, missing, and extraneous data
              but its adoption has been slow due to its computational and
              storage complexity and the lack of a detailed understanding of its
              properties. However, in recent years much progress has been made
              in these areas. In this review we discuss ideas for the efficient
              implementation of the HT and present results on the analytic and
              empirical performance of various methods. We also report the
              relationship of Hough methods and other transforms and consider
              applications in which the HT has been used. It seems likely that
              the HT will be an increasingly used technique and we hope that
              this survey will provide a useful guide to quickly acquaint
              researchers with the main literature in this research area.",
  month    =  oct,
  year     =  1988,
  url      = "https://www.sciencedirect.com/science/article/pii/S0734189X88800331",
  doi      = "10.1016/S0734-189X(88)80033-1",
  issn     = "0734-189X"
}

@INPROCEEDINGS{Girshick2014-mx,
  title     = "Rich feature hierarchies for accurate object detection and
               semantic segmentation",
  author    = "Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik,
               Jitendra",
  booktitle = "2014 IEEE Conference on Computer Vision and Pattern Recognition",
  publisher = "IEEE",
  abstract  = "Elsevier’s Scopus, the largest abstract and citation database of
               peer-reviewed literature. Search and access research from the
               science, technology, medicine, social sciences and arts and
               humanities fields.",
  month     =  jun,
  year      =  2014,
  url       = "http://dx.doi.org/10.1109/CVPR.2014.81",
  doi       = "10.1109/cvpr.2014.81",
  isbn      =  9781479951185,
  language  = "en"
}

@INPROCEEDINGS{Redmon2016-dz,
  title     = "You only look once: Unified, real-time object detection",
  author    = "Redmon, Joseph and Divvala, Santosh and Girshick, Ross and
               Farhadi, Ali",
  booktitle = "2016 IEEE Conference on Computer Vision and Pattern Recognition
               (CVPR)",
  publisher = "IEEE",
  abstract  = "Elsevier’s Scopus, the largest abstract and citation database of
               peer-reviewed literature. Search and access research from the
               science, technology, medicine, social sciences and arts and
               humanities fields.",
  month     =  jun,
  year      =  2016,
  url       = "http://dx.doi.org/10.1109/CVPR.2016.91",
  doi       = "10.1109/cvpr.2016.91",
  isbn      =  9781467388511,
  language  = "en"
}

@MISC{noauthor_2022-cz,
  title        = "{YIQ}",
  booktitle    = "Wikipedia",
  month        =  dec,
  year         =  2022,
  howpublished = "\url{https://en.wikipedia.org/wiki/YIQ}"
}

@BOOK{Muller2016-ui,
  title     = "Introduction to Machine Learning with Python",
  author    = "Müller, Andreas C and Guido, Sarah",
  publisher = "O'Reilly Media",
  edition   =  1,
  month     =  nov,
  year      =  2016,
  isbn      =  9781449369415
}

@BOOK{Perkins1997-jg,
  title     = "Understanding {SNMP} {MIBs}",
  author    = "Perkins, David",
  publisher = "Prentice Hall PTR",
  address   = "Upper Saddle River, N.J.",
  year      =  1997,
  url       = "https://arizona-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=01UA_ALMA21428506670003843&context=L&vid=01UA&lang=en_US&search_scope=Everything&adaptor=Local%20Search%20Engine&tab=default_tab&query=any,contains,mcginnis,%20evan",
  keywords  = "Simple Network Management Protocol (Computer network
               protocol);Computer networks–Specifications;Computer
               networks–Management",
  isbn      =  9780134377087
}

@ARTICLE{Woebbecke1995-yg,
  title     = "Color indices for weed identification under various soil,
               residue, and lighting conditions",
  author    = "Woebbecke, D M and Meyer, G E and Von Bargen, K and Mortensen, D
               A",
  journal   = "Trans. ASAE",
  publisher = "ASAE",
  address   = "St. Joseph, MI, United States",
  volume    =  38,
  number    =  1,
  pages     = "259--269",
  abstract  = "Color slide images of weeds among various soils and residues were
               digitized and analyzed for red, green, and blue (RGB) color
               content. Red, green, and blue chromatic coordinates (rgb) of
               plants were very different from those of background soils and
               residue. To distinguish living plant material from a nonplant
               background, several indices of chromatic coordinates were
               studied, tested, and were successful in identifying weeds. The
               indices included r-g, g-b, (g-b)||r-g|, and 2g-r-b. A modified
               hue was also used to distinguish weeds from non-plant surfaces.
               The modified hue, 2g-r-b index, and the green chromatic
               coordinate distinguished weeds from a nonplant background (0.05
               level of significance) better than other indices. However, the
               modified hue was the most computationally intense. These indices
               worked well for both nonshaded and shaded sunlit conditions.
               These indices could be used for sensor design for detecting weeds
               for spot spraying control.",
  year      =  1995,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029110322&partnerID=40&md5=d3430f82764dc64892eb6dc77186596e",
  keywords  = "Agricultural machinery; Color image processing; Design; Sensors;
               Soils; Spraying; Color indices; Lighting conditions; Modified
               hues; Residue; Sensors design; Spot spraying control; Sprayers;
               Weed identification; Plants (botany)",
  issn      = "0001-2351"
}

@INPROCEEDINGS{Meyer1999-zn,
  title     = "Machine vision detection parameters for plant species
               identification",
  author    = "Meyer, George E and Hindman, Timothy W and Laksmi, Koppolu",
  booktitle = "Proceedings of SPIE",
  publisher = "SPIE",
  address   = "Bellingham WA",
  volume    =  3543,
  pages     = "327--335",
  abstract  = "Machine vision based on classical image processing techniques has
               the potential to be a useful tool for plant detection and
               identification. Plant identification is needed for weed
               detection, herbicide application or other efficient chemical spot
               spraying operations. The key to successful detection and
               identification of plants as species types is the segmentation of
               plants form background pixel regions. In particular, it would be
               beneficial to segment individual leaves form tops of canopies as
               well. The segmentation process yields an edge or binary image
               which contains shape feature information. Results indicate that
               red-green-blue formats might provide the best segmentation
               criteria, based on models of human color perception. The binary
               image can be also used as a template to investigate textural
               features of the plant pixel region, using gray image
               co-occurrence matrices. Texture features considers leaf venation,
               colors, or additional canopy structure that might be used to
               identify various type of grasses or broadleaf plants.",
  month     =  jan,
  year      =  1999,
  url       = "http://dx.doi.org/10.1117/12.336896",
  keywords  = "Biological and medical sciences;Chemical control;Color image
               processing;Feature extraction;Fundamental and applied biological
               sciences. Psychology;Herbicides;Image analysis;Image
               segmentation;Mathematical models;Matrix algebra;Parasitic plants.
               Weeds;Phytopathology. Animal pests. Plant and forest
               protection;Plants (botany);Vegetation;Weed control;Weeds",
  doi       = "10.1117/12.336896",
  isbn      =  9780819431554,
  issn      = "0277-786X"
}

@PHDTHESIS{Neto2004-od,
  title    = "A combined statistical-soft computing approach for classification
              and mapping weed species in minimum -tillage systems",
  author   = "Neto, Joao Camargo",
  abstract = "This dissertation describes a combined statistical-soft computing
              approach for classifying and mapping weeds species using color
              images in minimum-tillage systems. A new unsupervised separation
              index (ExGExR) is introduced to distinguish plant canopies from
              different soil/residue backgrounds. Results showed that ExGExR was
              significantly improved for all species and all three weeks over
              the previously published excess green (ExG). ExGExR performed very
              well for separating both pigweed and velvetleaf from bare soil and
              corn stalk backgrounds during the first and second week after crop
              emergence. A new algorithm for individual leaf extraction was
              introduced based on fuzzy color clustering and genetic algorithm.
              Images of green canopies were segmented into fragments of
              potential leaf regions using clustering algorithm. Fragments were
              then reassembled into individual leaves using genetic optimization
              algorithm. The algorithm performance was evaluated by comparing
              the actual number leaves automatically extracted with the number
              of potential leaves observed visually. An overall performance of
              75\% for leaves correctly extracted was obtained. Elliptic Fourier
              method was next tested for characterizing the shape of hand
              selected young soybean, sunflower, red root pigweed, and
              velvetleaf leaves. Discriminant analysis of these shape
              coefficients suggested that the third week after emergence was the
              best time to identify plant species with a correct classification
              average of 89.4\%. When leaves from the second and third week were
              analyzed a correct classification average of 89.2\% was reached.
              An unsupervised method for plant species identification was
              finally tested. Elliptic Fourier descriptors not only provided
              leaflet shape information, but also a lamina boundary template,
              controlling where textural features were computed. Each lamina
              shape extracted was corrected such that all leaflets had the same
              orientation for texture extraction. SAS PROC DISCRIM procedure was
              performed to build a species classification model using selected
              Fourier coefficients and local homogeneity and entropy texture
              features. An overall success rate of 86\% was obtained for plant
              species classification.",
  year     =  2004,
  url      = "https://digitalcommons.unl.edu/dissertations/AAI3147135/",
  school   = "University of Nebraska - Lincoln"
}

@INPROCEEDINGS{Kataoka2003-pu,
  title     = "Crop growth estimation system using machine vision",
  author    = "Kataoka, T and Kaneko, T and Okamoto, H and Hata, S",
  booktitle = "Proceedings 2003 IEEE/ASME International Conference on Advanced
               Intelligent Mechatronics (AIM 2003)",
  publisher = "IEEE",
  volume    =  2,
  pages     = "b1079--b1083 vol.2",
  abstract  = "According to the philosophy of Precision Farming, the status of
               crops during their growing stages is important information for
               crop cultivation tasks and management. The system which was
               developed in this research involves the vegetation cover area of
               plant being determined by the vision system and the image
               processing technique, and the crop status, i.e., the plant
               height, the leaf length, and the dry matter, being estimated with
               the specific functions. The specific functions which show the
               relationship between the vegetation cover area of plants and the
               measured actual plant dimensions were analyzed using a growth
               curve (the Gompertz curve) and an exponential function. The
               Gompertz curve was used for the estimation of the dry mass of the
               plants. For the leaf length and the plant height, the exponential
               function worked well compared to the growth curve. Based on the
               results, the crop growing status could be estimated using crop
               images and calculated equations.",
  year      =  2003,
  url       = "https://ieeexplore.ieee.org/document/1225492",
  keywords  = "Agriculture;Area measurement;Crops;Equations;Image
               processing;Lenses;Machine vision;Sugar
               industry;Testing;Vegetation mapping",
  doi       = "10.1109/AIM.2003.1225492",
  isbn      =  9780780377592
}

@ARTICLE{Hunt2005-tz,
  title    = "Evaluation of Digital Photography from Model Aircraft for Remote
              Sensing of Crop Biomass and Nitrogen Status",
  author   = "Hunt, E Raymond and Cavigelli, Michel and Daughtry, Craig S T and
              Mcmurtrey, James E and Walthall, Charles L",
  journal  = "Precis. Agric.",
  volume   =  6,
  number   =  4,
  pages    = "359--378",
  abstract = "Remote sensing is a key technology for precision agriculture to
              assess actual crop conditions. Commercial, high-spatial-resolution
              imagery from aircraft and satellites are expensive so the costs
              may outweigh the benefits of the information. Hobbyists have been
              acquiring aerial photography from radio-controlled model aircraft;
              we evaluated these very-low-cost, very high-resolution digital
              photography for use in estimating nutrient status of corn and crop
              biomass of corn, alfalfa, and soybeans. Based on conclusions from
              previous work, we optimized an aerobatic model aircraft for
              acquiring pictures using a consumer-oriented digital camera.
              Colored tarpaulins were used to calibrate the images; there were
              large differences in digital number (DN) for the same reflectance
              because of differences in the exposure settings selected by the
              digital camera. To account for differences in exposure a
              Normalized Green–Red Difference Index [(NGRDI = (Green DN − Red
              DN)/(Green DN + Red DN)] was used; this index was linearly related
              to the normalized difference of the green and red reflectances,
              respectively. For soybeans, alfalfa and corn, dry biomass from
              zero to 120 g m−2 was linearly correlated to NGRDI, but for
              biomass greater than 150 g m−2 in corn and soybean, NGRDI did not
              increase further. In a fertilization experiment with corn, NGRDI
              did not show differences in nitrogen status, even though areas of
              low nitrogen status were clearly visible on late-season digital
              photographs. Simulations from the SAIL (Scattering of Arbitrarily
              Inclined Leaves) canopy radiative transfer model verified that
              NGRDI would be sensitive to biomass before canopy closure and that
              variations in leaf chlorophyll concentration would not be
              detectable. There are many advantages of model aircraft platforms
              for precision agriculture; currently, the imagery is best visually
              interpreted. Automated analysis of within-field variability
              requires more work on sensors that can be used with model aircraft
              platforms.",
  month    =  aug,
  year     =  2005,
  url      = "https://doi.org/10.1007/s11119-005-2324-5",
  doi      = "10.1007/s11119-005-2324-5",
  issn     = "1385-2256,1573-1618"
}

@ARTICLE{Hague2006-da,
  title    = "Automated Crop and Weed Monitoring in Widely Spaced Cereals",
  author   = "Hague, T and Tillett, N D and Wheeler, H",
  journal  = "Precis. Agric.",
  volume   =  7,
  number   =  1,
  pages    = "21--32",
  abstract = "An approach is described for automatic assessment of crop and weed
              area in images of widely spaced (0.25 m) cereal crops, captured
              from a tractor mounted camera. A form of vegetative index, which
              is invariant over the range of natural daylight illumination, was
              computed from the red, green and blue channels of a conventional
              CCD camera. The transformed image can be segmented into soil and
              vegetative components using a single fixed threshold. A previously
              reported algorithm was applied to robustly locate the crop rows.
              Assessment zones were automatically positioned; for crop growth
              directly over the crop rows, and for weed growth between the rows.
              The proportion of crop and weed pixels counted was compared with a
              manual assessment of area density on the basis of high resolution
              plan view photographs of the same area; this was performed for
              views with a range of crop and weed levels. The correlation of the
              manual and automatic measures was examined, and used to obtain a
              calibration for the automatic approach. The results of mapping of
              a small field, at two times, are presented. The results of the
              automated mapping appear to be consistent with manual assessment.",
  month    =  mar,
  year     =  2006,
  url      = "https://doi.org/10.1007/s11119-005-6787-1",
  doi      = "10.1007/s11119-005-6787-1",
  issn     = "1385-2256,1573-1618"
}

@ARTICLE{Burgos-Artizzu2011-od,
  title    = "Real-time image processing for crop/weed discrimination in maize
              fields",
  author   = "Burgos-Artizzu, Xavier P and Ribeiro, Angela and Guijarro, Maria
              and Pajares, Gonzalo",
  journal  = "Comput. Electron. Agric.",
  volume   =  75,
  number   =  2,
  pages    = "337--346",
  abstract = "This paper presents a computer vision system that successfully
              discriminates between weed patches and crop rows under
              uncontrolled lighting in real-time. The system consists of two
              independent subsystems, a fast image processing delivering results
              in real-time (Fast Image Processing, FIP), and a slower and more
              accurate processing (Robust Crop Row Detection, RCRD) that is used
              to correct the first subsystem’s mistakes. This combination
              produces a system that achieves very good results under a wide
              variety of conditions. Tested on several maize videos taken of
              different fields and during different years, the system
              successfully detects an average of 95\% of weeds and 80\% of crops
              under different illumination, soil humidity and weed/crop growth
              conditions. Moreover, the system has been shown to produce
              acceptable results even under very difficult conditions, such as
              in the presence of dramatic sowing errors or abrupt camera
              movements. The computer vision system has been developed for
              integration into a treatment system because the ideal setup for
              any weed sprayer system would include a tool that could provide
              information on the weeds and crops present at each point in
              real-time, while the tractor mounting the spraying bar is moving.",
  month    =  feb,
  year     =  2011,
  url      = "https://www.sciencedirect.com/science/article/pii/S0168169910002620",
  keywords = "Computer vision; Precision Agriculture; Weed detection; Real-time
              image processing",
  doi      = "10.1016/j.compag.2010.12.011",
  issn     = "0168-1699"
}

@ARTICLE{Guerrero2012-zi,
  title    = "Support Vector Machines for crop/weeds identification in maize
              fields",
  author   = "Guerrero, J M and Pajares, G and Montalvo, M and Romeo, J and
              Guijarro, M",
  journal  = "Expert Syst. Appl.",
  volume   =  39,
  number   =  12,
  pages    = "11149--11155",
  abstract = "In Precision Agriculture (PA) automatic image segmentation for
              plant identification is an important issue to be addressed.
              Emerging technologies in optical imaging sensors play an important
              role in PA. In maize fields, site-specific treatments, with
              chemical products or mechanical manipulations, are applied for
              weeds elimination. Maize is an irrigated crop, also unprotected
              from rainfall. After a strong rain, soil materials (particularly
              clays) mixed with water impregnate the vegetative cover. The green
              spectral component associated to the plants is masked by the
              dominant red spectral component coming from soil materials. This
              makes methods based on the greenness identification fail under
              such situations. We propose a new method based on Support Vector
              Machines for identifying plants with green spectral components
              masked and unmasked. The method is also valid for post-treatment
              evaluation, where loss of greenness in weeds is identified with
              the effectiveness of the treatment and in crops with damage or
              masking. The performance of the method allows to verify its
              viability for automatic tasks in agriculture based on image
              processing.",
  month    =  sep,
  year     =  2012,
  url      = "https://www.sciencedirect.com/science/article/pii/S0957417412005635",
  keywords = "Support Vector Machines; Image segmentation; Weeds/crop
              discrimination; Precision Agriculture",
  doi      = "10.1016/j.eswa.2012.03.040",
  issn     = "0957-4174"
}

@INCOLLECTION{Ronneberger2015-ye,
  title     = "{U}-Net: Convolutional Networks for Biomedical Image Segmentation",
  author    = "Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas",
  booktitle = "Lecture Notes in Computer Science",
  publisher = "Springer International Publishing",
  address   = "Cham",
  pages     = "234--241",
  abstract  = "Elsevier’s Scopus, the largest abstract and citation database of
               peer-reviewed literature. Search and access research from the
               science, technology, medicine, social sciences and arts and
               humanities fields.",
  series    = "Lecture notes in computer science",
  year      =  2015,
  url       = "http://dx.doi.org/10.1007/978-3-319-24574-4_28",
  doi       = "10.1007/978-3-319-24574-4\_28",
  isbn      = "9783319245737,9783319245744",
  issn      = "0302-9743,1611-3349",
  language  = "en"
}

@PROCEEDINGS{Hermann2007-cu,
  title    = "A comparative study on {2D} curvature estimators",
  author   = "Hermann, S and Klette, R",
  abstract = "Curvature is a frequently used property in twodimensional (2D)
              shape analysis, directly or for derived features such as corners
              or convex and concave arcs. This paper presents curvature
              estimators which follow approaches in differential geometry.
              Digital-straight segment approximation (as known from digital
              geometry) is used in those estimators. Results of multigrid
              experiments are evaluated leading to a comparative performance
              analysis of several curvature estimators. © 2007 IEEE.",
  year     =  2007,
  url      = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547271163&doi=10.1109%2fICCTA.2007.2&partnerID=40&md5=f12432add58bb3b96e37b93adb35f584",
  keywords = "Computation theory; Image segmentation; Parameter estimation; Two
              dimensional; Differential geometry; Multigrid experiments;
              Performance analysis; Shape analysis; Computational geometry",
  doi      = "10.1109/ICCTA.2007.2",
  isbn     =  9780769527703
}

@MISC{Thompson2019-mg,
  title     = "A preliminary analysis of methods for curvature estimation on
               surfaces with local reliefs",
  author    = "Thompson, Elia Moscoso and Biasotti, Silvia",
  publisher = "The Eurographics Association",
  abstract  = "Curvature estimation is very popular in geometry processing for
               the analysis of local surface variations. Despite the large
               number of methods, no quantitative nor qualitative studies have
               been conducted for a comparative analysis of the different
               algorithms on surfaces with small geometric variations, such as
               chiselled or relief surfaces. In this work we compare eight
               curvature estimation methods that are commonly adopted by the
               computer graphics community on a number of triangle meshes
               derived from scans of surfaces with local reliefs.",
  year      =  2019,
  url       = "http://dx.doi.org/10.2312/egs.20191006",
  doi       = "10.2312/EGS.20191006"
}

@BOOK{Nixon2012-ta,
  title     = "Feature Extraction and Image Processing for Computer Vision",
  author    = "Nixon, Mark S and Aguado, Alberto S",
  publisher = "Academic Press",
  edition   = "3rd ed.",
  year      =  2012,
  url       = "https://arizona-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=01UA_ALMA51806451690003843&context=L&vid=01UA&lang=en_US&search_scope=Everything&adaptor=Local%20Search%20Engine&tab=default_tab&query=title,contains,Feature%20Extraction%20and%20Image%20Processing%20for%20Computer%20Vision",
  keywords  = "Image processing -- Digital techniques",
  isbn      =  9780123978240
}

@MISC{noauthor_undated-xj,
  title        = "{ROC} Curves and {AUC} for Models Used for Binary
                  Classification",
  howpublished = "\url{https://library.virginia.edu/data/articles/roc-curves-and-auc-for-models-used-for-binary-classification}",
  note         = "Accessed: 2023-9-20",
  language     = "en"
}

@ARTICLE{Otsu1979-io,
  title    = "A Threshold Selection Method from Gray-Level Histograms",
  author   = "Otsu, N",
  journal  = "IEEE Trans. Syst. Man Cybern.",
  volume   =  9,
  number   =  1,
  pages    = "62--66",
  month    =  jan,
  year     =  1979,
  url      = "http://dx.doi.org/10.1109/TSMC.1979.4310076",
  keywords = "Histograms;Marine vehicles;Radar tracking;Least squares
              approximation;Surveillance;Target tracking;Gaussian
              distribution;Displays;Q measurement;Sea measurements",
  doi      = "10.1109/TSMC.1979.4310076",
  issn     = "0018-9472,2168-2909"
}

@ARTICLE{Etienne2021-ik,
  title     = "Deep learning-based object detection system for identifying weeds
               using uas imagery",
  author    = "Etienne, A and Ahmad, A and Aggarwal, V and Saraswat, D",
  journal   = "Remote Sensing",
  publisher = "MDPI",
  volume    =  13,
  number    =  24,
  abstract  = "Current methods of broadcast herbicide application cause a
               negative environmental and economic impact. Computer vision
               methods, specifically those related to object detection, have
               been reported to aid in site-specific weed management procedures
               for targeted herbicide application within a field. However, a
               major challenge to developing a weed detection system is the
               requirement for a properly annotated database to differentiate
               between weeds and crops under field conditions. This research
               involved creating an annotated database of 374 red, green, and
               blue (RGB) color images organized into monocot and dicot weed
               classes. The images were acquired from corn and soybean research
               plots located in north-central Indiana using an unmanned aerial
               system (UAS) flown at 30 and 10 m heights above ground level
               (AGL). A total of 25,560 individual weed instances were manually
               annotated. The annotated database consisted of four different
               subsets (Training Image Sets 1–4) to train the You Only Look Once
               version 3 (YOLOv3) deep learning model for five separate
               experiments. The best results were observed with Training Image
               Set 4, consisting of images acquired at 10 m AGL. For monocot and
               dicot weeds, respectively, an average precision (AP) score of
               91.48 \% and 86.13\% was observed at a 25\% IoU threshold (AP @ T
               = 0.25), as well as 63.37\% and 45.13\% at a 50\% IoU threshold
               (AP @ T = 0.5). This research has demonstrated a need to develop
               large, annotated weed databases to evaluate deep learning models
               for weed identification under field conditions. It also affirms
               the findings of other limited research studies utilizing object
               detection for weed identification under field conditions. © 2021
               by the authors. Licensee MDPI, Basel, Switzerland.",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121584464&doi=10.3390%2frs13245182&partnerID=40&md5=7bbc76886421154dc8d91125e510feae",
  keywords  = "Artificial intelligence; Deep learning; Machine learning; Object
               detection; UAS; Weed detection; Antennas; Database systems; Deep
               learning; Herbicides; Image acquisition; Object recognition;
               Unmanned aerial vehicles (UAV); Weed control; Above ground level;
               Annotated database; Deep learning; Field conditions; Herbicide
               application; Images sets; Monocots; Training image; Unmanned
               aerial systems; Weed detection; Object detection",
  doi       = "10.3390/rs13245182",
  issn      = "2072-4292"
}

@ARTICLE{Kilday1993-aq,
  title    = "Classifying mammographic lesions using computerized image analysis",
  author   = "Kilday, J and Palmieri, F and Fox, M D",
  journal  = "IEEE Trans. Med. Imaging",
  volume   =  12,
  number   =  4,
  pages    = "664--669",
  abstract = "The classification of 3 common breast lesions, fibroadenomas,
              cysts, and cancers, was achieved using computerized image analysis
              of tumor shape in conjunction with patient age. The process
              involved the digitization of 69 mammographic images using a video
              camera and a commercial frame grabber on a PC-based computer
              system. An interactive segmentation procedure identified the tumor
              boundary using a thresholding technique which successfully
              segmented 57\% of the lesions. Several features were chosen based
              on the gross and fine shape describing properties of the tumor
              boundaries as seen on the radiographs. Patient age was included as
              a significant feature in determining whether the tumor was a cyst,
              fibroadenoma, or cancer and was the only patient history
              information available for this study. The concept of a radial
              length measure provided a basis from which 6 of the 7 shape
              describing features were chosen, the seventh being tumor
              circularity. The feature selection process was accomplished using
              linear discriminant analysis and a Euclidean distance metric
              determined group membership. The effectiveness of the
              classification scheme was tested using both the apparent and the
              leaving-one-out test methods. The best results using the apparent
              test method resulted in correctly classifying 82\% of the tumors
              segmented using the entire feature space and the highest
              classification rate using the leaving-one-out test method was 69\%
              using a subset of the feature space. The results using only the
              shape descriptors, and excluding patient age resulted in correctly
              classifying 72\% using the entire feature space (except age), and
              51\% using a subset of the feature space.",
  year     =  1993,
  url      = "http://dx.doi.org/10.1109/42.251116",
  doi      = "10.1109/42.251116",
  pmid     =  18218460,
  issn     = "0278-0062",
  language = "en"
}

@ARTICLE{Iqbal2021-yx,
  title    = "Gray level co-occurrence matrix ({GLCM}) texture based crop
              classification using low altitude remote sensing platforms",
  author   = "Iqbal, Naveed and Mumtaz, Rafia and Shafi, Uferah and Zaidi, Syed
              Mohammad Hassan",
  journal  = "PeerJ Comput Sci",
  volume   =  7,
  pages    = "e536",
  abstract = "Crop classification in early phenological stages has been a
              difficult task due to spectrum similarity of different crops. For
              this purpose, low altitude platforms such as drones have great
              potential to provide high resolution optical imagery where Machine
              Learning (ML) applied to classify different types of crops. In
              this research work, crop classification is performed at different
              phenological stages using optical images which are obtained from
              drone. For this purpose, gray level co-occurrence matrix (GLCM)
              based features are extracted from underlying gray scale images
              collected by the drone. To classify the different types of crops,
              different ML algorithms including Random Forest (RF), Naive Bayes
              (NB), Neural Network (NN) and Support Vector Machine (SVM) are
              applied. The results showed that the ML algorithms performed much
              better on GLCM features as compared to gray scale images with a
              margin of 13.65\% in overall accuracy.",
  month    =  may,
  year     =  2021,
  url      = "http://dx.doi.org/10.7717/peerj-cs.536",
  keywords = "Classification; Feature extraction; GLCM; Machine learning; Remote
              sensing; Texture analysis; Unmanned aerial vehicles",
  doi      = "10.7717/peerj-cs.536",
  pmc      = "PMC8176538",
  pmid     =  34141878,
  issn     = "2376-5992",
  language = "en"
}

@ARTICLE{Anderegg2023-kb,
  title    = "On-farm evaluation of {UAV}-based aerial imagery for season-long
              weed monitoring under contrasting management and pedoclimatic
              conditions in wheat",
  author   = "Anderegg, Jonas and Tschurr, Flavian and Kirchgessner, Norbert and
              Treier, Simon and Schmucki, Manuel and Streit, Bernhard and
              Walter, Achim",
  journal  = "Comput. Electron. Agric.",
  volume   =  204,
  pages    =  107558,
  abstract = "Timely availability of weed infestation maps is a key prerequisite
              for the implementation of site-specific weed management practices.
              Low-altitude aerial imagery obtained from unmanned aerial vehicles
              (UAVs) has shown significant potential for weed detection in
              crops. However, most studies focused on wide-spaced row crops such
              as maize and sunflower and evaluated proposed methods on single or
              few well-characterized experimental sites at specific points in
              time representing a limited range of application scenarios. This
              study evaluated the feasibility of weed detection in on-farm wheat
              fields characterized by a narrow row spacing, throughout the early
              and late developmental stages using UAV imagery and ground-based
              high-resolution imagery. Image data was obtained for nine sites,
              representing a wide range of management and pedoclimatic
              conditions. These sites can be seen as a representative sample of
              scenarios that would be encountered in practice. A high within-
              and across-site as well as temporal variation was observed for
              weed infestation levels and weed population species composition,
              highlighting the need for spatially and temporally resolved weed
              mapping. Image-based classification of vegetation objects as crop
              or weed plants was achieved with an accuracy of 0.88 and 0.72 in
              ground-based high-resolution images and UAV-based aerial images
              captured from an altitude of 10 m, respectively. The accuracy of
              pixel-wise, vegetation-index-based weed infestation estimation
              during the late vegetative stages varied strongly across sites.
              Our results highlight the critical importance of a high ground
              resolution for weed detection using object-based image analysis
              during the critical growth stages of wheat and of robust methods
              that are applicable across a range of scenarios. This suggested
              that future research aiming at a rapid implementation of
              site-specific weed management in wheat should focus on the
              development of ground-based systems. Yet, aerial monitoring of
              wheat stands during late developmental stages using currently
              available equipment offers significant potential for reducing weed
              pressure with site-specific weed control measures in the context
              of crop rotations.",
  month    =  jan,
  year     =  2023,
  url      = "https://www.sciencedirect.com/science/article/pii/S0168169922008663",
  keywords = "Precision agriculture; Object-based image analysis; OBIA;
              Vegetation index; Site-specific management; Remote sensing",
  doi      = "10.1016/j.compag.2022.107558",
  issn     = "0168-1699"
}

@BOOK{Klette2004-qz,
  title     = "Digital Geometry: Geometric Methods for Digital Picture Analysis",
  author    = "Klette, Reinhard and Rosenfeld, Azriel",
  publisher = "Elsevier Science \& Technology",
  address   = "San Francisco",
  edition   =  1,
  abstract  = "Digital geometry is about deriving geometric information from
               digital pictures. The field emerged from its mathematical roots
               some forty-years ago through work in computer-based imaging, and
               it is used today in many fields, such as digital image processing
               and analysis (with applications in medical imaging, pattern
               recognition, and robotics) and of course computer graphics.
               Digital Geometry is the first book to detail the concepts,
               algorithms, and practices of the discipline. This comphrehensive
               text and reference provides an introduction to the mathematical
               foundations of digital geometry, some of which date back to
               ancient times, and also discusses the key processes involved,
               such as geometric algorithms as well as operations on pictures.
               *A comprehensive text and reference written by pioneers in
               digital geometry, image processing and analysis, and computer
               vision *Provides a collection of state-of-the-art algorithms for
               a wide variety of geometrical picture analysis tasks, including
               extracting data from digital images and making geometric
               measurements on the data *Includes exercises, examples, and
               references to related or more advanced work.",
  series    = "The Morgan Kaufmann Series in Computer Graphics",
  year      =  2004,
  url       = "http://dx.doi.org/10.1016/B978-1-55860-861-0.X5000-7",
  keywords  = "Algorithms;Combinatorial geometry;Discrete geometry;Image
               analysis",
  doi       = "10.1016/B978-1-55860-861-0.X5000-7",
  isbn      =  9781558608610
}

@INCOLLECTION{Anguita2012-nb,
  title     = "Human activity recognition on smartphones using a multiclass
               hardware-friendly support vector machine",
  author    = "Anguita, D and Ghio, A and Oneto, L and Parra, X and Reyes-Ortiz,
               J L",
  booktitle = "4th International Workshop on Ambient Assisted Living, IWAAL 2012",
  address   = "Vitoria-Gasteiz",
  volume    = "7657 LNCS",
  pages     = "216--223",
  abstract  = "Activity-Based Computing [1] aims to capture the state of the
               user and its environment by exploiting heterogeneous sensors in
               order to provide adaptation to exogenous computing resources.
               When these sensors are attached to the subject's body, they
               permit continuous monitoring of numerous physiological signals.
               This has appealing use in healthcare applications, e.g. the
               exploitation of Ambient Intelligence (AmI) in daily activity
               monitoring for elderly people. In this paper, we present a system
               for human physical Activity Recognition (AR) using smartphone
               inertial sensors. As these mobile phones are limited in terms of
               energy and computing power, we propose a novel hardware-friendly
               approach for multiclass classification. This method adapts the
               standard Support Vector Machine (SVM) and exploits fixed-point
               arithmetic for computational cost reduction. A comparison with
               the traditional SVM shows a significant improvement in terms of
               computational costs while maintaining similar accuracy, which can
               contribute to develop more sustainable systems for AmI. © 2012
               Springer-Verlag.",
  year      =  2012,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870866072&doi=10.1007%2f978-3-642-35395-6_30&partnerID=40&md5=f8cbae6e09f9a2886212e285d1a7ed10",
  keywords  = "Activity Recognition; Hardware-Friendly; Smartphones; SVM;
               Activity recognition; Activity-based computing; Ambient
               intelligence; Computational costs; Computing power; Computing
               resource; Continuous monitoring; Daily activity; Elderly people;
               Hardware-Friendly; Health care application; Heterogeneous
               sensors; Human activity recognition; Inertial sensor;
               Multi-class; Multi-class classification; Physical activity;
               Physiological signals; Sustainable systems; SVM; Hardware; Health
               care; Sensors; Smartphones; Support vector machines",
  doi       = "10.1007/978-3-642-35395-6\_30",
  isbn      =  9783642353949
}

@ARTICLE{Monteiro2021-sk,
  title     = "A new alternative to determine weed control in agricultural
               systems based on artificial neural networks ({ANNs})",
  author    = "Monteiro, A L and Souza, Freitas and Lins, H A and Teófilo, T M D
               S and Barros Júnior, A P and Silva, D V and Mendonça, V",
  journal   = "Field Crops Res.",
  publisher = "Elsevier B.V.",
  volume    =  263,
  abstract  = "Weed control is a necessary practice to avoid crop yield losses.
               Therefore, farmers should answer the following question: when to
               start weed control? Currently, there are no learning models to
               assist the producer to answer this question. Thus, the objectives
               were to: 1) evaluate the ability of artificial neural networks
               (ANNs) to estimate the beginning of weed control for different
               classes of acceptable yield losses; 2) validate a new alternative
               for modeling and predicting competition between weeds and crops.
               ANNs determined the ideal moment to control weeds based on
               non-destructive and destructive variables. The inputs C3/C4
               ratio, coexistence period, density of weeds, and crop
               (categorical variable to differentiate sesame and melon) provided
               accuracy and F-score values above 0.95 during training,
               validation, and testing steps for ANN in non-destructive method.
               When using the destructive variables, C3/C4 ratio plus
               coexistence period, fresh matter of weeds, and crop provided
               accuracy and F-score values above 0.90 during training,
               validation, and testing steps. The combination of non-destructive
               and destructive inputs also generated an ANN with high accuracy
               and F-score, above 0.95, during training, validation, and testing
               steps. Machine learning can be used in crop-weed competition
               modeling. © 2021 Elsevier B.V.",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099622811&doi=10.1016%2fj.fcr.2021.108075&partnerID=40&md5=460bcd2ef6e727c29048a987c1715a96",
  keywords  = "Artificial intelligence; Decision making; Modeling; Weed
               interference; accuracy assessment; artificial neural network;
               crop yield; farming system; machine learning; nondestructive
               testing; weed control; yield response; Sesamum indicum",
  doi       = "10.1016/j.fcr.2021.108075",
  issn      = "0378-4290"
}

@ARTICLE{Flores2021-fk,
  title     = "Distinguishing seedling volunteer corn from soybean through
               greenhouse color, color-infrared, and fused images using machine
               and deep learning",
  author    = "Flores, P and Zhang, Z and Igathinathane, C and Jithin, M and
               Naik, D and Stenger, J and Ransom, J and Kiran, R",
  journal   = "Ind. Crops Prod.",
  publisher = "Elsevier B.V.",
  volume    =  161,
  abstract  = "Volunteer corn (VC; Zea mays L.), as a weed in corn-soybean
               (Glycine max (L.) Merr.) rotation, has negatively impacted
               soybean production by reducing yield, lowering grain quality, and
               increasing the production costs. To assess the level of VC
               infestation to guide chemical applications, farmers usually rely
               on field visual observation. Since the field visual inspection is
               labor-intensive, time-consuming, and subjective, an automatic
               solution to differentiate VC from soybeans is required. As a
               first step toward that goal, this study aimed to develop a
               solution to differentiate those crops at seedling stage under
               greenhouse conditions. Color RGB and color-infrared (CIR) images
               of VC and soybean seedlings were collected in a greenhouse. A
               fused image dataset was created by blending the RGB and CIR image
               datasets. The top 20 extracted relevant features and the image
               datasets were fed into four different machine learning (ML)
               classifiers and four deep learning (DL) algorithms, respectively.
               All ML classifiers resulted in the highest accuracies on the
               fused images, with support vector machine (SVM) outperforming the
               other classifiers. Similarly, all the DL algorithms had a
               superior performance on the fused images, with GoogLeNet as the
               best algorithm. Overall, GoogLeNet was selected for its high
               accuracy 99.9\%, reasonable computation time (0.02 s per plant),
               and simple and direct application. The application of fused
               images along with GoogLeNet can be used as a novel tool to
               automatically distinguish VC from soybean. Future research should
               focus on field testing this methodology in a real-time mode. ©
               2021 Elsevier B.V.",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099201868&doi=10.1016%2fj.indcrop.2020.113223&partnerID=40&md5=e0377ffac0a6fd0fb90ecf844494501d",
  keywords  = "Deep learning; Image fusion; Image registration; Image
               segmentation; Machine learning; Soybean; Volunteer corn; Amino
               acids; Classification (of information); Color; Greenhouses;
               Learning systems; Nitrogen fixation; Support vector machines;
               Chemical applications; Greenhouse conditions; Relevant features;
               Soybean (Glycine max (L.) Merr.); Soybean production; Soybean
               seedlings; Visual inspection; Visual observations; Deep learning;
               algorithm; automation; food quality; greenhouse ecosystem; image
               analysis; machine learning; seeding; soybean; support vector
               machine; weed; Glycine max; Zea mays",
  doi       = "10.1016/j.indcrop.2020.113223",
  issn      = "0926-6690"
}

@ARTICLE{Sohail2021-cj,
  title     = "A review on machine vision and image processing techniques for
               weed detection in agricultural crops",
  author    = "Sohail, R and Nawaz, Q and Hamid, I and Gilani, S M M and Mumtaz,
               I and Mateen, A and Nawaz, J",
  journal   = "Pakistan Journal of Agricultural Sciences",
  publisher = "University of Agriculture",
  volume    =  58,
  number    =  1,
  pages     = "187--204",
  abstract  = "The advancement in the field of precision agriculture has opened
               doors for site-specific weed management. There is a growing need
               to control the amount of herbicide sprayed on weeds to reduce
               economic and environmental losses. In the field of precision
               agriculture, incorporation of machine learning techniques has
               enabled the farmers to automate the process of controlling weed
               using an adequate number of herbicides for different species
               in-situ. This study aims to explore various parameters of
               Computer Vision and Machine Learning algorithms and methods used
               by researchers to develop Artificial Intelligence models to
               remove weeds from agricultural fields. More than twenty
               state-of-the-art algorithms have been studied in this paper. We
               categorized these algorithms into five categories based on
               different features i.e. visual, shape, spatial, and spectral. At
               the end of this study, a comprehensive table is presented
               containing details of algorithms in terms of limitations and
               accuracy. © 2021, University of Agriculture. All rights reserved.",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099593950&doi=10.21162%2fPAKJAS%2f21.305&partnerID=40&md5=e2a7aba39d94f23a2e7f35556813a4b1",
  keywords  = "Image processing; Machine vision; Robotic weed control; Weed
               detection",
  doi       = "10.21162/PAKJAS/21.305",
  issn      = "0552-9034"
}

@PROCEEDINGS{Beeharry2020-nn,
  title     = "Performance of {ANN} and {AlexNet} for weed detection using
               {UAV}-based images",
  author    = "Beeharry, Y and Bassoo, V",
  editor    = "{Pudaruth S.} and {Mungur A.} and {Ah King R.T.F.} and {Fowdur
               T.P.} and {Bojkovic Z.} and {Milovanovic D.} and {Hurbungs V.}",
  publisher = "Institute of Electrical and Electronics Engineers Inc.",
  abstract  = "Unmanned Aerial Vehicles (UAVs) have become an integral part of
               several real-world applications. Their combination with other
               evolving paradigms such as image recognition using machine
               learning or deep learning algorithms has contributed to the
               suitability for use in smart agriculture and weed detection
               applications. In this paper, the performances of the Artificial
               Neural Network (ANN) and AlexNet algorithms for weed detection
               using UAV-based images have been studied. An image dataset
               containing 15336 segments with the following breakdown: 3249 of
               soil, 7376 of soybean, 3520 grass and 1191 of broadleaf weeds has
               been used. The partitioning for train and test sets has been done
               in the ratio of 70:30. Simulation results show that the
               conventional ANN algorithm provide an accuracy of 48.09\% while
               the AlexNet algorithms gives an accuracy 99.8\% on the test
               dataset. © 2020 IEEE.",
  year      =  2020,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099571177&doi=10.1109%2fELECOM49001.2020.9296994&partnerID=40&md5=d5ab3b49d9fd7a33fd2f26e383c2ca09",
  keywords  = "AlexNet; Artificial Neural Network; weed detection; Agricultural
               robots; Aircraft detection; Antennas; Deep learning; Image
               recognition; Neural networks; Statistical tests; Unmanned aerial
               vehicles (UAV); Weed control; ANN algorithm; Broadleaf weeds;
               Image datasets; Integral part; Real-world; Smart agricultures;
               Test sets; Weed detection; Learning algorithms",
  doi       = "10.1109/ELECOM49001.2020.9296994",
  isbn      =  9781728157078
}

@PROCEEDINGS{Perez-Ortiz2017-pg,
  title     = "Machine learning paradigms for weed mapping via unmanned aerial
               vehicles",
  author    = "Perez-Ortiz, M and Gutierrez, P A and Pena, J M and
               Torres-Sanchez, J and Lopez-Granados, F and Hervas-Martinez, C",
  publisher = "Institute of Electrical and Electronics Engineers Inc.",
  abstract  = "This paper presents a novel strategy for weed monitoring, using
               images taken with unmanned aerial vehicles (UAVs) and concepts of
               image analysis and machine learning. Weed control in precision
               agriculture designs site-specific treatments based on the
               coverage of weeds, where the key is to provide precise weed maps
               timely. Most traditional remote platforms, e.g. piloted planes or
               satellites, are, however, not suitable for early weed monitoring,
               given their low temporal and spatial resolutions, as opposed to
               he ultra-high spatial resolution of UAVs. The system here
               proposed makes use of UAV-imagery and is based on: 1) Divide the
               image, 2) compute and binarise the vegetation indexes, 3) detect
               crop rows, 4) optimise the parameters and 4) learn a
               classification model. Since crops are usually organised in rows,
               the use of a crop row detection algorithm helps to separate
               properly weed and crop pixels, which is a common handicap given
               the spectral similitude of both. Several artificial intelligence
               paradigms are compared in this paper to identify the most
               suitable strategy for this topic (i.e. unsupervised, supervised
               and semi-supervised approaches). Our experiments also study the
               effect of different parameteres: the flight altitude, the sensor
               and the use of previously trained models at a different height.
               Our results show that 1) very promising performance can be
               obtained, even when using very few labelled data and 2) the
               classification model can be learnt in a subplot of the
               experimental field at low altitude and then applied to the whole
               field at a higher height, which simplifies the whole process.
               These results motivate the use of this strategy to design weed
               monitoring strategies for early post-emergence weed control. ©
               2016 IEEE.",
  year      =  2017,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015991782&doi=10.1109%2fSSCI.2016.7849987&partnerID=40&md5=bc4aab58904adb41c5f577a715b76d0e",
  keywords  = "Artificial intelligence; Crops; Learning systems; Unmanned aerial
               vehicles (UAV); Classification models; Crop row detection;
               Different heights; Flight altitudes; Monitoring strategy; Novel
               strategies; Precision Agriculture; Temporal and spatial; Weed
               control",
  doi       = "10.1109/SSCI.2016.7849987",
  isbn      =  9781509042401
}

@PROCEEDINGS{Espinoza2020-es,
  title     = "Weed identification and removal using machine learning techniques
               and unmanned ground vehicles",
  author    = "Espinoza, M A M and Le, C Z and Raheja, A and Bhandari, S",
  editor    = "{Thomasson J.A.} and {Torres-Rua A.F.}",
  publisher = "SPIE",
  volume    =  11414,
  abstract  = "This paper presents the use of unmanned ground vehicle (UGV) and
               machine learning techniques for the identification removal of
               weeds in lettuce crop. In recent years, breakthroughs in deep
               learning, computer vision, and miniaturization of electronic
               devices have paved the way for use of unmanned systems and
               machine learning techniques for applications that are dull,
               dirty, and dangerous for humans including agricultural
               applications. Unmanned systems and machine learning techniques
               have potential to transform and modernize how the crops are grown
               and cared. One of the problems every farmer encounters is
               invasive weeds that can kill or hinder the growth of crops by
               stealing water, nutrients, and sunlight from the plants.
               Herbicides are used to kill and stop the growth of weeds.
               However, use of herbicides increases the cost of production, is
               labor intensive, and exposes human to dangerous chemicals.
               Manually removing the weeds is also very labor intensive. Using
               machine learning techniques and UGVs for the identification and
               removal of weeds will reduce the cost of production, human
               exposure to dangerous chemicals, and dependence on human labor.
               Models were trained using YOLO, Faster R-CNN, and SSD Mobile
               object detection techniques. For the training of machine learning
               models, images of the weeds in an experimental lettuce plot was
               collected throughout the growing season. Validation of the
               developed models was performed using different data sets than the
               training data sets in the same plot as well as a different plot.
               The identified weeds were then removed using the UGV through
               teleoperation. © 2020 SPIE.",
  year      =  2020,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089075752&doi=10.1117%2f12.2557625&partnerID=40&md5=2fdd9ed15e473720280303442772ae45",
  keywords  = "CNN,SSD; Machine Learning; Robotics; UGV; Weed Removal; Weeds;
               YOLO; Agricultural robots; Crops; Deep learning; Ground vehicles;
               Herbicides; Intelligent vehicle highway systems; Object
               detection; Weed control; Cost of productions; Electronic device;
               Identification and removal; Machine learning models; Machine
               learning techniques; Training data sets; Unmanned ground
               vehicles; Weed identification; Learning systems",
  doi       = "10.1117/12.2557625",
  isbn      =  9781510636057
}

@MISC{noauthor_undated-xq,
  title        = "Paperpile",
  howpublished = "\url{https://paperpile.com/app/p/da8a0891-8580-0eb5-9d66-3438a62cdebe}",
  note         = "Accessed: 2021-2-14"
}

@MISC{noauthor_undated-gz,
  title        = "Slurm Workload Manager - Documentation",
  howpublished = "\url{https://slurm.schedmd.com/documentation.html}",
  note         = "Accessed: 2023-10-19",
  language     = "en"
}

@MISC{Wikipedia_contributors2023-ox,
  title        = "{HSL} and {HSV}",
  author       = "{Wikipedia contributors}",
  booktitle    = "Wikipedia, The Free Encyclopedia",
  abstract     = "HSL (for hue, saturation, lightness) and HSV (for hue,
                  saturation, value; also known as HSB, for hue, saturation,
                  brightness) are alternative representations of the RGB color
                  model, designed in the 1970s by computer graphics researchers.
                  In these models, colors of each hue are arranged in a radial
                  slice, around a central axis of neutral colors which ranges
                  from black at the bottom to white at the top.",
  month        =  oct,
  year         =  2023,
  howpublished = "\url{https://en.wikipedia.org/w/index.php?title=HSL\_and\_HSV\&oldid=1180071700}",
  note         = "Accessed: --"
}

@BOOK{Fernandez2018-fw,
  title     = "Learning from Imbalanced Data Sets",
  author    = "Fernández, Alberto and García, Salvador and Galar, Mikel and
               Prati, Ronaldo C and Krawczyk, Bartosz and Herrera, Francisco",
  publisher = "Springer International Publishing",
  year      =  2018,
  url       = "https://link.springer.com/book/10.1007/978-3-319-98074-4",
  doi       = "10.1007/978-3-319-98074-4"
}

@ARTICLE{Nasiri2022-rj,
  title     = "Deep learning-based precision agriculture through weed
               recognition in sugar beet fields",
  author    = "Nasiri, A and Omid, M and Taheri-Garavand, A and Jafari, A",
  journal   = "Sustainable Computing: Informatics and Systems",
  publisher = "Elsevier Inc.",
  volume    =  35,
  abstract  = "Weeds are among the major factors adversely affecting crop yield.
               Therefore, weed control with minimal environmental damage is a
               global concern. Traditional weed control methods are not
               cost-effective. Hence, precision agriculture proposes variable
               flow herbicide technology through regional weed management to
               distinguish weed and crop. In the present study, we employed the
               U-Net architecture, as a deep encoder-decoder convolutional
               neural network (CNN) for pixel-wise semantic segmentation of
               sugar beet, weed, and soil. We trained the U-Net architecture
               with ResNet50 as the encoder block using 1385 RGB images
               collected under different conditions and various heights. We
               utilized the combination of the dice and focal losses as a custom
               linear loss function to overcome imbalanced data and small area
               segmentation challenges. The structure of the dataset for the
               training process and using the custom loss function led to a
               model with the accuracy and intersection over union (IoU) score
               of 0.9606 and 0.8423, respectively. The results showed that using
               the image dataset with proper distribution and custom loss
               function can improve segmentation accuracy, especially in small
               regions. Furthermore, in an autonomous weed control robot,
               CNN-based automatic weed detection can be integrated into
               selective herbicide applications. © 2022 Elsevier Inc.",
  year      =  2022,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131099205&doi=10.1016%2fj.suscom.2022.100759&partnerID=40&md5=26572e1afa6ae3add8171a771fde11b9",
  keywords  = "Deep learning; Semantic segmentation; Sugar beet; Weed detection;
               Convolutional neural networks; Cost effectiveness; Crops; Deep
               learning; Herbicides; Image enhancement; Network architecture;
               Precision agriculture; Semantics; Signal encoding; Sugar beets;
               Weed control; Convolutional neural network; Deep learning; Loss
               functions; Major factors; NET architecture; Precision
               Agriculture; Semantic segmentation; Sugar beet fields; Weed
               detection; Weed recognition; Semantic Segmentation",
  doi       = "10.1016/j.suscom.2022.100759",
  issn      = "2210-5379"
}

@ARTICLE{Shorewala2021-wf,
  title     = "Weed Density and Distribution Estimation for Precision
               Agriculture Using Semi-Supervised Learning",
  author    = "Shorewala, Shantam and Ashfaque, Armaan and Sidharth, R and
               Verma, Ujjwal",
  journal   = "IEEE Access",
  publisher = "IEEE",
  volume    =  9,
  pages     = "27971--27986",
  abstract  = "Uncontrolled growth of weeds can severely affect the crop yield
               and quality. Unrestricted use of herbicide for weed removal
               alters biodiversity and cause environmental pollution. Instead,
               identifying weed-infested regions can aid selective chemical
               treatment of these regions. Advances in analyzing farm images
               have resulted in solutions to identify weed plants. However, a
               majority of these approaches are based on supervised learning
               methods which requires huge amount of manually annotated images.
               As a result, these supervised approaches are economically
               infeasible for the individual farmer because of the wide variety
               of plant species being cultivated. In this paper, we propose a
               deep learning-based semi-supervised approach for robust
               estimation of weed density and distribution across farmlands
               using only limited color images acquired from autonomous robots.
               This weed density and distribution can be useful in a
               site-specific weed management system for selective treatment of
               infected areas using autonomous robots. In this work, the
               foreground vegetation pixels containing crops and weeds are first
               identified using a Convolutional Neural Network (CNN) based
               unsupervised segmentation. Subsequently, the weed infected
               regions are identified using a fine-tuned CNN, eliminating the
               need for designing hand-crafted features. The approach is
               validated on two datasets of different crop/weed species (1) Crop
               Weed Field Image Dataset (CWFID), which consists of carrot plant
               images and the (2) Sugar Beets dataset. The proposed method is
               able to localize weed-infested regions a maximum recall of 0.99
               and estimate weed density with a maximum accuracy of 82.13\%.
               Hence, the proposed approach is shown to generalize to different
               plant species without the need for extensive labeled data.",
  year      =  2021,
  url       = "http://dx.doi.org/10.1109/ACCESS.2021.3057912",
  doi       = "10.1109/ACCESS.2021.3057912",
  issn      = "2169-3536"
}

@PROCEEDINGS{Perez-Ortiz2017-wj,
  title     = "Machine learning paradigms for weed mapping via unmanned aerial
               vehicles",
  author    = "Perez-Ortiz, M and Gutierrez, P A and Pena, J M and
               Torres-Sanchez, J and Lopez-Granados, F and Hervas-Martinez, C",
  publisher = "Institute of Electrical and Electronics Engineers Inc.",
  abstract  = "This paper presents a novel strategy for weed monitoring, using
               images taken with unmanned aerial vehicles (UAVs) and concepts of
               image analysis and machine learning. Weed control in precision
               agriculture designs site-specific treatments based on the
               coverage of weeds, where the key is to provide precise weed maps
               timely. Most traditional remote platforms, e.g. piloted planes or
               satellites, are, however, not suitable for early weed monitoring,
               given their low temporal and spatial resolutions, as opposed to
               he ultra-high spatial resolution of UAVs. The system here
               proposed makes use of UAV-imagery and is based on: 1) Divide the
               image, 2) compute and binarise the vegetation indexes, 3) detect
               crop rows, 4) optimise the parameters and 4) learn a
               classification model. Since crops are usually organised in rows,
               the use of a crop row detection algorithm helps to separate
               properly weed and crop pixels, which is a common handicap given
               the spectral similitude of both. Several artificial intelligence
               paradigms are compared in this paper to identify the most
               suitable strategy for this topic (i.e. unsupervised, supervised
               and semi-supervised approaches). Our experiments also study the
               effect of different parameteres: the flight altitude, the sensor
               and the use of previously trained models at a different height.
               Our results show that 1) very promising performance can be
               obtained, even when using very few labelled data and 2) the
               classification model can be learnt in a subplot of the
               experimental field at low altitude and then applied to the whole
               field at a higher height, which simplifies the whole process.
               These results motivate the use of this strategy to design weed
               monitoring strategies for early post-emergence weed control. ©
               2016 IEEE.",
  year      =  2017,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015991782&doi=10.1109%2fSSCI.2016.7849987&partnerID=40&md5=bc4aab58904adb41c5f577a715b76d0e",
  keywords  = "Artificial intelligence; Crops; Learning systems; Unmanned aerial
               vehicles (UAV); Classification models; Crop row detection;
               Different heights; Flight altitudes; Monitoring strategy; Novel
               strategies; Precision Agriculture; Temporal and spatial; Weed
               control",
  doi       = "10.1109/SSCI.2016.7849987",
  isbn      =  9781509042401
}

@ARTICLE{Ji2011-qb,
  title    = "Crop-row detection algorithm based on Random Hough Transformation",
  author   = "Ji, Ronghua and Qi, Lijun",
  journal  = "Math. Comput. Model.",
  volume   =  54,
  number   =  3,
  pages    = "1016--1020",
  abstract = "It is important to detect crop rows accurately for field
              navigation. In order to spray on line, a variable rate spray
              system should detect the crop center line accurately. Most
              existing detection algorithms are slow to detect crop rows because
              of the complicated calculation. The gradient-based Random Hough
              Transform algorithm could improve the calculation speed and reduce
              the computation effectively by the more-to-one merger mapping
              method. In order to detect the center of the crop row rapidly and
              effectively, the detection algorithm with gradient-based Random
              Hough Transform was proposed to detect the center line of crop
              rows. We tested the center line of crop-row detection for three
              kinds of plant distribution, being sparse, general and intensive.
              The experimental results showed that the detection algorithm with
              gradient-based Random Hough Transform was adaptive to the
              difference of plant density in the crop row effectively.
              Contrasted with the detection algorithm based on the Hough
              transform, the detection algorithm based on the gradient-based
              Random Hough was faster and had a high detection correction rate.",
  month    =  aug,
  year     =  2011,
  url      = "https://www.sciencedirect.com/science/article/pii/S0895717710005212",
  keywords = "Detection algorithm; Random Hough Transform; Crop row",
  doi      = "10.1016/j.mcm.2010.11.030",
  issn     = "0895-7177"
}

@ARTICLE{Pantazi2016-yx,
  title    = "Active learning system for weed species recognition based on
              hyperspectral sensing",
  author   = "Pantazi, Xanthoula-Eirini and Moshou, Dimitrios and Bravo, Cedric",
  journal  = "Biosystems Eng.",
  volume   =  146,
  pages    = "193--202",
  abstract = "Weeds have a devastating impact in crop production and yield in
              general. Current practice uses uniform application of herbicides
              leading to high costs and degradation of the environment and the
              field productivity. Site-specific treatments can be regarded as
              solutions either for reducing inputs or enable alternative
              non-chemical treatments. However, site-specific treatment needs
              accurate targeting through sensing. A new machine learning method
              is proposed, which discriminates between crop and weed species
              relying on their spectral reflectance differences. Spectral
              features were extracted from a hyperspectral imaging system that
              was mounted on a robotic platform. The proposed machine learning
              method suggests active learning by combining novelty detection and
              incremental class augmentation. Novelty detection was based on
              one-class classifiers constructed by neural networks. Best results
              for the active learning were obtained for the one-class MOG
              (mixture of Gaussians) and one-class SOM (self-organising map)
              classifiers when compared with one-class support vector machines
              and the auto-encoder network. The SOM and MOG performance in crop
              recognition was found to be 100\% and 100\% respectively. The
              recognition performance for different weed species varied between
              31\% and 98\% (MOG) and 53\%–94\% (SOM).",
  month    =  jun,
  year     =  2016,
  url      = "https://www.sciencedirect.com/science/article/pii/S1537511016000143",
  keywords = "Spectrograph; Self-organising map; Mixture of Gaussians; One-class
              classifier; Auto-encoder network; Support vector machines",
  doi      = "10.1016/j.biosystemseng.2016.01.014",
  issn     = "1537-5110"
}

@MISC{noauthor_undated-te,
  title = "fulltext.pdf"
}

@ARTICLE{Hunt2013-ih,
  title    = "A visible band index for remote sensing leaf chlorophyll content
              at the canopy scale",
  author   = "Hunt, E Raymond and Doraiswamy, Paul C and McMurtrey, James E and
              Daughtry, Craig S T and Perry, Eileen M and Akhmedov, Bakhyt",
  journal  = "Int. J. Appl. Earth Obs. Geoinf.",
  volume   =  21,
  pages    = "103--112",
  abstract = "Leaf chlorophyll content is an important variable for agricultural
              remote sensing because of its close relationship to leaf nitrogen
              content. The triangular greenness index (TGI) was developed based
              on the area of a triangle surrounding the spectral features of
              chlorophyll with points at (670nm, R670), (550nm, R550), and
              (480nm, R480), where Rλ is the spectral reflectance at wavelengths
              of 670, 550 and 480, respectively. The equation is
              TGI=−0.5[(670−480)(R670−R550)−(670−550)(R670−R480)]. In 1999,
              investigators funded by NASA's Earth Observations
              Commercialization and Applications Program collaborated on a
              nitrogen fertilization experiment with irrigated maize in
              Nebraska. Airborne Visible/Infrared Imaging Spectrometer (AVIRIS)
              data and Landsat 5 Thematic Mapper (TM) data were acquired along
              with leaf chlorophyll meter and other data on three dates in July
              during late vegetative growth and early reproductive growth. TGI
              was consistently correlated with plot-averaged chlorophyll-meter
              values at the spectral resolutions of AVIRIS, Landsat TM, and
              digital cameras. Simulations using the Scattering by Arbitrarily
              Inclined Leaves (SAIL) canopy model indicate an interaction among
              TGI, leaf area index (LAI) and soil type at low crop LAI, whereas
              at high LAI and canopy closure, TGI was only affected by leaf
              chlorophyll content. Therefore, TGI may be the best spectral index
              to detect crop nitrogen requirements with low-cost digital cameras
              mounted on low-altitude airborne platforms.",
  month    =  apr,
  year     =  2013,
  url      = "https://www.sciencedirect.com/science/article/pii/S0303243412001791",
  keywords = "Spectral indices; Triangular greenness index (TGI); Airborne
              Visible/Infrared Imaging Spectrometer (AVIRIS); PROSPECT; SAIL;
              Landsat Thematic Mapper (TM); Nitrogen fertilization",
  doi      = "10.1016/j.jag.2012.07.020",
  issn     = "0303-2434"
}

@ARTICLE{Osorio2020-bt,
  title     = "A Deep Learning Approach for Weed Detection in Lettuce Crops
               Using Multispectral Images",
  author    = "Osorio, Kavir and Puerto, Andrés and Pedraza, Cesar and Jamaica,
               David and Rodríguez, Leonardo",
  journal   = "AgriEngineering",
  publisher = "Multidisciplinary Digital Publishing Institute",
  volume    =  2,
  number    =  3,
  pages     = "471--488",
  abstract  = "Weed management is one of the most important aspects of crop
               productivity; knowing the amount and the locations of weeds has
               been a problem that experts have faced for several decades. This
               paper presents three methods for weed estimation based on deep
               learning image processing in lettuce crops, and we compared them
               to visual estimations by experts. One method is based on support
               vector machines (SVM) using histograms of oriented gradients
               (HOG) as feature descriptor. The second method was based in
               YOLOV3 (you only look once V3), taking advantage of its robust
               architecture for object detection, and the third one was based on
               Mask R-CNN (region based convolutional neural network) in order
               to get an instance segmentation for each individual. These
               methods were complemented with a NDVI index (normalized
               difference vegetation index) as a background subtractor for
               removing non photosynthetic objects. According to chosen metrics,
               the machine and deep learning methods had F1-scores of 88\%,
               94\%, and 94\% respectively, regarding to crop detection.
               Subsequently, detected crops were turned into a binary mask and
               mixed with the NDVI background subtractor in order to detect weed
               in an indirect way. Once the weed image was obtained, the
               coverage percentage of weed was calculated by classical image
               processing methods. Finally, these performances were compared
               with the estimations of a set from weed experts through a
               Bland–Altman plot, intraclass correlation coefficients (ICCs) and
               Dunn’s test to obtain statistical measurements between every
               estimation (machine-human); we found that these methods improve
               accuracy on weed coverage estimation and minimize subjectivity in
               human-estimated data.",
  month     =  aug,
  year      =  2020,
  url       = "https://www.mdpi.com/2624-7402/2/3/32",
  doi       = "10.3390/agriengineering2030032",
  language  = "en"
}

@ARTICLE{Hamuda2017-nf,
  title    = "Automatic crop detection under field conditions using the {HSV}
              colour space and morphological operations",
  author   = "Hamuda, Esmael and Mc Ginley, Brian and Glavin, Martin and Jones,
              Edward",
  journal  = "Comput. Electron. Agric.",
  volume   =  133,
  pages    = "97--107",
  abstract = "Developing an automatic weeding system requires robust detection
              of the exact location of the crop to be protected from damage.
              Computer vision techniques can be an effective means of
              determining plant location. In this paper, a novel algorithm based
              on colour features and morphological erosion and dilation is
              proposed. This process segments cauliflower crop regions in the
              image from weeds and soil under natural illumination (cloudy,
              partially cloudy, and sunny). The proposed algorithm uses the HSV
              colour space for discriminating crop, weeds and soil. The region
              of interest (ROI) is defined by filtering each of the HSV channels
              between certain values (minimum and maximum threshold values). The
              region is then further refined by using a morphological erosion
              and dilation process. The moment method is applied to determine
              the position and mass distribution of objects in video sequences,
              as well as to track crops. The performance of the algorithm was
              assessed by comparing the obtained results with those of ground
              truth methods (manual annotation). A sensitivity of 98.91\% and
              precision of 99.04\% was achieved.",
  month    =  feb,
  year     =  2017,
  url      = "https://www.sciencedirect.com/science/article/pii/S0168169916303714",
  keywords = "Morphological; Natural illumination; HSV colour space; Crop
              detection",
  doi      = "10.1016/j.compag.2016.11.021",
  issn     = "0168-1699"
}

@ARTICLE{Brink1996-xy,
  title    = "Minimum cross-entropy threshold selection",
  author   = "Brink, A D and Pendock, N E",
  journal  = "Pattern Recognit.",
  volume   =  29,
  number   =  1,
  pages    = "179--188",
  abstract = "Thresholding is a common and easily implemented form of image
              segmentation. Many methods of automatic threshold selection based
              on the optimization of some discriminant function have been
              proposed. Such functions often take the form of a metric distance
              or similarity measure between the original image and the segmented
              result. A non-metric measure, the cross-entropy, is used here to
              determine the optimum threshold. It is shown that this measure is
              related to other commonly used measures of distance or similarity
              under special conditions, although it is in some senses more
              general. Some typical results using this method are presented,
              together with results using a metric form of the cross-entropy.",
  month    =  jan,
  year     =  1996,
  url      = "https://www.sciencedirect.com/science/article/pii/0031320395000666",
  keywords = "Cross-entropy; Thresholding; Segmentation; Correlation; Pearson's;
              Maximum entropy",
  doi      = "10.1016/0031-3203(95)00066-6",
  issn     = "0031-3203"
}

@ARTICLE{Zack1977-yl,
  title    = "Automatic measurement of sister chromatid exchange frequency",
  author   = "Zack, G W and Rogers, W E and Latt, S A",
  journal  = "J. Histochem. Cytochem.",
  volume   =  25,
  number   =  7,
  pages    = "741--753",
  abstract = "An automatic system for detecting and counting sister chromatid
              exchanges in human chromosomes has been developed. Metaphase
              chromosomes from lymphocytes which had incorporated
              5-bromodeoxyuridine for two replication cycles were treated with
              the dye 33258 Hoechst and photodegraded so that the sister
              chromatids exhibited differential Giemsa staining. A
              computer-controlled television-microscope system was used to
              acquire digitized metaphase spread images by direct scanning of
              microscope slides. Individual objects in the images were
              identified by a thresholding procedure. The probability that each
              object was a single, separate chromosome was estimated from size
              and shape measurements. An analysis of the spatial relationships
              of the dark-chromatid regions of each object yielded a set of
              possible exchange locations and estimated probabilities that such
              locations corresponded to sister chromatid exchanges. A normalized
              estimate of the sister chromatid exchange frequency was obtained
              by summing the joint probabilities that a location contained an
              exchange within a single, separate chromosome over the set of
              chromosomes from one or more cells and dividing by the expected
              value of the total chromosome area analyzed. Comparison with
              manual scoring of exchanges showed satisfactory agreement up to
              levels of approximately 30 sister chromatid exchanges/cell, or
              slightly more than twice control levels. The processing time for
              this automated sister chromatid exchange detection system was
              comparable to that of manual scoring.",
  month    =  jul,
  year     =  1977,
  url      = "http://dx.doi.org/10.1177/25.7.70454",
  doi      = "10.1177/25.7.70454",
  pmid     =  70454,
  issn     = "0022-1554",
  language = "en"
}

@ARTICLE{Chandel2021-jv,
  title     = "An integrated inter- and intra-row weeding system for row crops",
  author    = "Chandel, N S and Chandel, A K and Roul, A K and Solanki, K R and
               Mehta, C R",
  journal   = "Crop Prot.",
  publisher = "Elsevier Ltd",
  volume    =  145,
  abstract  = "Weeding is critical to eliminate non-native plants that compete
               with main crops and adversely affect their production quality and
               quantity. Numerous prototypes exist for inter-row weeding but
               very limited for intra-row weed eradication. This study developed
               a tractor drawn integrated inter- and intra-row weeding (IIIRW)
               system for field crops. Active rotary tines were used for
               intra-row weeding and passive tines for inter-row weeding.
               Optimum operational configurations were obtained with rigorous
               repeated soil bin experiments, and developed system was evaluated
               for three growing seasons (2017–19) in field grown maize (Zea
               mays L.) and pigeon pea (Cajanus cajan (L.) Millsp.) crops.
               Optimum ratios of intra-row tine rotary speed to forward speed
               (u/v) were in the ranges of 0.8–1.3 that lead to weed mortality
               of 88.4 \% (Buried: 8.5 \%, Uprooted: 79.9 \%), negligible intact
               weeds, and plant damage (Pd) within 6 \%. Sole inter-row weeding
               operation resulted up to 78.1 \% of weed mortality (Buried: 18.1
               \%, Uprooted: 60.0 \%) and negligible Pd. Overall weed mortality
               with the IIIRW system was 92.8 \% (Buried: 9.5 \%, Uprooted: 83.3
               \%) in maize and 84.1 \% (Buried: 7.6 \%, Uprooted: 76.5 \%) in
               pigeon pea crops. Results suggest suitability of the IIIRW system
               for a range of similar crops for field capacity in ranges of
               0.22–0.26 ha/h at recommended operating speeds within 0.50–0.56
               m/s. The IIIRW system requires a single prime mover and could be
               potentially economical and efficient technology for field weeding
               operations. © 2021 Elsevier Ltd",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103758089&doi=10.1016%2fj.cropro.2021.105642&partnerID=40&md5=4cae681b782ad8ba769c43fe1585bfaa",
  keywords  = "Crop damage; Economical operation; Inter and intra-row weeds;
               Mechanical weeding; Weed mortality; crop plant; detection method;
               instrumentation; legume; mortality; weed; Cajanus cajan; Zea mays",
  doi       = "10.1016/j.cropro.2021.105642",
  issn      = "0261-2194"
}

@ARTICLE{Chen2019-wg,
  title     = "Vegetable crop row extraction method based on accumulation
               threshold of Hough Transformation",
  author    = "Chen, Z and Li, W and Zhang, W and Li, Y and Li, M and Li, H",
  journal   = "Nongye Gongcheng Xuebao/Transactions of the Chinese Society of
               Agricultural Engineering",
  publisher = "Chinese Society of Agricultural Engineering",
  volume    =  35,
  number    =  22,
  pages     = "314--322",
  abstract  = "Agricultural machinery field automatic navigation technology is
               widely used in farming, sowing, weeding, fertilizing, spraying,
               harvesting and other agricultural production process. This
               technology can improve the efficiency of the mechanical
               efficiency and reduce the missing areas of operation, labor
               intensity and the complexity of the operation. Because machine
               vision can be used to obtain and perceive the relative position
               information of crop rows, current crop growth status and field
               environment in real time, it is widely applied in online crop
               detection and identification. In this paper, a method based on
               automatic accumulation threshold of Hough Transformation was
               presented in order to improve the adaptability of the crop row
               recognition algorithm for different kinds and growth periods of
               vegetables with machine vision. The method was composed of image
               preprocessing, feature point detection, optimal accumulation
               threshold acquisition and crop row extraction. Firstly, to reduce
               the adverse effects of light change and restrain the background
               noise, a* component of Lab color model was selected for
               transforming RGB image to grayscale image. Optimal adaptive
               threshold and morphology close-open operation was applied for
               minimizing error segmentation probability and eliminating
               irrelevant detail. Secondly, the feature points of crop rows were
               extracted by sectionalized vertical projection method. The
               original image was divided into several horizontal segments and
               target pixel ratio and vertical projection width were used as
               double threshold in the luminance projection view of each segment
               to determine the location of feature points and distinguish
               noise. Thirdly, the Hough transformation method with different
               accumulative thresholds was performed to fit straight lines for
               all feature points in the image coordinate system, then they were
               all converted to Hough space accumulator as points. These points
               were clustered into the same number as crop rows by K-means
               clustering method. According to the camera projection, the
               optimal accumulator threshold was acquired by the position
               relation of clustering centroid and minimum inter-class variance.
               Finally, the fitting line parameters of real crop rows were the
               clustering centroid parameters of the accumulation space under
               the optimal accumulation threshold, then the parameters were
               converted into the crop lines in the image coordinate system. The
               crop row identification tests of lettuce and cabbage were carried
               out in the greenhouse and filed according to the conditions of
               crops in different growing periods, different weed densities, and
               different light conditions in the field. The greenhouse
               experiment showed that the algorithm can effectively identify
               crop rows with an average recognition accuracy of 97.1\% for two
               crops of different growth periods under different weed densities.
               The outdoor experiment showed that the algorithm can also
               identify crop rows with 94.6\% recognition accuracy under
               different row numbers and light conditions. Time consumption for
               optimal accumulator threshold algorithm and crop rows extraction
               algorithm were no more than 1.5 and 0.2 s, and the average
               accuracy rate of crop row detection was achieved 95.8\%. In view
               of the practical application of field operations, as the
               environmental parameters basically do not change significantly in
               a short time, the optimal accumulation threshold was only needed
               to be obtained once, which can ensure the time consumption of
               algorithm was about 0.2 s. © 2019, Editorial Department of the
               Transactions of the Chinese Society of Agricultural Engineering.
               All right reserved.",
  year      =  2019,
  url       = "https://www.scopus.com/record/display.uri?eid=2-s2.0-85079348543&origin=resultslist&sort=plf-f&src=s&sid=7ff83019f5390ac8a8ce07580d57738d&sot=b&sdt=b&sl=35&s=TITLE-ABS-KEY%28weed+detection+ratio%29&relpos=17&citeCnt=2&searchTerm=",
  keywords  = "Algorithms; Crop row recognition; Hough transform; K-means
               clustering; Machine vision; Navigation; Precision agriculture;
               Algorithms; Computer vision; Crops; Efficiency; Extraction; Fits
               and tolerances; Greenhouses; Hough transforms; Image
               segmentation; Navigation; Precision agriculture; Vegetables;
               Accumulation threshold; Agricultural productions; Detection and
               identifications; Environmental parameter; Feature point
               detection; Greenhouse experiments; K-means clustering method;
               Mechanical efficiency; K-means clustering",
  issn      = "1002-6819"
}

@ARTICLE{Lin2017-xq,
  title     = "Detection of corn and weed species by the combination of
               spectral, shape and textural features",
  author    = "Lin, F and Zhang, D and Huang, Y and Wang, X and Chen, X",
  journal   = "Sustainability (Switzerland)",
  publisher = "MDPI AG",
  volume    =  9,
  number    =  8,
  abstract  = "Accurate detection of weeds in farmland can help reduce pesticide
               use and protect the agricultural environment. To develop
               intelligent equipment for weed detection, this study used an
               imaging spectrometer system, which supports micro-scale plant
               feature analysis by acquiring high-resolution hyper spectral
               images of corn and a number of weed species in the laboratory.
               For the analysis, the object-oriented classification system with
               segmentation and decision tree algorithms was utilized on the
               hyper spectral images to extract shape and texture features of
               eight species of plant leaves, and then, the spectral
               identification characteristics of different species were
               determined through sensitive waveband selection and using
               vegetation indices calculated from the sensitive band data of the
               images. On the basis of the comparison and analysis of the
               combined characteristics of spectra, shape, and texture, it was
               determined that the spectral characteristics of the ratio
               vegetation index of R677/R710 and the normalized difference
               vegetation index, shape features of shape index, area, and
               length, as well as the texture feature of the entropy index could
               be used to build a discrimination model for corn and weed
               species. Results of the model evaluation showed that the Global
               Accuracy and the Kappa coefficient of the model were both over
               95\%. In addition, spectral and shape features can be regarded as
               the preferred characteristics to develop a device of weed
               identification from the view of accessibility to crop/weeds
               discriminant features, according to different roles of various
               features in classifying plants. Therefore, the results of this
               study provide valuable information for the portable device
               development of intelligent weed detection. © 2017 by the authors.
               Licensee MDPI, Basel, Switzerland.",
  year      =  2017,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026824347&doi=10.3390%2fsu9081335&partnerID=40&md5=fae4e8c733e19d3d32edd65993c456b2",
  keywords  = "Corn; Decision tree; Hyper spectral imaging; Object-oriented;
               Weed; accessibility; accuracy assessment; agricultural land;
               algorithm; decision making; detection method; discriminant
               analysis; entropy; maize; NDVI; shape; spectral analysis;
               spectrometer; texture; weed; Zea mays",
  doi       = "10.3390/su9081335",
  issn      = "2071-1050"
}

@ARTICLE{El-Faki2000-lh,
  title     = "Weed detection using color machine vision",
  author    = "El-Faki, M S and Zhang, N and Peterson, D E",
  journal   = "Trans. ASAE",
  publisher = "ASAE",
  address   = "St. Joseph, MI, United States",
  volume    =  43,
  number    =  6,
  pages     = "1969--1978",
  abstract  = "Many weed species have reddish stems, but stems of wheat and
               soybean are green. These color features were used in this study
               to establish a simple weed-detection method using a color
               machine-vision system. This method is more practical than
               texture- or shape-based methods because of its low sensitivity to
               canopy overlap, leaf orientation, camera focusing, and wind
               effect. Four types of relative color indices formed by RGB gray
               levels were designed. The most effective combinations of these
               color indices were selected using a statistical method. These
               combinations were used as the input variables for a statistical
               classifier based on discriminant analysis (DA) and two artificial
               neural-network (NN) classifiers. These classifiers were trained
               and tested using three weed species. (Johnsongrass, redroot
               pigweed, and yellow foxtail) with soybean and three weed species
               (wild buckwheat, cheat, and field bindweed) with wheat.
               Preprocessing and postprocessing algorithms were developed to
               shorten the processing time and to reduce noise. The results
               showed that the statistical DA classifier was more accurate than
               the NN classifiers in classification accuracy. The least-square
               means of the classification rates using the DA classifiers for
               soybean and wheat were 54.9\% and 62.2\%, respectively. The
               misclassification rates for most weed species were below 3\%.
               Because the reddish colors on the stems of some weed species vary
               as the plants grow, an in-field calibration procedure will be
               needed to make the classifiers more adaptive to different
               circumstances. Many weed species have reddish stems, but stems of
               wheat and soybean are green. These color features were used in
               this study to establish a simple weed-detection method using a
               color machine-vision system. This method is more practical than
               texture- or shape-based methods because of its low sensitivity to
               canopy overlap, leaf orientation, camera focusing, and wind
               effect. Four types of relative color indices formed by RGB gray
               levels were designed. The most effective combinations of these
               color indices were selected using a statistical method. These
               combinations were used as the input variables for a statistical
               classifier based on discriminant analysis (DA) and two artificial
               neural-network (NN) classifiers. These classifiers were trained
               and tested using three weed species. (Johnsongrass, redroot
               pigweed, and yellow foxtail) with soybean and three weed species
               (wild buckwheat, cheat, and field bindweed) with wheat.
               Preprocessing and postprocessing algorithms were developed to
               shorten the processing time and to reduce noise. The results
               showed that the statistical DA classifier was more accurate than
               the NN classifiers in classification accuracy. The least-square
               means of the classification rates using the DA classifiers for
               soybean and wheat were 54.9\% and 62.2\%, respectively. The
               misclassification rates for most weed species were below 3\%.
               Because the reddish colors on the stems of some weed species vary
               as the plants grow, an in-field calibration procedure will be
               needed to make the classifiers more adaptive to different
               circumstances.",
  year      =  2000,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034473205&partnerID=40&md5=e0134c79bd1e86417cea41fa1fb0e936",
  keywords  = "Color; Discriminant analysis; Machine vision; Precision
               agriculture; Sensor; Weed; Algorithms; Color image processing;
               Computer vision; Neural networks; Pattern recognition;
               Discriminant analysis; Weed detection; Weed control",
  issn      = "0001-2351"
}

@ARTICLE{Elstone2020-gf,
  title     = "High speed crop and weed identification in lettuce fields for
               precision weeding",
  author    = "Elstone, L and How, K Y and Brodie, S and Ghazali, M Z and Heath,
               W P and Grieve, B",
  journal   = "Sensors",
  publisher = "MDPI AG",
  volume    =  20,
  number    =  2,
  abstract  = "Precision weeding can significantly reduce or even eliminate the
               use of herbicides in farming. To achieve high-precision,
               individual targeting of weeds, high-speed, low-cost plant
               identification is essential. Our system using the red, green, and
               near-infrared reflectance, combined with a size differentiation
               method, is used to identify crops and weeds in lettuce fields.
               Illumination is provided by LED arrays at 525, 650, and 850 nm,
               and images are captured in a single-shot using a modified RGB
               camera. A kinematic stereo method is utilised to compensate for
               parallax error in images and provide accurate location data of
               plants. The system was verified in field trials across three
               lettuce fields at varying growth stages from 0.5 to 10 km/h.
               In-field results showed weed and crop identification rates of
               56\% and 69\%, respectively. Post-trial processing resulted in
               average weed and crop identifications of 81\% and 88\%,
               respectively. © 2020 by the authors. Licensee MDPI, Basel,
               Switzerland.",
  year      =  2020,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078004407&doi=10.3390%2fs20020455&partnerID=40&md5=2ffd3c6fdb09c92a85a92acb98bdf1a6",
  keywords  = "Kinetic stereo imaging; Multispectral imaging; Plant detection;
               Precision weeding; Crops; Geometrical optics; Infrared devices;
               Crop identification; Differentiation methods; Multispectral
               imaging; Near infra-red reflectances; Plant detections; Plant
               identification; Precision weeding; Stereo imaging; Stereo image
               processing; article; crop; field study; growth curve; human;
               illumination; infrared radiation; lettuce; nonhuman; velocity;
               weed",
  doi       = "10.3390/s20020455",
  pmc       =  31947520,
  issn      = "1424-8220"
}

@ARTICLE{Hemming2001-ue,
  title     = "Computer-vision-based weed identification under field conditions
               using controlled lighting",
  author    = "Hemming, J and Rath, T",
  journal   = "J. Agric. Eng. Res.",
  publisher = "Academic Press",
  volume    =  78,
  number    =  3,
  pages     = "233--243",
  abstract  = "The methods of digital image analysis were used to develop an
               identification system for weeds in crops. Two vegetable crops
               (cabbage and carrots) and a number of naturally occurring weed
               species were used to develop the classification algorithms.
               Considering the rougher environment, special attention was given
               to the open-field experiments. The images were obtained with a
               device that provided controlled lighting conditions. The analysis
               was carried out off-line. Eight different morphological features
               and three colour features were calculated for each single object
               to build a joint feature space. On the basis of sample data sets
               of each class, statistics were carried out to determine the
               features, which are suitable for discrimination. A membership
               function based on a fuzzy logic approach was formed and used for
               the classification. The experiments showed that colour features
               can help to increase the classification accuracy. Moreover,
               colour was used successfully for the segmentation procedure of
               plants and soil. Depending on growth stage, weed density and
               method of calculation between 51 and 95\% of the plants were
               classified correctly. Problems still exists by separating and
               allocating single plants in plant stands where the plants have
               grown together. Compared to other studies the plant
               identification system presented is an improvement, especially
               considering that the experiments were carried out under field
               conditions. © 2001 Silsoe Research Institute.",
  year      =  2001,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002811038&doi=10.1006%2fjaer.2000.0639&partnerID=40&md5=11eb6f8f661ae8a2b94ddcf758f67b99",
  doi       = "10.1006/jaer.2000.0639",
  issn      = "0021-8634"
}

@MISC{Wikipedia_contributors2023-xt,
  title        = "{CIELAB} color space",
  author       = "{Wikipedia contributors}",
  booktitle    = "Wikipedia, The Free Encyclopedia",
  abstract     = "The CIELAB color space, also referred to as L*a*b*, is a color
                  space defined by the International Commission on Illumination
                  (abbreviated CIE) in 1976.[a] It expresses color as three
                  values: L* for perceptual lightness and a* and b* for the four
                  unique colors of human vision: red, green, blue and yellow.
                  CIELAB was intended as a perceptually uniform space, where a
                  given numerical change corresponds to a similar perceived
                  change in color. While the LAB space is not truly perceptually
                  uniform, it nevertheless is useful in industry for detecting
                  small differences in color.",
  month        =  oct,
  year         =  2023,
  howpublished = "\url{https://en.wikipedia.org/w/index.php?title=CIELAB\_color\_space\&oldid=1181839243}",
  note         = "Accessed: --"
}

@INPROCEEDINGS{F_Rovira-Mas2013-st,
  title     = "Machine vision row crop detection using blob analysis and the
               Hough transform",
  author    = "{F. Rovira-Más} and {Q. Zhang} and {J. F. Reid and J. D. Will}",
  booktitle = "Automation Technology for Off-Road Equipment Proceedings of the
               2002 Conference",
  publisher = "American Society of Agricultural and Biological Engineers",
  address   = "St. Joseph, MI",
  abstract  = "One of the main stages in the automatic guidance of agricultural
               vehicles is the detection of crop rows. The purpose of this paper
               is to present a machine vision algorithm to find the rows in a
               soybean field. A video camera was mounted on a tractor in order
               to capture real images, and send them to a computer for
               processing. The vision algorithm was based on the Hough transform
               and blob analysis techniques, and its outputs were the equations
               of the lines representing the rows. Between one and five lines
               were generally found to determine the desired trajectory. The
               information provided by these lines was effective to identify the
               path to be followed by the tractor. The algorithm overcame image
               noise problems.",
  year      =  2013,
  url       = "http://elibrary.asabe.org/abstract.asp?aid=10022&t=1&redir=&redirType=",
  doi       = "10.13031/2013.10022",
  isbn      =  9781892769251
}

@ARTICLE{Perez-Ortiz2015-yk,
  title     = "A semi-supervised system for weed mapping in sunflower crops
               using unmanned aerial vehicles and a crop row detection method",
  author    = "Pérez-Ortiz, M and Peña, J M and Gutiérrez, P A and
               Torres-Sánchez, J and Hervás-Martínez, C and López-Granados, F",
  journal   = "Applied Soft Computing Journal",
  publisher = "Elsevier Ltd",
  volume    =  37,
  pages     = "533--544",
  abstract  = "This paper presents a system for weed mapping, using imagery
               provided by unmanned aerial vehicles (UAVs). Weed control in
               precision agriculture is based on the design of site-specific
               control treatments according to weed coverage. A key component is
               precise and timely weed maps, and one of the crucial steps is
               weed monitoring, by ground sampling or remote detection.
               Traditional remote platforms, such as piloted planes and
               satellites, are not suitable for early weed mapping, given their
               low spatial and temporal resolutions. Nonetheless, the ultra-high
               spatial resolution provided by UAVs can be an efficient
               alternative. The proposed method for weed mapping partitions the
               image and complements the spectral information with other sources
               of information. Apart from the well-known vegetation indexes,
               which are commonly used in precision agriculture, a method for
               crop row detection is proposed. Given that crops are always
               organised in rows, this kind of information simplifies the
               separation between weeds and crops. Finally, the system
               incorporates classification techniques for the characterisation
               of pixels as crop, soil and weed. Different machine learning
               paradigms are compared to identify the best performing
               strategies, including unsupervised, semi-supervised and
               supervised techniques. The experiments study the effect of the
               flight altitude and the sensor used. Our results show that an
               excellent performance is obtained using very few labelled data
               complemented with unlabelled data (semi-supervised approach),
               which motivates the use of weed maps to design site-specific weed
               control strategies just when farmers implement the early
               post-emergence weed control. © 2015 Elsevier B.V.",
  year      =  2015,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941766152&doi=10.1016%2fj.asoc.2015.08.027&partnerID=40&md5=a192dda1e5d932862aa8757bc7d4220c",
  keywords  = "Hough transform; Machine learning; Remote sensing; Support vector
               machine; Unmanned aerial vehicles (UAV); Weed detection;
               Agriculture; Aircraft control; Amphibious vehicles; Artificial
               intelligence; Crops; Hough transforms; Learning systems; Mapping;
               Photomapping; Remote sensing; Support vector machines; Unmanned
               aerial vehicles (UAV); Vehicles; Classification technique;
               Control strategies; Control treatments; Precision Agriculture;
               Sources of informations; Spatial and temporal resolutions;
               Spectral information; Weed detection; Weed control",
  doi       = "10.1016/j.asoc.2015.08.027",
  issn      = "1568-4946"
}

@ARTICLE{Lopez-Granados2016-jc,
  title     = "Early season weed mapping in sunflower using {UAV} technology:
               variability of herbicide treatment maps against weed thresholds",
  author    = "López-Granados, F and Torres-Sánchez, J and Serrano-Pérez, A and
               de Castro, A I and Mesas-Carrascosa, F-J and Peña, J-M",
  journal   = "Precis. Agric.",
  publisher = "Springer New York LLC",
  volume    =  17,
  number    =  2,
  pages     = "183--199",
  abstract  = "Site-specific weed management is defined as the application of
               customised control treatments only where weeds are located within
               the crop-field by using adequate herbicide according to weed
               emergence. The aim of the study was to generate georeferenced
               weed seedling infestation maps in two sunflower fields by
               analysing overlapping aerial images of the visible and
               near-infrared spectrum (using visible or multi-spectral cameras)
               collected by an unmanned aerial vehicle (UAV) flying at 30 and 60
               m altitudes. The main tasks focused on the configuration and
               evaluation of the UAV and its sensors for image acquisition and
               ortho-mosaicking, as well as the development of an automatic and
               robust image analysis procedure for weed seedling mapping used to
               design a site-specific weed management program. The control
               strategy was based on seven weed thresholds with 2.5 steps of
               increasing ratio from 0 \% (herbicide must be applied just when
               there is presence or absence of weed) to 15 \% (herbicide applied
               when weed coverage >15 \%). As a first step of the imagery
               analysis, sunflower rows were correctly matched to the
               ortho-mosaicked imagery, which allowed accurate image analysis
               using object-based image analysis [object-based-image-analysis
               (OBIA) methods]. The OBIA algorithm developed for weed seedling
               mapping with ortho-mosaicked imagery successfully classified the
               sunflower-rows with 100 \% accuracy in both fields for all flight
               altitudes and camera types, indicating the computational and
               analytical robustness of OBIA. Regarding weed discrimination,
               high accuracies were observed using the multi-spectral camera at
               any flight altitude, with the highest (approximately 100 \%)
               being those recorded for the 15 \% weed threshold, although
               satisfactory results from 2.5 to 5 \% thresholds were also
               observed, with accuracies higher than 85 \% for both field 1 and
               field 2. The lowest accuracies (ranging from 50 to 60 \%) were
               achieved with the visible camera at all flight altitudes and 0 \%
               weed threshold. Herbicide savings were relevant in both fields,
               although they were higher in field 2 due to less weed
               infestation. These herbicide savings varied according to the
               different scenarios studied. For example, in field 2 and at 30 m
               flight altitude and using the multi-spectral camera, a range of
               23–3 \% of the field (i.e., 77 and 97 \% of area) could be
               treated for 0–15 \% weed thresholds. The OBIA procedure computed
               multiple data which permitted calculation of herbicide
               requirements for timely and site-specific post-emergence weed
               seedling management. © 2015, Springer Science+Business Media New
               York.",
  year      =  2016,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939247593&doi=10.1007%2fs11119-015-9415-8&partnerID=40&md5=e438c3afa9196db838c3620dcd3b630c",
  keywords  = "Mosaicked imagery; object-based-image-analysis (OBIA); Remote
               sensing; Site-specific weed management (SSWM); Unmanned aerial
               vehicle (UAV); Weed threshold; aerial photograph; chemical
               control; herb; herbicide; image analysis; mapping method; remote
               sensing; seasonal variation; threshold; unmanned vehicle; weed;
               weed control; Helianthus",
  doi       = "10.1007/s11119-015-9415-8",
  issn      = "1385-2256"
}

@PROCEEDINGS{Zhang2006-lm,
  title    = "Crop/weed discrimination using near-infrared reflectance
              spectroscopy ({NIRS})",
  author   = "Zhang, Y and He, Y",
  volume   = "6047 II",
  abstract = "The traditional uniform herbicide application often results in an
              over chemical residues on soil, crop plants and agriculture
              produce, which have imperiled the environment and food security.
              Near-infrared reflectance spectroscopy (NIRS) offers a promising
              means for weed detection and site-specific herbicide application.
              In laboratory, a total of 90 samples (30 for each species) of the
              detached leaves of two weeds, i.e., threeseeded mercury (Acalypha
              australis L.) and fourleafed duckweed (Marsilea quadrifolia L.),
              and one crop soybean (Glycine max) was investigated for NIRS on
              325-1075 nm using a field spectroradiometer. 20 absorbance samples
              of each species after pretreatment were exported and the lacked Y
              variables were assigned independent values for partial least
              squares (PLS) analysis. During the combined principle component
              analysis (PCA) on 400-1000 nm, the PC1 and PC2 could together
              explain over 91\% of the total variance and detect the three plant
              species with 98.3\% accuracy. The full-cross validation results of
              PLS, i.e., standard error of prediction (SEP) 0.247, correlation
              coefficient (r) 0.954 and root mean square error of prediction
              (RMSEP) 0.245, indicated an optimum model for weed identification.
              By predicting the remaining 10 samples of each species in the PLS
              model, the results with deviation presented a 100\% crop/weed
              detection rate. Thus, it could be concluded that PLS was an
              available alternative of for qualitative weed discrimination on
              NIRS.",
  year     =  2006,
  url      = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749660146&doi=10.1117%2f12.710957&partnerID=40&md5=c967c2b300ec31e5b6908f6dc68d3e2c",
  keywords = "Near-infrared reflectance spectra; Partial least squares; Plant
              recognition; Site-specific weed management; Near-infrared
              reflectance spectra; Partial least squares; Plant recognition;
              Site-specific weed management; Crops; Herbicides; Least squares
              approximations; Plants (botany); Principal component analysis;
              Weed control; Infrared spectroscopy; Farm Crops; Herbicides;
              Infrared Spectroscopy; Plants; Weed Control",
  doi      = "10.1117/12.710957",
  isbn     =  9780819460806
}

@MISC{Honig2021-df,
  title        = "Farmworkers face a life-and-death commute to Arizona’s lettuce
                  fields",
  author       = "Honig, Esther",
  booktitle    = "Food and Environment Reporting Network",
  abstract     = "It’s one in the morning and the stars are out as hundreds of
                  people shuffle slowly along the wall that marks the U.S.
                  border in the small Mexican city of San Luis Río Colorado. In
                  heavy boots and wide…",
  month        =  apr,
  year         =  2021,
  howpublished = "\url{https://thefern.org/2021/04/farmworkers-face-a-life-and-death-commute-to-arizonas-lettuce-fields/}",
  note         = "Accessed: 2022-2-3",
  language     = "en"
}

@INCOLLECTION{Brivot1996-af,
  title     = "Segmentation of plants and weeds using infrared images",
  author    = "Brivot, R and Marchant, J A",
  booktitle = "Acta Horticulturae",
  publisher = "International Society for Horticultural Science",
  volume    =  406,
  pages     = "165--172",
  abstract  = "The work presented here is part of a project whose goal is to
               guide automatically a vehicle along rows of crops in order to
               target herbicide or pesticide accurately on weeds or plants. This
               paper deals with the segmentation of near-infrared images for
               discriminating plants, weeds, and soil. The algorithm described
               has been developed with a real-time parallel implementation and a
               real agricultural environment in mind. This algorithm uses
               techniques based on hysteresis thresholding and region labelling
               methods, blob-filtering and mathematical morphology. It can
               provide information on the size and the position of plants and
               weed patches as well as information that could be used either for
               guiding the vehicle or tracking plants and weeds. Successful
               segmentation has been done on several image sequences in diffuse
               light conditions. We show that it is possible to discriminate
               plants, weeds, and soil for different fields of view.",
  year      =  1996,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0013424884&doi=10.17660%2fActaHortic.1996.406.16&partnerID=40&md5=4066a07c2f9ea08f2704ccc101dbcb68"
}

@ARTICLE{Kamath2020-mx,
  title     = "Crop and weed discrimination using laws’ texture masks",
  author    = "Kamath, R and Balachandra, M and Prabhu, S",
  journal   = "International Journal of Agricultural and Biological Engineering",
  publisher = "Chinese Society of Agricultural Engineering",
  volume    =  13,
  number    =  1,
  pages     = "191--197",
  abstract  = "Computers have become an integral part of human lives. Computers
               are used in almost every field even in agriculture. Technologies
               like computer vision-based pattern recognition are being used to
               detect diseases and pests like weeds affecting the crop. The
               Weeds are unwanted plants growing among crops competing for
               nutrients, water, and sunlight. It can significantly reduce the
               quality and yield of the crops incurring a huge loss to the
               farmers. This paper investigates the use of texture features
               extracted from Laws’ texture masks for discrimination of Carrot
               crops and weeds in digital images. Laws’ texture method is one of
               the popular methods used to extract texture features in medical
               image processing, though not much explored in plant-based images
               or agricultural images. This experiment was carried out on two
               categories of benchmark digital image datasets of Carrot crop and
               Carrot weed respectively, which are publicly available. A total
               of 70 texture features were extracted. The dimensionality
               reduction technique was used to get the optimal features. These
               features were then used to train the Random Forest classifier.
               The results and observations from the experiment showed that the
               classifier achieved above 94\% accuracy. © 2020, Chinese Society
               of Agricultural Engineering. All rights reserved.",
  year      =  2020,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081009680&doi=10.25165%2fj.ijabe.20201301.4920&partnerID=40&md5=1fccce9c4eac30676cf336ee8bab310d",
  keywords  = "Classifier; Crop; Precision agriculture; Texture analysis; Weed",
  issn      = "1934-6344"
}

@INCOLLECTION{Sujith2021-gv,
  title     = "Classification of plant leaf using shape and texture features",
  author    = "Sujith, A and Neethu, R",
  editor    = "{Ranganathan G.} and {Chen J.} and {Rocha A.}",
  booktitle = "4th International Conference on Inventive Communication and
               Computational Technologies, ICICCT 2020",
  publisher = "Springer Science and Business Media Deutschland GmbH",
  volume    =  145,
  pages     = "269--282",
  abstract  = "Plants are mainly classified based on their characteristics of
               plant components such as leaves, flower, stem, root, seed, etc.
               Feature or characteristics is an essential fact for plant
               classification. A good feature extraction technique can help to
               extract quality features that give clear information to
               discriminate against each class. Computer engineers can help
               botanists to identify plants and their species through advanced
               computational techniques with the stipulated time. The proposed
               method gives efficient hybrid feature extraction using the PHOG,
               LBP, and GLCM feature extraction techniques. The fused feature
               vector is normalized and reduced size by Neighborhood Components
               Analysis (NCA). The efficient feature extraction and feature
               selection techniques have helped to improve the classification
               performance and reduced the model complexity. Two benchmark plant
               dataset Flavia and Swedish Leaves used to evaluate the proposed
               work. The primary contributions of this paper are introducing a
               multi-feature fusion shape and texture method for plant leaf
               image classification. The experimental result shows the average
               accuracy of the proposed method is 98.23\%, and the average
               computational complexity is 147.98 s. © The Editor(s) (if
               applicable) and The Author(s), under exclusive license to
               Springer Nature Singapore Pte Ltd 2021.",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092080888&doi=10.1007%2f978-981-15-7345-3_22&partnerID=40&md5=f92582e3689f8f5ec3bc7353a4113168",
  keywords  = "Gray level co-occurrence matrix; Local binary pattern;
               Neighborhood components analysis; Plant classification; Pyramid
               histogram of oriented gradients",
  doi       = "10.1007/978-981-15-7345-3\_22",
  isbn      =  9789811573446
}

@ARTICLE{Yang2021-oc,
  title     = "Plant leaf recognition by integrating shape and texture features",
  author    = "Yang, C",
  journal   = "Pattern Recognit.",
  publisher = "Elsevier Ltd",
  volume    =  112,
  abstract  = "Plant leaf identification is a significant challenge in the
               fields of computer vision and pattern recognition. This article
               presents a new approach to plant leaf identification, one that
               integrates shape and texture characteristics. First, we introduce
               the shape and texture features used by the proposed plant leaf
               recognition method. The proposed multiscale triangle descriptor
               (MTD) is employed to characterize the shape information of a
               plant leaf, and the local binary pattern histogram Fourier
               (LBP-HF) is used as the texture feature. Then, the shape and
               texture features of a leaf image are combined by weighted
               distance measurement, where L1 distance and chi-square distance
               are used for shape and texture features, respectively. The
               proposed approach provides a robust descriptor for the task of
               plant leaf recognition by combining the complementary MTD and
               LBP-HF features. The proposed approach has been thoroughly
               evaluated on three benchmark leaf datasets, including the Flavia,
               Swedish and MEW2012 leaf datasets. Our method achieves 77.6\%,
               85.7\%, and 67.5\% retrieval accuracy on the Flavia, Swedish and
               MEW2012 leaf datasets, respectively, while the corresponding
               classification accuracy is 99.1\%, 98.4\%, 95.6\%. The
               recognition performance of our method is better or comparable to
               prior state-of-the-art plant leaf recognition method. © 2020",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099478543&doi=10.1016%2fj.patcog.2020.107809&partnerID=40&md5=b0e8efbb8fe5fada80171a23a489b260",
  keywords  = "Local binary pattern; Multiscale triangle descriptor; Plant leaf
               recognition; Shape descriptor; Texture feature; Classification
               (of information); Textures; Chi Square distance; Classification
               accuracy; Local binary patterns; Retrieval accuracy; Shape and
               textures; Shape information; State of the art; Texture features;
               Pattern recognition",
  doi       = "10.1016/j.patcog.2020.107809",
  issn      = "0031-3203"
}

@INCOLLECTION{Montalvo2016-yo,
  title     = "Identification of plant textures in agricultural images by
               principal component analysis",
  author    = "Montalvo, M and Guijarro, M and Guerrero, J M and Ribeiro, Á",
  editor    = "{Martinez-Alvarez F.} and {Troncoso A.} and {Quintian H.} and
               {Corchado E.}",
  booktitle = "11th International Conference on Hybrid Artificial Intelligent
               Systems, HAIS 2016",
  publisher = "Springer Verlag",
  volume    =  9648,
  pages     = "391--401",
  abstract  = "In precision agriculture the extraction of green parts is a very
               important task. One of the biggest issues, when it comes to
               computer vision, is image segmentation, which has motivated the
               research conducted in this work. Our goal is the segmentation of
               vegetative and soil parts in the images. For this proposal a
               novel method of segmentation is defined in which different
               vegetation indices are calculated and through the reduction of
               components by principal component analysis (PCA) we obtain an
               enhanced greyscale image. Finally, by Otsu thresholding, we
               binarize the grayscale image isolating the green parts from the
               other elements in the image. © Springer International Publishing
               Switzerland 2016.",
  year      =  2016,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964036740&doi=10.1007%2f978-3-319-32034-2_33&partnerID=40&md5=a6843a72b7feb95dce515571d1d10454",
  keywords  = "Agricultural images; Precision agriculture; Principal component
               analysis; Segmentation image; Thresholding; Agriculture;
               Artificial intelligence; Computer vision; Image analysis; Image
               segmentation; Intelligent systems; Agricultural images;
               Gray-scale images; Grey scale images; Otsu thresholding;
               Precision Agriculture; Segmentation images; Thresholding;
               Vegetation index; Principal component analysis",
  doi       = "10.1007/978-3-319-32034-2\_33",
  isbn      =  9783319320335
}

@ARTICLE{Chaki2015-bc,
  title     = "Plant leaf recognition using texture and shape features with
               neural classifiers",
  author    = "Chaki, J and Parekh, R and Bhattacharya, S",
  journal   = "Pattern Recognit. Lett.",
  publisher = "Elsevier",
  volume    =  58,
  pages     = "61--68",
  abstract  = "Abstract This paper proposes a novel methodology of
               characterizing and recognizing plant leaves using a combination
               of texture and shape features. Texture of the leaf is modeled
               using Gabor filter and gray level co-occurrence matrix (GLCM)
               while shape of the leaf is captured using a set of curvelet
               transform coefficients together with invariant moments. Since
               these features are in general sensitive to the orientation and
               scaling of the leaf image, a pre-processing stage prior to
               feature extraction is applied to make corrections for varying
               translation, rotation and scaling factors. Efficacy of the
               proposed methods is studied by using two neural classifiers: a
               neuro-fuzzy controller (NFC) and a feed-forward back-propagation
               multi-layered perceptron (MLP) to discriminate between 31 classes
               of leaves. The features have been applied individually as well as
               in combination to investigate how recognition accuracies can be
               improved. Experimental results demonstrate that the proposed
               approach is effective in recognizing leaves with varying texture,
               shape, size and orientations to an acceptable degree. © 2015
               Elsevier B.V. All rights reserved.",
  year      =  2015,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925386662&doi=10.1016%2fj.patrec.2015.02.010&partnerID=40&md5=e14376e23185d1f11eb229149fcd2d61",
  keywords  = "Curvelet transform; Feed-forward back-propagation multi-layered
               perceptron; Gabor filter; Gray level co-occurrence matrix;
               Invariant moments; Neuro-fuzzy controller; Backpropagation;
               Feature extraction; Fuzzy filters; Gabor filters; Plants
               (botany); Textures; Curvelet transforms; Gray level co-occurrence
               matrix; Invariant moment; Multi-layered Perceptron; Neuro-fuzzy
               controller; Fuzzy inference",
  doi       = "10.1016/j.patrec.2015.02.010",
  issn      = "0167-8655"
}

@ARTICLE{Chaki2015-gf,
  title     = "Plant leaf recognition using texture and shape features with
               neural classifiers",
  author    = "Chaki, J and Parekh, R and Bhattacharya, S",
  journal   = "Pattern Recognit. Lett.",
  publisher = "Elsevier",
  volume    =  58,
  pages     = "61--68",
  abstract  = "Abstract This paper proposes a novel methodology of
               characterizing and recognizing plant leaves using a combination
               of texture and shape features. Texture of the leaf is modeled
               using Gabor filter and gray level co-occurrence matrix (GLCM)
               while shape of the leaf is captured using a set of curvelet
               transform coefficients together with invariant moments. Since
               these features are in general sensitive to the orientation and
               scaling of the leaf image, a pre-processing stage prior to
               feature extraction is applied to make corrections for varying
               translation, rotation and scaling factors. Efficacy of the
               proposed methods is studied by using two neural classifiers: a
               neuro-fuzzy controller (NFC) and a feed-forward back-propagation
               multi-layered perceptron (MLP) to discriminate between 31 classes
               of leaves. The features have been applied individually as well as
               in combination to investigate how recognition accuracies can be
               improved. Experimental results demonstrate that the proposed
               approach is effective in recognizing leaves with varying texture,
               shape, size and orientations to an acceptable degree. © 2015
               Elsevier B.V. All rights reserved.",
  year      =  2015,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925386662&doi=10.1016%2fj.patrec.2015.02.010&partnerID=40&md5=e14376e23185d1f11eb229149fcd2d61",
  keywords  = "Curvelet transform; Feed-forward back-propagation multi-layered
               perceptron; Gabor filter; Gray level co-occurrence matrix;
               Invariant moments; Neuro-fuzzy controller; Backpropagation;
               Feature extraction; Fuzzy filters; Gabor filters; Plants
               (botany); Textures; Curvelet transforms; Gray level co-occurrence
               matrix; Invariant moment; Multi-layered Perceptron; Neuro-fuzzy
               controller; Fuzzy inference",
  doi       = "10.1016/j.patrec.2015.02.010",
  issn      = "0167-8655"
}

@ARTICLE{Concepcion2020-qo,
  title   = "Lettuce Canopy Area Measurement Using Static Supervised Neural
             Networks Based on Numerical Image Textural Feature Analysis of
             Haralick and Gray Level Co-Occurrence Matrix",
  author  = "Concepcion, II, Ronnie S and Lauguico, Sandy C and Alejandrino,
             Jonnel D and Dadios, Elmer P and Sybingco, Edwin",
  journal = "Malang",
  volume  =  42,
  number  =  3,
  pages   = "472--486",
  month   =  oct,
  year    =  2020,
  url     = "http://dx.doi.org/10.17503/agrivita.v42i3.2528",
  doi     = "10.17503/agrivita.v42i3.2528"
}

@ARTICLE{Raja2020-wi,
  title     = "Real-time weed-crop classification and localisation technique for
               robotic weed control in lettuce",
  author    = "Raja, R and Nguyen, T T and Slaughter, D C and Fennimore, S A",
  journal   = "Biosystems Eng.",
  publisher = "Academic Press",
  volume    =  192,
  pages     = "257--274",
  abstract  = "Robotic weed control for vegetables is necessary to increase crop
               productivity, avoid intensive hand weeding as labour shortages in
               developed countries such as United States has led to a surge in
               food production costs. However, development of a reliable,
               intelligent robotic system for weed control in real-time for
               vegetables still remains a challenging task. The main issue
               arises while distinguishing crops from weeds in real-time. In
               this paper, a novel technique to crop signalling to distinguish
               crops from in-row weeds in complex natural scenarios, such as
               high weed densities commonly found on organic farms, in real-time
               using machine vision is presented. Crop signalling is a simple
               and low-cost technique in which a signalling compound is produced
               by or applied to the crop and where the signalling compound is
               machine readable and helps to create visual features that
               uniquely distinguish the crops from weeds. The crop and weed
               mapping algorithm presented here were specially designed and
               developed for a vision-based weeding robot equipped with a
               micro-jet herbicide-spraying system for weed control in a lettuce
               field. The proposed technique involves weed/crop mapping and
               decision making. Experimental results show that the crop
               detection accuracy was 99.75\%, and 98.11\% of sprayable weeds
               were detected. The proposed technique is highly accurate,
               reliable and more robust than other sensor-based techniques
               presented in the literature. © 2020 IAgrE",
  year      =  2020,
  url       = "http://dx.doi.org/10.1016/j.biosystemseng.2020.02.002",
  keywords  = "Automatic weed control; crop signalling; machine vision;
               precision agriculture; robotics; Computer vision; Conformal
               mapping; Costs; Crops; Decision making; Intelligent robots;
               Precision agriculture; Robotics; Vegetables; Crop classification;
               Crop productivity; Detection accuracy; Developed countries; Food
               production; Intelligent robotic systems; Novel techniques;
               Spraying system; Weed control",
  doi       = "10.1016/j.biosystemseng.2020.02.002",
  issn      = "1537-5110"
}

@ARTICLE{Gomathi2020-pj,
  title     = "Meta-heuristic based trained deep convolutional neural network
               for crop/weed classification",
  author    = "Gomathi, N and Jagtap, A M",
  journal   = "International Journal of Emerging Trends in Engineering Research",
  publisher = "World Academy of Research in Science and Engineering",
  volume    =  8,
  number    =  7,
  pages     = "3915--3926",
  abstract  = "Computer vision and camera sensors are hopeful technologies for
               capturing information and processing to facilitate autonomous
               cultivation with machine learning. Nowadays, field robots are
               widely utilized, which autonomously navigates in fields tasks for
               advanced developments. However, manual activities are also
               required for certain needs, for instance, controlling weed in
               organic carrot farming is carried out manually and it is
               essential to evade considerable crop yield loss. This paper makes
               an attempt to introduce a new automatic crop/weed classification
               under three major phases: (i) Pre-processing (ii) Feature
               Extraction and (iii) Classification. Initially, the images are
               converted to greyscale images under pre-processing stage.
               Further, from the pre-processed image, the features like “Grey
               Level Co-occurrence Matrix (GLCM) and Grey Level Runlength Matrix
               (GLRM) based texture features” are extracted. Finally, the
               classification is done by the hybrid classifiers, where both the
               Deep Convolutional Neural Network (DCNN) and Neural Network (NN)
               is incorporated. Finally, both the classified outputs are ORed to
               get the final classification output. Moreover, in order to
               enhance the performance of proposed work, it is planned to tune
               the hidden neurons of NN optimally via a new improved Moth Search
               Algorithm (MSA) and is named as Moth Search with new Step Length
               evaluation (MS-SL). Finally, the performance of proposed work is
               evaluated over other state-of-the-art models with respect to
               certain performance measures. © 2020, World Academy of Research
               in Science and Engineering. All rights reserved.",
  year      =  2020,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090297627&doi=10.30534%2fijeter%2f2020%2f161872020&partnerID=40&md5=4d864dcdcaf85499c6f0714982e3410f",
  keywords  = "Crop classification; DCNN; GLCM; GLRM; Moth Search Algorithm",
  doi       = "10.30534/ijeter/2020/161872020",
  issn      = "2347-3983"
}

@ARTICLE{Sabzi2020-af,
  title    = "An automatic visible-range video weed detection, segmentation and
              classification prototype in potato field",
  author   = "Sabzi, Sajad and Abbaspour-Gilandeh, Yousef and Arribas, Juan
              Ignacio",
  journal  = "Heliyon",
  volume   =  6,
  number   =  5,
  pages    = "e03685",
  abstract = "Weeds might be defined as destructive plants that grow and compete
              with agricultural crops in order to achieve water and nutrients.
              Uniform spray of herbicides is nowadays a common cause in crops
              poisoning, environment pollution and high cost of herbicide
              consumption. Site-specific spraying is a possible solution for the
              problems that occur with uniform spray in fields. For this reason,
              a machine vision prototype is proposed in this study based on
              video processing and meta-heuristic classifiers for online
              identification and classification of Marfona potato plant (Solanum
              tuberosum) and 4299 samples from five weed plant varieties: Malva
              neglecta (mallow), Portulaca oleracea (purslane), Chenopodium
              album L (lamb's quarters), Secale cereale L (rye) and Xanthium
              strumarium (coklebur). In order to properly train the machine
              vision system, various videos taken from two Marfona potato fields
              within a surface of six hectares are used. After extraction of
              texture features based on the gray level co-occurrence matrix
              (GLCM), color features, spectral descriptors of texture, moment
              invariants and shape features, six effective discriminant features
              were selected: the standard deviation of saturation (S) component
              in HSV color space, difference of first and seventh moment
              invariants, mean value of hue component (H) in HSI color space,
              area to length ratio, average blue-difference chrominance (Cb)
              component in YCbCr color space and standard deviation of in-phase
              (I) component in YIQ color space. Classification results show a
              high accuracy of 98\% correct classification rate (CCR) over the
              test set, being able to properly identify potato plant from
              previously mentioned five different weed varieties. Finally, the
              machine vision prototype was tested in field under real conditions
              and was able to properly detect, segment and classify weed from
              potato plant at a speed of up to 0.15 m/s.",
  month    =  may,
  year     =  2020,
  url      = "http://dx.doi.org/10.1016/j.heliyon.2020.e03685",
  keywords = "Agricultural engineering; Agricultural soil science; Agricultural
              technology; Agriculture; Classification; Computational
              intelligence; Computer engineering; Computer simulation; Food
              engineering; Food science; Horticulture; Machine vision;
              Meta-heuristic algorithms; Plant competition; Site-specific
              spraying; Video processing; Video processing.",
  doi      = "10.1016/j.heliyon.2020.e03685",
  pmc      = "PMC7260593",
  pmid     =  32490222,
  issn     = "2405-8440",
  language = "en"
}

@ARTICLE{Chawla2002-dk,
  title     = "{SMOTE}: Synthetic minority over-sampling technique",
  author    = "Chawla, N V and Bowyer, K W and Hall, L O and Kegelmeyer, W P",
  journal   = "J. Artif. Intell. Res.",
  publisher = "AI Access Foundation",
  volume    =  16,
  pages     = "321--357",
  abstract  = "An approach to the construction of classifiers from imbalanced
               datasets is described. A dataset is imbalanced if the
               classification categories are not approximately equally
               represented. Often real-world data sets are predominately
               composed of ``normal'' examples with only a small percentage of
               ``abnormal'' or ``interesting'' examples. It is also the case
               that the cost of misclassifying an abnormal (interesting) example
               as a normal example is often much higher than the cost of the
               reverse error. Under-sampling of the majority (normal) class has
               been proposed as a good means of increasing the sensitivity of a
               classifier to the minority class. This paper shows that a
               combination of our method of over-sampling the minority
               (abnormal) class and under-sampling the majority (normal) class
               can achieve better classifier performance (in ROC space) than
               only under-sampling the majority class. This paper also shows
               that a combination of our method of over-sampling the minority
               class and under-sampling the majority class can achieve better
               classifier performance (in ROC space) than varying the loss
               ratios in Ripper or class priors in Naive Bayes. Our method of
               over-sampling the minority class involves creating synthetic
               minority class examples. Experiments are performed using C4.5,
               Ripper and a Naive Bayes classifier. The method is evaluated
               using the area under the Receiver Operating Characteristic curve
               (AUC) and the ROC convex hull strategy.",
  month     =  jun,
  year      =  2002,
  url       = "http://dx.doi.org/10.1613/jair.953",
  doi       = "10.1613/jair.953",
  issn      = "1076-9757,1943-5037",
  language  = "en"
}

@ARTICLE{Nguyen2011-cb,
  title     = "Borderline over-sampling for imbalanced data classification",
  author    = "Nguyen, Hien M and Cooper, Eric W and Kamei, Katsuari",
  journal   = "International Journal of Knowledge Engineering and Soft Data
               Paradigms",
  publisher = "Inderscience Publishers",
  abstract  = "Traditional classification algorithms usually provide poor
               accuracy on the prediction of the minority class of imbalanced
               data sets. This paper proposes a new method for dealing with
               imbalanced data sets by over-sampling the borderline minority
               class instances. A Support Vector Machine (SVM) classifier is
               then trained to predict future instances. Compared with other
               over-sampling methods, the proposed method focuses only on the
               minority class instances residing along the decision boundary,
               due to the fact that this region is the most crucial for
               establishing the decision boundary. Furthermore, the artificial
               minority instances are generated in such a way that the regions
               of the minority class with fewer majority class instances would
               be expanded by extrapolation, otherwise the current boundary of
               the minority class would be consolidated by interpolation.
               Experimental results show that the proposed method achieves a
               better performance than other over-sampling methods.",
  month     =  apr,
  year      =  2011,
  url       = "https://www.inderscienceonline.com/doi/10.1504/IJKESDP.2011.039875",
  doi       = "10.1504/IJKESDP.2011.039875",
  language  = "en"
}

@INPROCEEDINGS{He2008-xr,
  title     = "{ADASYN}: Adaptive synthetic sampling approach for imbalanced
               learning",
  author    = "He, Haibo and Bai, Yang and Garcia, Edwardo A and Li, Shutao",
  booktitle = "2008 IEEE International Joint Conference on Neural Networks (IEEE
               World Congress on Computational Intelligence)",
  publisher = "IEEE",
  pages     = "1322--1328",
  month     =  jun,
  year      =  2008,
  url       = "https://ieeexplore.ieee.org/abstract/document/4633969/?casa_token=aMTa-okO_kgAAAAA:uZZErDzeepfydokxp7qMDoPicFA3XYMgYKuapTOPB2RoTNKb53gY0MGwn-ra6_XhUMvqErAF",
  doi       = "10.1109/ijcnn.2008.4633969",
  isbn      = "9781424418206,9781424418213",
  issn      = "2161-4393,2161-4407"
}

@ARTICLE{Last2017-rh,
  title         = "Oversampling for imbalanced learning based on {K}-means and
                   {SMOTE}",
  author        = "Last, Felix and Douzas, Georgios and Bacao, Fernando",
  journal       = "arXiv [cs.LG]",
  abstract      = "Learning from class-imbalanced data continues to be a common
                   and challenging problem in supervised learning as standard
                   classification algorithms are designed to handle balanced
                   class distributions. While different strategies exist to
                   tackle this problem, methods which generate artificial data
                   to achieve a balanced class distribution are more versatile
                   than modifications to the classification algorithm. Such
                   techniques, called oversamplers, modify the training data,
                   allowing any classifier to be used with class-imbalanced
                   datasets. Many algorithms have been proposed for this task,
                   but most are complex and tend to generate unnecessary noise.
                   This work presents a simple and effective oversampling method
                   based on k-means clustering and SMOTE oversampling, which
                   avoids the generation of noise and effectively overcomes
                   imbalances between and within classes. Empirical results of
                   extensive experiments with 71 datasets show that training
                   data oversampled with the proposed method improves
                   classification results. Moreover, k-means SMOTE consistently
                   outperforms other popular oversampling methods. An
                   implementation is made available in the python programming
                   language.",
  month         =  nov,
  year          =  2017,
  url           = "http://dx.doi.org/10.1016/j.ins.2018.06.056",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1711.00837",
  doi           = "10.1016/j.ins.2018.06.056"
}

@MISC{Wirth2004-li,
  title        = "Shape Analysis and Measurement",
  author       = "Wirth, Michael A",
  year         =  2004,
  url          = "http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf",
  howpublished = "Microscopy II: Image Analysis and 3D Reconstruction"
}

@PROCEEDINGS{Andujar2013-ot,
  title    = "Weed-crop discrimination using {LiDAR} measurements",
  author   = "Andújar, D and Moreno, H and Valero, C and Gerhards, R and
              Griepentrog, H W",
  abstract = "In this paper, we propose a new approach for discriminating maize
              and weed plants from soil surface, evaluating the accuracy and
              performance of a LiDAR sensor for vegetation detection using
              distance and reflection values. Field measurements were conducted
              in a maize field at growth stage BBCH 12-14. Static measurements
              were taken at different sampling areas with different weed
              densities. Regression analyses were carried out to assess the
              capabilities of the system for vegetation and soil measurement. A
              high relationship between LiDAR measured distance (LiDAR heights)
              and actual height was found. A binary logistic regression was used
              to predict the presence or absence of vegetation. The results
              permitted the discrimination of vegetation from the soil with
              accuracy up to 95\%. This technique offers significant promise for
              the development of real-time spatially selective weed control
              techniques, either as the sole weed detection system or in
              combination with other detection tools.",
  year     =  2013,
  url      = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893416174&partnerID=40&md5=2fd8355844d3f81a6dace79420c0da04",
  keywords = "Laser scanning; Plant height; Reflection; Weed detection; Binary
              logistic regression; Control techniques; Field measurement; Laser
              scanning; Lidar measurements; Plant height; Static measurements;
              Weed detection; Agriculture; Optical radar; Reflection; Regression
              analysis; Vegetation; Weed control",
  isbn     =  9789086862245
}

@ARTICLE{Shahbazi2021-kr,
  title     = "Comparison of crop and weed height, for potential differentiation
               of weed patches at harvest",
  author    = "Shahbazi, N and Flower, K C and Callow, J N and Mian, A and
               Ashworth, M B and Beckie, H J",
  journal   = "Weed Res.",
  publisher = "Blackwell Publishing Ltd",
  volume    =  61,
  number    =  1,
  pages     = "25--34",
  abstract  = "Weeds and weed control are major production costs in global
               agriculture, with increasing challenges associated with
               herbicide-based management because of concerns with chemical
               residue and herbicide resistance. Non-chemical weed management
               may address these challenges but requires the ability to
               differentiate weeds from crops. Harvest is an ideal opportunity
               for the differentiation of weeds that grow taller than the crop,
               however, the ability to differentiate late-season weeds from the
               crop is unknown. Weed mapping enables farmers to locate weed
               patches, evaluate the success of previous weed management
               strategies, and assist with planning for future herbicide
               applications. The aim of this study was to determine whether weed
               patches could be differentiated from the crop plants, based on
               height differences. Field surveys were carried out before crop
               harvest in 2018 and 2019, where a total of 86 and 105 weedy
               patches were manually assessed respectively. The results of this
               study demonstrated that across the 191 assessed weedy patches, in
               97\% of patches with Avena fatua (wild oat) plants, 86\% with
               Raphanus raphanistrum (wild radish) plants and 92\% with Sonchus
               oleraceus L. (sow thistles) plants it was possible to distinguish
               the weeds taller than the 95\% of the crop plants. Future work
               should be dedicated to the assessment of the ability of remote
               sensing methods such as Light Detection and Ranging to detect and
               map late-season weed species based on the results from this study
               on crop and weed height differences. © 2020 European Weed
               Research Society",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097017406&doi=10.1111%2fwre.12450&partnerID=40&md5=9100bbbcdff8dafcf5ee83f8c55d1674",
  keywords  = "height; late-season weed control; site-specific weed management;
               weed-crop differentiation; cereal; comparative study; crop plant;
               differentiation; field survey; harvesting; height; herbicide;
               lidar; mapping method; remote sensing; weed; weed control; Avena
               fatua; Raphanus raphanistrum; Raphanus sativus; Sonchus oleraceus",
  doi       = "10.1111/wre.12450",
  issn      = "0043-1737"
}

@MISC{Prosser1998-mi,
  title        = "Convex Hull",
  author       = "Prosser, Patrick",
  month        =  mar,
  year         =  1998,
  howpublished = "Algorithms and Data Structures"
}

@ARTICLE{Fawcett2007-uq,
  title    = "{ROC} graphs: Notes and practical considerations for researchers",
  author   = "Fawcett, Tom",
  abstract = "Receiver Operating Characteristics (ROC) graphs are a useful
              technique for organizing classifiers and visualizing their
              performance. ROC graphs are commonly used in medical decision
              making, and in recent years have been increasingly adopted in the
              machine learning and data mining research communities. Although
              ROC graphs are apparently simple, there are some common
              misconceptions and pitfalls when using them in practice. This
              article serves both as a tutorial introduction to ROC graphs and
              as a practical guide for using them in research.",
  year     =  2007,
  url      = "https://www.ehu.eus/ccwintco/uploads/8/83/Notes_on_roc_curves-2009.pdf"
}

@BOOK{Gonzalez2016-xu,
  title     = "Digital Image Processing",
  author    = "Gonzalez, Rafael C and Woods, Richard E",
  publisher = "Addison-Wesley Pub (Sd)",
  year      =  2016,
  isbn      =  9780133356724
}

@ARTICLE{Barati2011-oj,
  title    = "Comparison the accuracies of different spectral indices for
              estimation of vegetation cover fraction in sparse vegetated areas",
  author   = "Barati, Susan and Rayegani, Behzad and Saati, Mehdi and Sharifi,
              Alireza and Nasri, Masoud",
  journal  = "Egypt. J. Remote Sens. Space Sci.",
  volume   =  14,
  number   =  1,
  pages    = "49--56",
  abstract = "Quantitative estimation of canopy biophysical variables are very
              important in different studies such as meteorology, agriculture
              and ecology, so knowledge of the spatial and temporal distribution
              of these variables would be highly beneficial. Meanwhile, remote
              sensing is known as an important source of information to estimate
              fractional vegetation cover in large areas. Today spectral indices
              have been very popular in the remote sensing of vegetation
              features. But often reflections of soil and rocks are much more
              than reflections of sparse vegetation in these areas, that makes
              separation of plant signals difficult. So in this study measured
              fractional vegetation cover of a desert area were evaluated with
              20 vegetation indices in five different categories as the most
              appropriate category, or indicator for desert vegetation to be
              identified. The five categories were including: (1) conventional
              ratio and differential indices such as NDVI; (2) indices corrected
              and derived from the traditional indicators such as NDVIc and
              GNDVI; (3) soil reflectance adjusted indices such as SAVI; (4)
              triangle indices based on three discreet bands in their equation
              (Green, Red and NIR) like TVI; and (5) non-conventional ratio and
              differential indices such as CI. According to the results of this
              research, DVI index with 0.668 the coefficient of determination
              (R2) showed the best fractional vegetation cover estimation. But
              according to the sparse vegetation in desert areas and the results
              of this research it seems none of these indicators alone can
              accurately estimate the percentage of vegetation cover, however,
              to do a proper estimation it is possible to enter data of these
              indices in a multivariate regression model. Using this method
              enabled us to increase the coefficient of determination of
              fractional vegetation cover estimation model up to 0.797.",
  month    =  jun,
  year     =  2011,
  url      = "https://www.sciencedirect.com/science/article/pii/S1110982311000147",
  keywords = "Vegetation cover fraction; Remote sensing; LISS III; Vegetation
              indices",
  doi      = "10.1016/j.ejrs.2011.06.001",
  issn     = "1110-9823"
}

@MISC{Various_undated-lg,
  title        = "{CyVerse} Documentation",
  author       = "{Various}",
  howpublished = "\url{https://learning.cyverse.org/\_/downloads/foss/en/foss-2020-spring/pdf/}"
}

@MISC{Various_undated-oj,
  title        = "{CircleCI} Documentation",
  author       = "{Various}",
  howpublished = "\url{https://circleci.com/docs/2.0/configuration-reference/}"
}

@MISC{Various_undated-yv,
  title        = "{HSL} and {HSV}",
  author       = "{Various}",
  booktitle    = "Wikipedia",
  howpublished = "\url{https://en.wikipedia.org/wiki/HSL\_and\_HSV}"
}

@ARTICLE{Maenpaa2000-ec,
  title     = "Robust texture classification by subsets of local binary patterns",
  author    = "Mäenpää, M and Ojala, O and Pietikäinen, M and Soriano, M",
  journal   = "Proceedings - International Conference on Pattern Recognition",
  publisher = "Institute of Electrical and Electronics Engineers Inc.",
  volume    =  15,
  number    =  3,
  pages     = "935--938",
  abstract  = "Recently, a nonparametric approach to texture analysis has been
               developed, in which the distributions of simple texture measures
               based on local binary patterns (LBP) are used for texture
               description. The basic LBP encodes 256 simple feature detectors
               in a single 3x3 operator. This paper shows that a properly
               selected subset of patterns encoded in LBP forms an efficient and
               robust texture description which can achieve better
               classification rates in comparison with the whole LBP histogram.
               Experiments on classification of textures from the
               Columbia-Utrecht (CURET) data-base demonstrate the robustness of
               the approach. © 2000 IEEE.",
  year      =  2000,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750906241&partnerID=40&md5=655ca3b93fb4030f1a19bbca814d1283",
  keywords  = "Feature extraction; Signal processing; Speech recognition;
               Classification rates; Feature detector; Local binary pattern
               (LBP); Local binary patterns; Nonparametric approaches; Texture
               analysis; Texture classification; Texture description;
               Classification (of information)",
  issn      = "1051-4651"
}

@INCOLLECTION{Sheeba2021-pd,
  title     = "A Comparison Study on Various Continuous Integration Tools in
               Software Development",
  author    = "{Sheeba} and Shidaganti, G and Gosar, A P",
  editor    = "{Joshi A.} and {Khosravy M.} and {Gupta N.}",
  booktitle = "4th International Conference on Information and Communication
               Technology for Intelligent Systems,ICTIS 2020",
  publisher = "Springer Science and Business Media Deutschland GmbH",
  volume    =  141,
  pages     = "65--76",
  abstract  = "Continuous integration (CI) frameworks are currently the basis
               for a few software development projects that reduce the time and
               cost of the software. Most of the companies provide CI tools with
               similar facilities and some companies build their own CI tool.
               However, it does not mean that the costliest product is better
               than a low-cost or open-source device. Generally, all of these
               tools are intended to make the Product Building Software Process
               easy and automated by quality assurance and time reduction. In
               spite of this fact, ongoing integration tools have their own
               merits and demerits, so it is very important and sometimes
               difficult to choose the right CI tool for a project. The wrong
               choice of tools can reduce the overall flexibility and quality of
               the software. A few continuous integration tools, such as
               Jenkins, TravisCI, Codeship, Bamboo, TeamCity and CircleCI, which
               implement CI practices, are generally adopted by programmers,
               developers. The main objective of this paper is to demonstrate
               the analysis, usefulness and comparison of selected tools and to
               help in selecting the most compatible CI implementation tool that
               meets project requirements. © 2021, The Editor(s) (if applicable)
               and The Author(s), under exclusive license to Springer Nature
               Singapore Pte Ltd.",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096450028&doi=10.1007%2f978-981-15-7106-0_7&partnerID=40&md5=2c7c1f0fbfe2113290377747fc59fedf",
  keywords  = "CI tool; Continuous integration; Continuous integration
               framework; Software development projects; Software project",
  doi       = "10.1007/978-981-15-7106-0\_7",
  isbn      =  9789811571053
}

@PROCEEDINGS{Liao2020-xv,
  title     = "Modelling {CI}/{CD} Pipeline through Agent-Based Simulation",
  author    = "Liao, Q",
  editor    = "{Vieira M.} and {Madeira H.} and {Antunes N.} and {Zheng Z.}",
  publisher = "Institute of Electrical and Electronics Engineers Inc.",
  abstract  = "The need for rapid and efficient software development pushes the
               demand for automation in the phases of build, test, and release.
               Thereby, the methodology of Continuous Integration and Continuous
               Deployment (CI/CD) emerges, which then gives birth to a set of
               CI/CD enabling services, such as Travis CI and Jenkins. Those
               services facilitate the automatic compilation, connection
               tracking, and packaging of new features. They not only
               incorporate playgrounds for testing and functionality
               verification but also enable the final delivery.Poor
               understanding and execution in CI/CD operations can result in
               slowing and even halting the pace of a software project. Many
               bottlenecks of CI/CD pipeline might occur due to its incorrect
               configurations, i.e. the inadequate level of automation, the
               unsuitable load capacity and the suboptimal queueing strategy.
               However, understanding the actual CI/CD pipeline is hard since
               its performance varies significantly with different hosting
               machines, technologies and plugins. On the other hand, finding a
               way to analyse and improve the settings of CI/CD pipeline brings
               great managerial and economic benefits since an optimal
               configuration implies the eventual high efficiency. To that end,
               this study attempts to design a model that can not only capture
               the abstraction of the pipeline but also provides a testing
               environment for the impersonal influencers of CI/CD performance.
               The current study, therefore, aims to contribute (1) a pipeline
               model based on the logic of the queueing system and enabled by
               agent-based simulation, and (2) an experimental environment which
               allows the testing of different settings and operation scenarios.
               © 2020 IEEE.",
  year      =  2020,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099854360&doi=10.1109%2fISSREW51248.2020.00059&partnerID=40&md5=a6801c3b2d534a7dc4cd1016223e47d5",
  keywords  = "Agent-based Modelling; CI/CD; Multi-agent Simulation; Pipeline
               Simulation; Queueing System",
  doi       = "10.1109/ISSREW51248.2020.00059",
  isbn      =  9781728198705
}

@ARTICLE{Fawcett2006-zx,
  title     = "An introduction to {ROC} analysis",
  author    = "Fawcett, Tom",
  journal   = "Pattern Recognit. Lett.",
  publisher = "Elsevier B.V",
  volume    =  27,
  number    =  8,
  pages     = "861--874",
  abstract  = "Receiver operating characteristics (ROC) graphs are useful for
               organizing classifiers and visualizing their performance. ROC
               graphs are commonly used in medical decision making, and in
               recent years have been used increasingly in machine learning and
               data mining research. Although ROC graphs are apparently simple,
               there are some common misconceptions and pitfalls when using them
               in practice. The purpose of this article is to serve as an
               introduction to ROC graphs and as a guide for using them in
               research.",
  month     =  jun,
  year      =  2006,
  url       = "http://dx.doi.org/10.1016/j.patrec.2005.10.010",
  keywords  = "Artificial intelligence;Classifier evaluation;Computer
               science;Data mining;Evaluation metrics;Machine learning;natural
               sciences;Receiver operating characteristic;ROC analysis;Simple
               (abstract algebra)",
  doi       = "10.1016/j.patrec.2005.10.010",
  issn      = "0167-8655,1872-7344"
}

@ARTICLE{Msibi2021-to,
  title    = "High pesticide inhalation exposure from multiple spraying sources
              amongst applicators in Eswatini, Southern Africa",
  author   = "Msibi, Sithembiso S and Chen, Chung-Yu and Chang, Cheng-Ping and
              Chen, Chiou-Jong and Chiang, Su-Yin and Wu, Kuen-Yuh",
  journal  = "Pest Manag. Sci.",
  volume   =  77,
  number   =  10,
  pages    = "4303--4312",
  abstract = "BACKGROUND: Serious concerns surround the potential risks
              resulting from inhalation exposure to pesticides amongst
              agricultural workers when mixing and applying these compounds. In
              Eswatini (formerly known as Swaziland), Southern Africa,
              pesticides are widely used to improve the yield and quality of
              sugar cane production, the largest contributor to the country's
              economy. We assessed applicators' inhalation exposures from
              multiple spraying sources to four commonly used herbicides in
              Eswatini. RESULTS: Analysis of 76 personal air samples by liquid
              chromatography with tandem mass spectrometry (LC-MS/MS) revealed
              four pesticides: ametryn, atrazine, pendimethalin and
              2,4-dichlorophenoxyacetic acid, with mean concentrations of 36.91,
              21.57, 31.05 and 0.89 μg m-3 , respectively. These inhalation
              exposures are much higher than those recorded in previous similar
              studies. CONCLUSION: Although all applicators in this study used
              personal protective equipment (PPE), they nevertheless recorded
              high levels of inhalation exposure to commonly used pesticides.
              Our findings suggest that in addition to observing mandated
              regular changing and cleaning practices with PPE for ultimate
              personal protection, pesticide applicators should distance
              themselves from each other when spraying to effectively reduce
              their exposure to pesticides from multiple spraying sources.
              Further studies are needed to determine the optimal spraying
              distance between pesticide applicators. © 2021 Society of Chemical
              Industry.",
  month    =  oct,
  year     =  2021,
  url      = "http://dx.doi.org/10.1002/ps.6459",
  keywords = "Africa; Eswatini; applicators; inhalation exposure; multiple
              spraying sources; pesticides",
  doi      = "10.1002/ps.6459",
  pmid     =  33942970,
  issn     = "1526-498X,1526-4998",
  language = "en"
}

@ARTICLE{Rydz2021-ar,
  title    = "Estimating Exposure to Three Commonly Used, Potentially
              Carcinogenic Pesticides (Chlorolathonil, 2,4-{D}, and Glyphosate)
              Among Agricultural Workers in Canada",
  author   = "Rydz, Ela and Larsen, Kristian and Peters, Cheryl E",
  journal  = "Ann Work Expo Health",
  volume   =  65,
  number   =  4,
  pages    = "377--389",
  abstract = "OBJECTIVES: Certain pesticides have been associated with adverse
              health outcomes including cancer and reproductive harms. However,
              little is known about the prevalence of occupational pesticide
              exposure among agricultural workers in Canada. The purpose of this
              study was to estimate the prevalence and likelihood of
              occupational exposure to pesticides in Canada's agricultural
              industry, using three commonly used, potentially carcinogenic
              pesticides [chlorothalonil, 2,4-dichlorophenoxyacetic acid
              (2,4-D), and glyphosate] as an example. METHODS: Estimates were
              calculated using the Canadian Census of Population and the Census
              of Agriculture. The number of workers and the proportion of farms
              applying 'herbicides' or 'fungicides' by farm type was estimated
              using survey data from the Census of Agriculture. These values
              were multiplied to yield the potential number of workers at risk
              of exposure. Likelihood of exposure (i.e. exposed, probably
              exposed, and possibly exposed) was then qualitatively assigned
              using information on crop type, primary expected tasks, crop
              production practices, and residue transfer data. Additional
              agricultural workers who are at risk of exposure but not captured
              by the Census of Agriculture were identified using the 2016 Census
              of Population. RESULTS: An estimated range of 37 700-55 800
              workers (11-13\% of agricultural workers) were exposed to
              glyphosate in Canada while 30 800-43 600 workers (9-11\%) and
              9000-14 100 (2.9-3.2\%) were exposed to 2,4-D and chlorothalonil,
              respectively. Approximately 70-75\% of workers at risk of exposure
              were considered probably or possibly exposed to any of the
              pesticides. Glyphosate exposure was most common among workers in
              oilseed (29\% of oilseed farm workers exposed) and dry pea/bean
              farms (28\%), along with those providing support activities for
              farms (31\%). 2,4-D exposure was most common in corn (28\%), other
              grain (28\%), and soybean farms (27\%), while chlorothalonil
              exposure was more likely among greenhouse, nursery, and
              floriculture workers (42\%), workers on farms (28\%, for
              occupations not captured by the Census of Agriculture,
              specifically), and those providing support activities for farms
              (20\%). Regional variations broadly reflected differences in farm
              types by province. CONCLUSIONS: This study estimated the
              prevalence of occupational exposure to three pesticides in Canada.
              Seasonal and temporary agricultural workers, which were captured
              by the Census of Agriculture, contributed to many additionally
              exposed workers. A large percent of the workers who were
              considered at risk of exposure were considered probably or
              possibly exposed, indicating a need for enhanced data collection
              and availability on pesticide use data in Canada. The study's
              methods can be applied to estimate workers' exposures to other
              pesticides within the agricultural industry.",
  month    =  may,
  year     =  2021,
  url      = "http://dx.doi.org/10.1093/annweh/wxaa109",
  keywords = "2, 4-D; agriculture; chlorothalonil; glyphosate; occupational
              exposure; pesticides",
  doi      = "10.1093/annweh/wxaa109",
  pmid     =  33336237,
  issn     = "2398-7316,2398-7308",
  language = "en"
}

@ARTICLE{Silva-Madera2021-cx,
  title     = "Pesticide Contamination in Drinking and Surface Water in the
               Cienega, Jalisco, Mexico",
  author    = "Silva-Madera, R J and Salazar-Flores, J and Peregrina-Lucano, A A
               and Mendoza-Michel, J and Ceja-Gálvez, H R and Rojas-Bravo, D and
               Reyna-Villela, M Z and Torres-Sánchez, E D",
  journal   = "Water Air Soil Pollut.",
  publisher = "Springer Science and Business Media Deutschland GmbH",
  volume    =  232,
  number    =  2,
  abstract  = "Sixty percent of global agricultural production depends on the
               use of pesticides, despite their adverse effects on human health
               and the ecosystem. In Mexico, the application of these products
               has been exacerbated, including pesticides already banned in
               other countries. The objective of this study was to determine
               pesticide concentrations in samples of water purification plants
               and surface water from the Cienega area of Jalisco, Mexico. A
               survey of 119 farmers with occupational exposure to pesticides
               was carried out in order to obtain information on the most
               frequently used pesticides. Subsequently, 51 samples taken at 7
               different sites were analyzed using liquid chromatography and
               mass-mass spectrometry. The most frequently used pesticides were
               organophosphates (28.87\%), pyrethroids (12.89\%), and the
               herbicide paraquat (31.95\%). In surface water, the prevalent
               pesticides were glyphosate (56.96–510.46 ppb) and malathion
               (311.76–863.49 ppb). Glyphosate levels were higher than the
               limits acceptable in daily water intake in Cumuato. Malathion
               levels exceeded the limits permissible by EPA in water
               purification plants in urban public establishments (100 ppb for
               children, and 200 ppb for adults). In addition, a
               multidimensional scaling analysis showed that the sampled sites
               could be grouped into 2 different bodies of water, based on
               similarities in their glyphosate concentrations (stress = 0.005),
               while the concentrations of malathion were heterogeneous (stress
               = 0.001). © 2021, The Author(s).",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099950709&doi=10.1007%2fs11270-021-04990-y&partnerID=40&md5=321232d9101012746bb00cd7019ec677",
  keywords  = "Cienega-Jalisco; HPLC-MS/MS; Pesticides; Surface water; Water
               purification plants; Agricultural robots; Agriculture;
               Herbicides; Liquid chromatography; Mass spectrometry; Potable
               water; Purification; Water treatment plants; Adverse effect;
               Agricultural productions; Herbicide paraquat; Multidimensional
               scaling analysis; Occupational exposure; Pesticide
               concentrations; Pesticide contaminations; Water purification
               plants; Surface waters; drinking water; glyphosate; malathion;
               organophosphate; paraquat; pesticide; pyrethroid; concentration
               (composition); drinking water; glyphosate; liquid chromatography;
               malathion; mass spectrometry; occupational exposure; surface
               water; water pollution; water treatment plant; agricultural
               worker; Article; concentration (parameter); fluid intake; human;
               Jalisco; liquid chromatography-mass spectrometry; occupational
               exposure; surface water hydrology; urban area; water
               contamination; water management; water sampling; Jalisco; Mexico
               [North America]",
  doi       = "10.1007/s11270-021-04990-y",
  issn      = "0049-6979"
}

@ARTICLE{Pedroso2021-bk,
  title    = "Cancer and occupational exposure to pesticides: a bibliometric
              study of the past 10 years",
  author   = "Pedroso, Thays Millena Alves and Benvindo-Souza, Marcelino and de
              Araújo Nascimento, Felipe and Woch, Júlia and Dos Reis, Fabiana
              Gonçalves and de Melo E Silva, Daniela",
  journal  = "Environ. Sci. Pollut. Res. Int.",
  abstract = "Occupational exposure to pesticides has been identified as a major
              trigger of the development of cancer. Pesticides can cause
              intoxication in the individuals who manipulate them through either
              inhalation, ingestion, or dermal contact. Given this, we
              investigated the association between the incidence of cancer and
              occupational exposure to pesticides through a bibliometric
              analysis of the studies published between 2011 and 2020, based on
              62 papers selected from the Scopus database. The results indicated
              an exponential increase in the number of studies published over
              the past decade, with most of the research being conducted in the
              USA, France, India, and Brazil, although a further 17 nations were
              also involved in the research on the association between cancer
              and pesticides. The principal classes of pesticides investigated
              in relation to their role in intoxication and cancer were
              insecticides, herbicides, and fungicides. The types of cancer
              reported most frequently were multiple myeloma, bladder cancer,
              non-Hodgkin's lymphoma, prostate cancer, leukemia, and breast
              cancer. Despite the known association between pesticides and
              cancer, studies are still relatively scarce in comparison with the
              global scale of the use of these xenobiotic substances, which is
              related to the increasing demand for agricultural products
              throughout the world.",
  month    =  oct,
  year     =  2021,
  url      = "http://dx.doi.org/10.1007/s11356-021-17031-2",
  keywords = "Agriculture; Cancer; DNA; Diseases; Farm workers; Health;
              Pesticides",
  doi      = "10.1007/s11356-021-17031-2",
  pmc      = "PMC8525621",
  pmid     =  34668133,
  issn     = "0944-1344,1614-7499",
  language = "en"
}

@ARTICLE{Macfarlane2008-am,
  title    = "Training and other predictors of personal protective equipment use
              in Australian grain farmers using pesticides",
  author   = "Macfarlane, E and Chapman, A and Benke, G and Meaklim, J and Sim,
              M and McNeil, J",
  journal  = "Occup. Environ. Med.",
  volume   =  65,
  number   =  2,
  pages    = "141--146",
  abstract = "OBJECTIVES: To investigate patterns of use of personal protective
              equipment (PPE) to reduce pesticide exposure in a sample of
              Australian farmers and also to assess the influence of possible
              predictive factors. METHODS: A cross-sectional survey of 1102
              farmers recruited through the Victorian Farmers Federation (VFF)
              was conducted. A written questionnaire was filled out by
              participants at VFF meetings attended by a visiting research
              assistant. Participants answered questions about frequency of
              pesticide use and PPE items they usually used when doing two
              different pesticide-related tasks, mixing and application, of each
              of four classes of pesticides. They also answered questions about
              personal characteristics, farm characteristics, farming
              activities, career and health. RESULTS: Nearly all surveyed
              farmers had ever used pesticides, and over 87\% had used
              Herbicides or Animal Health Products in the previous 12 months.
              Non-use of PPE was frequently reported, with up to 10-40\% of
              farmers routinely using no PPE at all when using pesticides.
              Across all pesticide classes, PPE use was higher for pesticide
              mixing than for application. In multivariate analyses PPE use
              appeared to be most strongly associated with younger age and farm
              chemical training. CONCLUSIONS: PPE use across all pesticide
              classes was poor, indicating the possibility of clinically
              significant pesticide exposure in many farmers. Given that PPE use
              was found to be associated with farm chemical training, the
              authors suggest that training is likely to be an important
              intervention for reducing farmers' pesticide exposure. Poor uptake
              of farm chemical training by farmers and the aging farming
              workforce are causes for concern in the light of these findings.",
  month    =  feb,
  year     =  2008,
  url      = "http://dx.doi.org/10.1136/oem.2007.034843",
  doi      = "10.1136/oem.2007.034843",
  pmid     =  17704194,
  issn     = "1351-0711,1470-7926",
  language = "en"
}

@MISC{US_Bureau_of_Labor_Statistics2021-yi,
  title        = "Occupational Employment and Wages in Yuma — May 2020 : Western
                  Information Office : {U}.{S}. Bureau of Labor Statistics",
  author       = "{US Bureau of Labor Statistics}",
  booktitle    = "U.S. Bureau of Labor Statistics",
  abstract     = "Workers in the Yuma, AZ Metropolitan Statistical Area had an
                  average (mean) hourly wage of $20.75 in May 2020, 23 percent
                  below the nationwide average of $27.07.",
  month        =  jun,
  year         =  2021,
  howpublished = "\url{https://www.bls.gov/regions/west/news-release/occupationalemploymentandwages\_yuma.htm}",
  note         = "Accessed: 2022-1-28",
  language     = "en"
}

@MISC{noauthor_undated-tt,
  title       = "pypylon: The official python wrapper for the pylon Camera
                 Software Suite",
  institution = "Github",
  abstract    = "The official python wrapper for the pylon Camera Software Suite
                 - basler/pypylon: The official python wrapper for the pylon
                 Camera Software Suite",
  url         = "https://github.com/basler/pypylon",
  language    = "en"
}

@MISC{Wikipedia_contributors2022-qd,
  title        = "{YCbCr}",
  author       = "{Wikipedia contributors}",
  booktitle    = "Wikipedia, The Free Encyclopedia",
  abstract     = "YCbCr, Y′CbCr, or Y Pb/Cb Pr/Cr, also written as YCBCR or
                  Y′CBCR, is a family of color spaces used as a part of the
                  color image pipeline in video and digital photography systems.
                  Y′ is the luma component and CB and CR are the blue-difference
                  and red-difference chroma components. Y′ (with prime) is
                  distinguished from Y, which is luminance, meaning that light
                  intensity is nonlinearly encoded based on gamma corrected RGB
                  primaries.",
  month        =  jan,
  year         =  2022,
  howpublished = "\url{https://en.wikipedia.org/w/index.php?title=YCbCr\&oldid=1069029896}",
  note         = "Accessed: --"
}

@MISC{Siemens2021-vn,
  author       = "Siemens, Mark",
  editor       = "McGinnis, Evan",
  abstract     = "Labor costs in Yuma, AZ",
  month        =  aug,
  year         =  2021,
  howpublished = "personal communication"
}

@ARTICLE{Siemens2020-ds,
  title   = "High Speed Centimeter Scale Resolution Sprayers for Precision Weed
             Control in Vegetable Crops",
  author  = "Siemens, M C",
  journal = "AZ Veg IPM Update",
  volume  =  11,
  number  =  8,
  month   =  apr,
  year    =  2020,
  url     = "https://acis.cals.arizona.edu/agricultural-ipm/vegetables/vegetable-ipm-updates/high-speed-centimeter-scale-resolution-sprayers-for-precision-weed-control-in-vegetable-crops?Biometeorologypage=4&Insectpage=15&Weedspage=3&Trappingpage=7&PlantDiagnosticpage=6"
}

@ARTICLE{Ballard1981-oc,
  title     = "Generalizing the Hough transform to detect arbitrary shapes",
  author    = "Ballard, D H",
  journal   = "Pattern Recognit.",
  publisher = "Elsevier BV",
  volume    =  13,
  number    =  2,
  pages     = "111--122",
  abstract  = "The Hough transform is a method for detecting curves by
               exploiting the duality between points on a curve and parameters
               of that curve. The initial work showed how to detect both
               analytic curves(1,2) and non-analytic curves,(3) but these
               methods were restricted to binary edge images. This work was
               generalized to the detection of some analytic curves in grey
               level images, specifically lines,(4) circles(5) and parabolas.(6)
               The line detection case is the best known of these and has been
               ingeniously exploited in several applications.(7,8,9)We show how
               the boundaries of an arbitrary non-analytic shape can be used to
               construct a mapping between image space and Hough transform
               space. Such a mapping can be exploited to detect instances of
               that particular shape in an image. Furthermore, variations in the
               shape such as rotations, scale changes or figure ground reversals
               correspond to straightforward transformations of this mapping.
               However, the most remarkable property is that such mappings can
               be composed to build mappings for complex shapes from the
               mappings of simpler component shapes. This makes the generalized
               Hough transform a kind of universal transform which can be used
               to find arbitrarily complex shapes.",
  month     =  jan,
  year      =  1981,
  url       = "http://dx.doi.org/10.1016/0031-3203(81)90009-1",
  doi       = "10.1016/0031-3203(81)90009-1",
  issn      = "0031-3203,1873-5142",
  language  = "en"
}

@ARTICLE{Zhang2004-cm,
  title    = "Review of shape representation and description techniques",
  author   = "Zhang, Dengsheng and Lu, Guojun",
  journal  = "Pattern Recognit.",
  volume   =  37,
  number   =  1,
  pages    = "1--19",
  abstract = "More and more images have been generated in digital form around
              the world. There is a growing interest in finding images in large
              collections or from remote databases. In order to find an image,
              the image has to be described or represented by certain features.
              Shape is an important visual feature of an image. Searching for
              images using shape features has attracted much attention. There
              are many shape representation and description techniques in the
              literature. In this paper, we classify and review these important
              techniques. We examine implementation procedures for each
              technique and discuss its advantages and disadvantages. Some
              recent research results are also included and discussed in this
              paper. Finally, we identify some promising techniques for image
              retrieval according to standard principles.",
  month    =  jan,
  year     =  2004,
  url      = "https://www.sciencedirect.com/science/article/pii/S0031320303002759",
  keywords = "Shape; Image retrieval; CBIR; Review; Shape descriptor",
  doi      = "10.1016/j.patcog.2003.07.008",
  issn     = "0031-3203"
}

@MISC{Kerns1999-la,
  title        = "Guidelines for Head Lettuce Production in Arizona ({ACIS})",
  author       = "Kerns, D L and Matheron, M E and Palumbo, J C and Sanchez, C A
                  and Still, D W and Tickes, B R and Umeda, K and Wilcox, M A",
  abstract     = "Provided by the University of Arizona.",
  year         =  1999,
  howpublished = "\url{https://cals.arizona.edu/crop/vegetables/cropmgt/az1099.html}",
  note         = "Accessed: 2022-3-30"
}

@INCOLLECTION{Anguita2013-df,
  title     = "Training computationally efficient smartphone–based human
               activity recognition models",
  author    = "Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra,
               Xavier and Reyes-Ortiz, Jorge Luis",
  booktitle = "Artificial Neural Networks and Machine Learning – ICANN 2013",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "426--433",
  abstract  = "This work presents a HAR system which incorporates
               smartphone-embedded inertial sensors and uses Support Vector
               Machines (SVM) for the classification of Activities of Daily
               Living (ADL) and explores two feature selection mechanisms for
               allowing a radically faster recognition. The exploitation of
               smartphones for Human Activity Recognition (HAR) has been an
               active research area in which the development of fast and
               efficient Machine Learning approaches is crucial for preserving
               battery life and reducing computational requirements. In this
               work, we present a HAR system which incorporates
               smartphone-embedded inertial sensors and uses Support Vector
               Machines (SVM) for the classification of Activities of Daily
               Living (ADL). By exploiting a publicly available benchmark HAR
               dataset, we show the benefits of adding smartphones gyroscope
               signals into the recognition system against the traditional
               accelerometer-based approach, and explore two feature selection
               mechanisms for allowing a radically faster recognition: the
               utilization of exclusively time domain features and the
               adaptation of the L1 SVM model which performs comparably to
               non-linear approaches while neglecting a large number of
               non-informative features.",
  series    = "Lecture notes in computer science",
  year      =  2013,
  url       = "http://link.springer.com/10.1007/978-3-642-40728-4_54",
  doi       = "10.1007/978-3-642-40728-4\_54",
  isbn      = "9783642407277,9783642407284",
  issn      = "0302-9743,1611-3349",
  language  = "en"
}

@ARTICLE{Upendar2021-mq,
  title    = "Greenness identification using visible spectral colour indices for
              site specific weed management",
  author   = "Upendar, K and Agrawal, K N and Chandel, N S and Singh, K",
  journal  = "Plant Physiology Reports",
  volume   =  26,
  number   =  1,
  pages    = "179--187",
  abstract = "In the present study an attempt has been made to identify the
              green vegetation based on colour using visible spectral colour
              indices such as excess green index (ExG), excess red index (ExR)
              and excess green minus excess red index (ExGR). At first stage,
              the performance of colour indices were tested at four illumination
              intensities using the standard colour patches. The results
              indicated a clear separation between the ExG, ExR and ExGR values
              of green colour patches (foliage, yellow green \& green) and soil
              colour patches (dark skin, moderate red \& magenta) at
              illumination intensity of 89.04 ± 8.12 lux than 188.8 ± 6.36,
              259.25 ± 12.73 and 359.28 ± 10.10 lux illumination intensities.
              This observation suggested that the colour indices might perform
              better at low lighting condition. In the second stage, the images
              of original plants and soil were captured at an illumination
              intensity of 89.04 ± 8.12 lux and classification rate at different
              threshold were studied. The average correct classification rate of
              ExGR and ExG colour indices were found to be 93.03\% and 86.03\%
              at threshold values 0 and 10, respectively. This indicates that
              the colour index ExGR could be successfully employed for image
              based classification of plant and non-plant material.",
  month    =  mar,
  year     =  2021,
  url      = "https://doi.org/10.1007/s40502-020-00562-0",
  doi      = "10.1007/s40502-020-00562-0",
  issn     = "2662-2548"
}

@ARTICLE{Gu2022-xo,
  title     = "A Survey on Deep Learning for Human Activity Recognition",
  author    = "Gu, F and Chung, M-H and Chignell, M and Valaee, S and Zhou, B
               and Liu, X",
  journal   = "ACM Computing Surveys",
  publisher = "Association for Computing Machinery",
  volume    =  54,
  number    =  8,
  abstract  = "Human activity recognition is a key to a lot of applications such
               as healthcare and smart home. In this study, we provide a
               comprehensive survey on recent advances and challenges in human
               activity recognition (HAR) with deep learning. Although there are
               many surveys on HAR, they focused mainly on the taxonomy of HAR
               and reviewed the state-of-the-art HAR systems implemented with
               conventional machine learning methods. Recently, several works
               have also been done on reviewing studies that use deep models for
               HAR, whereas these works cover few deep models and their
               variants. There is still a need for a comprehensive and in-depth
               survey on HAR with recently developed deep learning methods. ©
               2021 Association for Computing Machinery.",
  year      =  2022,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116615099&doi=10.1145%2f3472290&partnerID=40&md5=2517311222a3af6809c9de660ab4d03c",
  keywords  = "activity recognition; Additional Key Words and PhrasesMachine
               learning; deep learning; deep models; mobile sensing; Automation;
               Deep learning; Intelligent buildings; Pattern recognition;
               Activity recognition; Additional key word and phrasesmachine
               learning; Deep learning; Deep model; Human activity recognition;
               Human activity recognition systems; Key words; Mobile sensing;
               Smart homes; State of the art; Surveys",
  doi       = "10.1145/3472290",
  issn      = "0360-0300"
}

@PROCEEDINGS{Anguita2013-ts,
  title    = "A public domain dataset for human activity recognition using
              smartphones",
  author   = "Anguita, D and Ghio, A and Oneto, L and Parra, X and Reyes-Ortiz,
              J L",
  abstract = "Human-centered computing is an emerging research field that aims
              to understand human behavior and integrate users and their social
              context with computer systems. One of the most recent, challenging
              and appealing applications in this framework consists in sensing
              human body motion using smartphones to gather context information
              about people actions. In this context, we describe in this work an
              Activity Recognition database, built from the recordings of 30
              subjects doing Activities of Daily Living (ADL) while carrying a
              waist-mounted smartphone with embedded inertial sensors, which is
              released to public domain on a well-known on-line repository.
              Results, obtained on the dataset by exploiting a multiclass
              Support Vector Machine (SVM), are also acknowledged.",
  year     =  2013,
  url      = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887123513&partnerID=40&md5=8f6328ee377708d1b485b885d929cb00",
  keywords = "Activities of Daily Living; Activity recognition; Context
              information; Human activity recognition; Human body motion;
              Human-centered computing; Multiclass support vector machines;
              Research fields; Neural networks; Pattern recognition; Support
              vector machines; Smartphones",
  isbn     =  9782874190810
}

@ARTICLE{McGinnis2021-bo,
  title       = "Parameter Selection in Weed/Crop Discrimination",
  author      = "McGinnis, Evan",
  journal     = "INFO 521: Introduction to Machine Learning",
  institution = "University of Arizona",
  year        =  2021
}

@ARTICLE{Nguyen2005-zm,
  title    = "Shape Analysis of Breast Masses in Mammograms via the Fractal
              Dimension",
  author   = "Nguyen, Thanh and Rangayyan, Rangaraj",
  journal  = "Conf. Proc. IEEE Eng. Med. Biol. Soc.",
  volume   =  2005,
  pages    = "3210--3213",
  abstract = "Masses due to benign breast diseases and tumors due to breast
              cancer present significantly different shapes on mammograms. In
              general, malignant tumors appear with rough and complex boundaries
              or contours, whereas benign masses present smooth, round, or oval
              contours. Fractal analysis may be used to derive shape features to
              perform pattern classification of breast masses and tumors.
              Several procedures have been proposed to compute the fractal
              dimension of various types of objects or regions of interest in
              biomedical images, among which the box-counting and ruler methods
              are popular. In this study, we applied the two methods mentioned
              above to compute the fractal dimension of both the two-dimensional
              (2D) contours of breast masses and tumors, as well as their
              one-dimensional (1D) signatures. A comparative analysis was
              performed to assess the performance of the two methods of
              computing the fractal dimension and the two methods of
              representing the boundaries of masses. It was observed that
              analysis of the 2D contour representation with the ruler method
              resulted in the highest classification accuracy of up to 0.946, as
              indicated by the area under the receiver operating characteristics
              (ROC) curve. The results indicate that the fractal dimension can
              serve as a good shape feature for the benign-versus-malignant
              classification of breast masses in mammograms.",
  year     =  2005,
  url      = "http://dx.doi.org/10.1109/IEMBS.2005.1617159",
  doi      = "10.1109/IEMBS.2005.1617159",
  pmid     =  17282928,
  issn     = "1557-170X",
  language = "en"
}

@ARTICLE{Shen1994-eg,
  title    = "Application of shape analysis to mammographic calcifications",
  author   = "Shen, L and Rangayyan, R M and Desautels, J L",
  journal  = "IEEE Trans. Med. Imaging",
  volume   =  13,
  number   =  2,
  pages    = "263--274",
  abstract = "The authors have developed a set of shape factors to measure the
              roughness of contours of calcifications in mammograms and for use
              in their classification as malignant or benign. The analysis of
              mammograms is performed in three stages. First, a region growing
              technique is used to obtain the contours of calcifications. Then,
              three measures of shape features, including compactness, moments,
              and Fourier descriptors are computed for each region. Finally,
              their applicability for classification is studied by using the
              three shape measures to form feature vectors. Classification of
              143 calcifications from 18 biopsy-proven cases as benign or
              malignant using the three measures with the nearest-neighbor
              method was 100\% accurate.",
  year     =  1994,
  url      = "http://dx.doi.org/10.1109/42.293919",
  doi      = "10.1109/42.293919",
  pmid     =  18218503,
  issn     = "0278-0062",
  language = "en"
}

@MISC{noauthor_undated-gj,
  title        = "Color Spaces",
  howpublished = "\url{https://culorijs.org/color-spaces/}",
  note         = "Accessed: 2023-4-20"
}

@INCOLLECTION{Berrar2019-ol,
  title     = "Performance Measures for Binary Classification",
  author    = "Berrar, Daniel",
  editor    = "Ranganathan, Shoba and Gribskov, Michael and Nakai, Kenta and
               Schönbach, Christian",
  booktitle = "Encyclopedia of Bioinformatics and Computational Biology",
  publisher = "Academic Press",
  address   = "Oxford",
  pages     = "546--560",
  abstract  = "This article is an introduction to some of the most commonly used
               performance measures for the evaluation of binary classifiers.
               These measures are categorized into three broad families:
               measures based on a single classification threshold, measures
               based on a probabilistic interpretation of error, and ranking
               measures. Graphical methods, such as ROC curves, precision-recall
               curves, TPR-FPR plots, gain charts, and lift charts, are also
               discussed. Using a simple example, we illustrate how to calculate
               the various performance measures and show how they are related.
               The article also explains how to assess the statistical
               significance of an obtained performance value, how to calculate
               approximate and exact parametric confidence intervals, and how to
               derive percentile bootstrap confidence intervals for a
               performance measure.",
  month     =  jan,
  year      =  2019,
  url       = "https://www.sciencedirect.com/science/article/pii/B9780128096338203518",
  keywords  = "Accuracy; AUC; AUCH; AUCPR; Average precision; Balanced accuracy;
               Bootstrap percentile confidence interval; Brier score;
               Clopper-Pearson confidence interval; Cohen׳s kappa; Confusion
               matrix; Cross-entropy; Error rate; -measure; False discovery
               rate; -measure; Gain chart; Gini index; -measure; Information
               score; Kolmogorv-Smirnov statistic; Lift; Lift chart; Logloss;
               MAP; Matthew׳s correlation coefficient; Mean absolute error; Mean
               squared error; Negative likelihood ratio; Negative predictive
               value; Positive likelihood ratio; Positive predictive value;
               Precision; Precision-recall plot; Recall; ROC; Scoring function;
               Sensitivity; Specificity; TaKS; TPR-FPR plot; Trapezoidal
               estimators; True negative rate; True positive rate; Type I error;
               Type II error; Wald confidence interval; Youden index",
  doi       = "10.1016/B978-0-12-809633-8.20351-8",
  isbn      =  9780128114322
}

@INCOLLECTION{Forsyth2012-tv,
  title     = "Chapter 3 - Color",
  author    = "Forsyth, David A and Ponce, Jean",
  booktitle = "Computer Vision -- A Modern Approach",
  publisher = "Pearson Education",
  pages     = "68--103",
  year      =  2012,
  isbn      =  9780136085928
}

@INCOLLECTION{Titus2022-yl,
  title     = "Comparative Analysis of Local Binary Descriptors for Plant
               Discrimination",
  author    = "Titus, R M and Stephen, R and Vimina, E R",
  editor    = "{Karuppusamy P.} and {Perikos I.} and {Garcia Marquez F.P.}",
  booktitle = "International Conference on Ubiquitous Intelligent Systems, ICUIS
               2021",
  publisher = "Springer Science and Business Media Deutschland GmbH",
  volume    =  243,
  pages     = "295--305",
  abstract  = "Weed management is one of the prime obstacles faced by most of
               farmers nowadays. Efficient weed detection methods will cut back
               the price of weed management. Feature extractors have an
               important role in the domain of computer vision. The feature
               extracting algorithm takes the image as its input, and then it
               gives back the feature descriptors of the image that can be used
               to discriminate one feature from another. In software systems,
               there are various binary descriptors that are widely used for
               face recognition, plant discrimination, fingerprint detection,
               etc. This paper shows the performance comparison of different
               binary descriptors like local directional relation pattern
               (LDRP), local directional order pattern (LDOP), and local binary
               pattern (LBP) with support vector machine (SVM) for the image set
               classification. The results indicate that the sequence of LBP and
               SVM together produce a better accuracy of 84.51\% in
               “bccr-segset” plant leaf database when compared to LDOP which
               produced an accuracy of 75\% and LDRP with an accuracy of
               75.56\%. © 2022, The Author(s), under exclusive license to
               Springer Nature Singapore Pte Ltd.",
  year      =  2022,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118133941&doi=10.1007%2f978-981-16-3675-2_22&partnerID=40&md5=da8801270ebb062f6deddfbf8a0f3c86",
  keywords  = "Classification; Feature extraction; LBP; LDOP; LDRP; Plant
               discrimination; SVM; Classification (of information); Face
               recognition; Comparative analyzes; Descriptors; Features
               extraction; Local binary patterns; Local directional order
               pattern; Local directional relation pattern; Order patterns;
               Plant discrimination; Support vectors machine; Weed management;
               Support vector machines",
  doi       = "10.1007/978-981-16-3675-2\_22",
  isbn      =  9789811636745
}

@ARTICLE{Kupidura2019-kq,
  title     = "The comparison of different methods of texture analysis for their
               efficacy for land use classification in satellite imagery",
  author    = "Kupidura, P",
  journal   = "Remote Sensing",
  publisher = "MDPI AG",
  volume    =  11,
  number    =  10,
  abstract  = "The paper presents a comparison of the efficacy of several
               texture analysis methods as tools for improving land use/cover
               classification in satellite imagery. The tested methods were:
               gray level co-occurrence matrix (GLCM) features, Laplace filters
               and granulometric analysis, based on mathematical morphology. The
               performed tests included an assessment of the classification
               accuracy performed based on spectro-textural datasets: spectral
               images with the addition of images generated using different
               texture analysis methods. The class nomenclature was based on
               spectral and textural differences and included the following
               classes: water, low vegetation, bare soil, urban, and two
               (coniferous and deciduous) forest classes. The classification
               accuracy was assessed using the overall accuracy and kappa index
               of agreement, based on the reference data generated using visual
               interpretation of the images. The analysis was performed using
               very high-resolution imagery (Pleiades, WorldView-2) and
               high-resolution imagery (Sentinel-2). The results show the
               efficacy of selected GLCM features and granulometric analysis as
               tools for providing textural data, which could be used in the
               process of land use/cover classification. It is also clear that
               texture analysis is generally a more important and effective
               component of classification for images of higher resolution. In
               addition, for classification using GLCM results, the Random
               Forest variable importance analysis was performed. © 2019 by the
               authors.",
  year      =  2019,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066761119&doi=10.3390%2frs11101233&partnerID=40&md5=db85c5e0c3b247c45397f74696b2ff49",
  keywords  = "Classification; GLCM; Granulometric analysis; Laplace filter;
               Mathematical morphology; Satellite imagery; Texture analysis;
               Classification (of information); Decision trees; Image analysis;
               Image enhancement; Image texture; Land use; Laplace transforms;
               Mathematical morphology; Morphology; Satellite imagery;
               Spectroscopy; Textures; Classification accuracy; GLCM;
               Granulometric analysis; Gray level co occurrence matrix(GLCM);
               High resolution imagery; Kappa index of agreements; Laplace
               filter; Texture analysis; Image classification",
  doi       = "10.3390/rs11101233",
  issn      = "2072-4292"
}

@ARTICLE{noauthor_undated-tt,
  title = "{TexturalFeatures}.pdf",
  url   = "http://haralick.org/journals/TexturalFeatures.pdf"
}

@ARTICLE{Dickey1979-ft,
  title     = "Distribution of the estimators for autoregressive time series
               with a unit root",
  author    = "Dickey, David A and Fuller, Wayne A",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "JSTOR",
  volume    =  74,
  number    =  366,
  pages     =  427,
  abstract  = "Primo by Ex Libris",
  month     =  jun,
  year      =  1979,
  url       = "https://arizona-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=TN_cdi_crossref_primary_10_2307_2286348&context=PC&vid=01UA&lang=en_US&search_scope=Everything&adaptor=primo_central_multiple_fe&tab=default_tab&query=title,contains,Distribution%20of%20the%20Estimators%20for%20Autoregressive%20Time%20Series%20with%20a%20Unit%20Root",
  doi       = "10.2307/2286348",
  issn      = "0162-1459,1537-274X",
  language  = "en"
}

@BOOK{Forsyth2012-hy,
  title     = "Computer Vision: A Modern Approach",
  author    = "Forsyth, David and Ponce, Jean",
  publisher = "Pearson",
  abstract  = "Computer Vision: A Modern Approach, 2e, is appropriate for
               upper-division undergraduate- and graduate-level courses in
               computer vision found in departments of Computer Science,
               Computer Engineering and Electrical Engineering. This textbook
               provides the most complete treatment of modern computer vision
               methods by two of the leading authorities in the field. This
               accessible presentation gives both a general view of the entire
               computer vision enterprise and also offers sufficient detail for
               students to be able to build useful applications. Students will
               learn techniques that have proven to be useful by first-hand
               experience and a wide range of mathematical methods",
  year      =  2012,
  url       = "https://play.google.com/store/books/details?id=gM63QQAACAAJ",
  isbn      =  9780136085928,
  language  = "en"
}

@MISC{MathWorks_undated-jg,
  title        = "Conversion of {RGB} colorspace",
  author       = "{MathWorks}",
  booktitle    = "Image Processing Toolbox Documentation. MathWorks.",
  abstract     = "This MATLAB function converts the red, green, and blue values
                  of an RGB image to luminance (Y) and chrominance (I and Q)
                  values of an NTSC image.",
  howpublished = "\url{https://www.mathworks.com/help/images/ref/rgb2ntsc.html}",
  note         = "Accessed: 2023-4-20",
  language     = "en"
}

@INPROCEEDINGS{Aygun2017-es,
  title     = "A benchmarking: Feature extraction and classification of
               agricultural textures using {LBP}, {GLCM}, {RBO}, Neural
               Networks, k-{NN}, and random forest",
  author    = "Aygün, Sercan and Güneş, Ece Olcay",
  booktitle = "2017 6th International Conference on Agro-Geoinformatics",
  publisher = "IEEE",
  pages     = "1--4",
  abstract  = "Agricultural textures are in the interest of classification in
               image processing. Natural images have unique textural shapes
               inside which cause a tough problem for classification. This paper
               tests different feature extraction and classification approaches
               to serve a benchmarking on several agricultural databases like
               seeds and leaves. Features are obtained using Local Binary
               Pattern (LBP), Gray Level Co-Occurrence Matrix (GLCM), and
               Relational Bit Operator (RBO) independently. Classification is
               done by Neural Networks, k-nearest neighbor method, and random
               forest independently, too. LBP counts several binary patterns
               that occur in the image. GLCM is a kind of statistical approach
               that uses homogeneity, contrast, energy, and correlation
               information from pixels. RBO counts the binary relations of
               neighboring pixels in a box filter to get textural features for
               image processing. The leading test results are obtained from the
               LBP method for features and random forest data structure for
               classification. For example, agricultural seed type
               classification is obtained with LBP features and random forest
               classification with an accuracy of 99.5\% and leaf classification
               with 93.5\% accuracy. Following sections in the paper start with
               an introduction and continue with literature review, methods and
               materials, test results and conclusion.",
  month     =  aug,
  year      =  2017,
  url       = "http://dx.doi.org/10.1109/Agro-Geoinformatics.2017.8047000",
  doi       = "10.1109/Agro-Geoinformatics.2017.8047000",
  isbn      = "9781538638842,9781538638835"
}

@ARTICLE{Fragassa2023-cj,
  title     = "A New Procedure for Combining {UAV}-Based Imagery and Machine
               Learning in Precision Agriculture",
  author    = "Fragassa, C and Vitali, G and Emmi, L and Arru, M",
  journal   = "Sustainability (Switzerland)",
  publisher = "MDPI",
  volume    =  15,
  number    =  2,
  abstract  = "Drone images from an experimental field cropped with sugar beet
               with a high diffusion of weeds taken from different flying
               altitudes were used to develop and test a machine learning method
               for vegetation patch identification. Georeferenced images were
               combined with a hue-based preprocessing analysis, digital
               transformation by an image embedder, and evaluation by supervised
               learning. Specifically, six of the most common machine learning
               algorithms were applied (i.e., logistic regression, k-nearest
               neighbors, decision tree, random forest, neural network, and
               support-vector machine). The proposed method was able to
               precisely recognize crops and weeds throughout a wide cultivation
               field, training from single partial images. The information has
               been designed to be easily integrated into autonomous weed
               management systems with the aim of reducing the use of water,
               nutrients, and herbicides for precision agriculture. © 2023 by
               the authors.",
  year      =  2023,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146608421&doi=10.3390%2fsu15020998&partnerID=40&md5=e713df2c96e5f65c3c681331b39da059",
  keywords  = "agricultural robotics; environmental sustainability; image
               analysis; machine learning; precision agriculture; sugar beet;
               unmanned aerial vehicle (UAV); weeding; image analysis; machine
               learning; precision agriculture; robotics; satellite imagery;
               sugar beet; sustainability; unmanned vehicle; weed control",
  doi       = "10.3390/su15020998",
  issn      = "2071-1050"
}

@UNPUBLISHED{Hall-Beyer2017-nx,
  title  = "{GLCM} {TEXTURE}: A {TUTORIAL}",
  author = "Hall-Beyer, Mryka",
  month  =  mar,
  year   =  2017,
  url    = "http://lapi.fi-p.unam.mx/wp-content/uploads/Tutorial-GLCM.pdf"
}

@ARTICLE{Luo2024-dv,
  title     = "Semantic segmentation of agricultural images: A survey",
  author    = "Luo, Zifei and Yang, Wenzhu and Yuan, Yunfeng and Gou, Ruru and
               Li, Xiaonan",
  journal   = "Inf. Process. Agric.",
  publisher = "Elsevier BV",
  volume    =  11,
  number    =  2,
  pages     = "172--186",
  abstract  = "As an important research topic in recent years, semantic
               segmentation has been widely applied to image understanding
               problems in various fields. With …",
  month     =  jun,
  year      =  2024,
  url       = "http://dx.doi.org/10.1016/j.inpa.2023.02.001",
  doi       = "10.1016/j.inpa.2023.02.001",
  issn      = "2214-3173",
  language  = "en"
}

@ARTICLE{Woebbecke1995-bw,
  title     = "Shape features for identifying young weeds using image analysis",
  author    = "Woebbecke, D M and Meyer, G E and Von Bargen, K and Mortensen, D
               A",
  journal   = "Trans. ASAE",
  publisher = "ASAE",
  address   = "St. Joseph, MI, United States",
  volume    =  38,
  number    =  1,
  pages     = "271--281",
  abstract  = "Shape feature analyses were performed on binary images originally
               obtained from color images of 10 common weeds, along with corn
               and soybeans, found in the Midwest. Features studied were
               roundness, aspect, perimeter/thickness, elongatedness, and seven
               invariant central moments (ICM), for each plant type and age up
               to 45 days after emergence. Shape features were generally
               independent of plant size, image rotation, and plant location
               within most images. The ability to discriminate between monocots
               and dicots was most evident between 14 and 23 days using these
               features. Shape features that best distinguished these plants
               were aspect and first invariant central moment (ICM1), which
               classified 60 to 90\% of the dicots from the monocots. Using
               Analysis of Variance and Tukey's multiple comparison tests, shape
               features did not change significantly for most species over the
               study period. This information could be very useful in the future
               design of advanced spot spraying applications.",
  year      =  1995,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029107676&partnerID=40&md5=091c92f6437522a4cfac7e0e3e3ae1d8",
  keywords  = "Agricultural machinery; Agricultural products; Color image
               processing; Image analysis; Spraying; Dicots; Invariant central
               moments; Monocots; Shape features; Spot spraying; Weeds; Plants
               (botany)",
  issn      = "0001-2351"
}

@ARTICLE{Saile2022-vu,
  title     = "Evaluating Sensor-Based Mechanical Weeding Combined with Pre-and
               Post-Emergence Herbicides for Integrated Weed Management in
               Cereals",
  author    = "Saile, M and Spaeth, M and Gerhards, R",
  journal   = "Agronomy",
  publisher = "MDPI",
  volume    =  12,
  number    =  6,
  abstract  = "Due to the increasing number of herbicide-resistant weed
               populations and the resulting yield losses, weed control must be
               given high priority to ensure food security. Integrated weed
               management (IWM) strategies, including reduced herbicide
               application, sensor-guided mechanical weed control and
               combinations thereof are indispensable to achieve this goal.
               Therefore, this study examined combinations of pre-and
               post-emergence herbicide applications with sensor-based harrowing
               and hoeing in cereals by conducting five field experiments at two
               locations in Southwestern Germany from 2019 to 2021. Each
               experiment contained an untreated control and a single
               post-emergence herbicide treatment as a comparison to these IWM
               treatments. The effects of the different IWM approaches on weed
               control efficacy (WCE), crop density, and grain yield were
               recorded. All experiments were set up in a randomized complete
               block design with four repetitions. Pre-emergence herbicide
               application combined with one-time harrowing and subsequent
               hoeing (Pre-Herb + Harr + Hoe) achieved the highest WCE (100\%),
               followed by an approach of WCE (95\%) for two-times hoeing. In
               contrast, a single pre-emergence herbicide application achieved
               the worst result with an average WCE of 25\%. Grain yield was
               equal between all treatments in between 6 t ha−1 and 10 t ha−1,
               except for a single pre-emergence herbicide application, which
               achieved a 2.5 t ha−1 higher grain yield in winter wheat in 2021
               that averaged 11 t ha−1, compared to the combination of Pre-Herb
               + Harr + Hoe that averaged 8.5 t ha−1. The results showed that it
               is possible to reduce and replace herbicides while achieving
               equivalent yield and WCE. © 2022 by the authors. Licensee MDPI,
               Basel, Switzerland.",
  year      =  2022,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132769920&doi=10.3390%2fagronomy12061465&partnerID=40&md5=842a2f6f47233d0f4b0c742836062f59",
  keywords  = "camera-guided; digital farming; herbicide reduction; integrated
               weed management; precision farming; site-specific",
  doi       = "10.3390/agronomy12061465",
  issn      = "2073-4395"
}

@ARTICLE{Mwitta2022-yt,
  title     = "Evaluation of Diode Laser Treatments to Manage Weeds in Row Crops",
  author    = "Mwitta, C and Rains, G C and Prostko, E",
  journal   = "Agronomy",
  publisher = "MDPI",
  volume    =  12,
  number    =  11,
  abstract  = "Herbicides have been the primary weed management practice in
               agriculture for decades. However, due to their effects on the
               environment in addition to weeds becoming resistant, alternative
               approaches to weed control are critical. One approach is using
               lasers, particularly diode lasers because of their portability,
               low power demand, and cost effectiveness. In this research,
               weeds’ response to diode laser treatments was investigated. Three
               experiments were conducted. The first experiment involved
               treating two species of weeds with four different laser powers to
               determine the time it takes to sever the weed stem. The second
               experiment involved monitoring the status of two species of weeds
               for a week after treating them with two lasers at constant
               application times of 1 s, 2 s, and 3 s. The third experiment was
               a repeat of the second with higher laser powers and shorter
               treatment times. The results showed diode lasers have a potential
               to be an effective weed controlling tool. Weed stem diameter,
               laser power, treatment duration, and distance between laser and
               weed were all statistically significant in weed mortality, with
               weed species having no significance. Furthermore, it was found
               that weed management is possible by exposing the stem of the two
               weed species between 0.8 and 2.65 mm diameter to a laser beam
               dosage without necessarily severing it, with 80\% effectiveness
               at 0.5 s treatment time, and 100\% effectiveness using a 6.1 W
               laser for 1.5 s. © 2022 by the authors.",
  year      =  2022,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141582446&doi=10.3390%2fagronomy12112681&partnerID=40&md5=73754c5cfdaa68b457a599abb3adf2c4",
  keywords  = "laser weeding; non-chemical weed elimination; precision weeding",
  doi       = "10.3390/agronomy12112681",
  issn      = "2073-4395"
}

@ARTICLE{Gai2020-zh,
  title     = "Automated crop plant detection based on the fusion of color and
               depth images for robotic weed control",
  author    = "Gai, J and Tang, L and Steward, B L",
  journal   = "Journal of Field Robotics",
  publisher = "John Wiley and Sons Inc.",
  volume    =  37,
  number    =  1,
  pages     = "35--52",
  abstract  = "Robotic weeding enables weed control near or within crop rows
               automatically, precisely and effectively. A computer-vision
               system was developed for detecting crop plants at different
               growth stages for robotic weed control. Fusion of color images
               and depth images was investigated as a means of enhancing the
               detection accuracy of crop plants under conditions of high weed
               population. In-field images of broccoli and lettuce were acquired
               3–27 days after transplanting with a Kinect v2 sensor. The image
               processing pipeline included data preprocessing, vegetation pixel
               segmentation, plant extraction, feature extraction, feature-based
               localization refinement, and crop plant classification. For the
               detection of broccoli and lettuce, the color-depth fusion
               algorithm produced high true-positive detection rates (91.7\% and
               90.8\%, respectively) and low average false discovery rates
               (1.1\% and 4.0\%, respectively). Mean absolute localization
               errors of the crop plant stems were 26.8 and 7.4 mm for broccoli
               and lettuce, respectively. The fusion of color and depth was
               proved beneficial to the segmentation of crop plants from
               background, which improved the average segmentation success rates
               from 87.2\% (depth-based) and 76.4\% (color-based) to 96.6\% for
               broccoli, and from 74.2\% (depth-based) and 81.2\% (color-based)
               to 92.4\% for lettuce, respectively. The fusion-based algorithm
               had reduced performance in detecting crop plants at early growth
               stages. © 2019 Wiley Periodicals, Inc.",
  year      =  2020,
  url       = "http://dx.doi.org/10.1002/rob.21897",
  keywords  = "computer vision; crop detection; robotic weeding; sensor fusion;
               Color; Computer control systems; Computer vision; Data handling;
               Extraction; Image enhancement; Image fusion; Image segmentation;
               Robotics; Weed control; Color and depth images; Computer vision
               system; Different growth stages; False discovery rate; Image
               processing pipeline; Localization errors; Robotic weeding; Sensor
               fusion; Crops",
  doi       = "10.1002/rob.21897",
  issn      = "1556-4959"
}

@ARTICLE{Ojala1996-ps,
  title     = "A comparative study of texture measures with classification based
               on feature distributions",
  author    = "Ojala, T and Pietikäinen, M and Harwood, D",
  journal   = "Pattern Recognit.",
  publisher = "Elsevier Ltd",
  volume    =  29,
  number    =  1,
  pages     = "51--59",
  abstract  = "This paper evaluates the performance both of some texture
               measures which have been successfully used in various
               applications and of some new promising approaches proposed
               recently. For classification a method based on Kullback
               discrimination of sample and prototype distributions is used. The
               classification results for single features with one-dimensional
               feature value distributions and for pairs of complementary
               features with two-dimensional distributions are presented.",
  year      =  1996,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029669420&doi=10.1016%2f0031-3203%2895%2900067-4&partnerID=40&md5=ab3c793620b5cfdbd868cecd526156f4",
  keywords  = "Brodatz textures; Classification; Feature distribution; Kullback
               discriminant; Performance evaluation; Texture analysis;
               Calculations; Feature extraction; Image analysis; Invariance;
               Performance; Brodatz textures; Feature distribution; Gray level
               difference method; Kullback discrimination; Texture analysis;
               Texture measures; Pattern recognition; feature distribution;
               Kullback discriminant; texture analysis",
  doi       = "10.1016/0031-3203(95)00067-4",
  issn      = "0031-3203"
}

@ARTICLE{Ojala2002-mj,
  title    = "Multiresolution gray-scale and rotation invariant texture
              classification with local binary patterns",
  author   = "Ojala, T and Pietikäinen, M and Mäenpää, T",
  journal  = "IEEE Trans. Pattern Anal. Mach. Intell.",
  volume   =  24,
  number   =  7,
  pages    = "971--987",
  abstract = "This paper presents a theoretically very simple, yet efficient,
              multiresolution approach to gray-scale and rotation invariant
              texture classification based on local binary patterns and
              nonparametric discrimination of sample and prototype
              distributions. The method is based on recognizing that certain
              local binary patterns, termed ``uniform,'' are fundamental
              properties of local image texture and their occurrence histogram
              is proven to be a very powerful texture feature. We derive a
              generalized gray-scale and rotation invariant operator
              presentation that allows for detecting the ``uniform'' patterns
              for any quantization of the angular space and for any spatial
              resolution and presents a method for combining multiple operators
              for multiresolution analysis. The proposed approach is very robust
              in terms of gray-scale variations since the operator is, by
              definition, invariant against any monotonic transformation of the
              gray scale. Another advantage is computational simplicity as the
              operator can be realized with a few operations in a small
              neighborhood and a lookup table. Excellent experimental results
              obtained in true problems of rotation invariance, where the
              classifier is trained at one particular rotation angle and tested
              with samples from other rotation angles, demonstrate that good
              discrimination can be achieved with the occurrence statistics of
              simple rotation invariant local binary patterns. These operators
              characterize the spatial configuration of local image texture and
              the performance can be further improved by combining them with
              rotation invariant variance measures that characterize the
              contrast of local image texture. The joint distributions of these
              orthogonal measures are shown to be very powerful tools for
              rotation invariant texture analysis.",
  year     =  2002,
  url      = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036647193&doi=10.1109%2fTPAMI.2002.1017623&partnerID=40&md5=dbe62186803e1e66622e2679b405f6a8",
  keywords = "Brodatz; Contrast; Distribution; Histogram; Nonparametric; Outex;
              Texture analysis; Binary sequences; Classification (of
              information); Computational complexity; Image quality;
              Mathematical operators; Mathematical transformations; Table
              lookup; Textures; Vector quantization; Histogram; Local binary
              patterns; Multiresolution gray scale; Rotation invariant texture
              classification; Pattern recognition",
  doi      = "10.1109/TPAMI.2002.1017623",
  issn     = "0162-8828"
}

@ARTICLE{Guijarro2011-bl,
  title    = "Automatic segmentation of relevant textures in agricultural images",
  author   = "Guijarro, M and Pajares, G and Riomoros, I and Herrera, P J and
              Burgos-Artizzu, X P and Ribeiro, A",
  journal  = "Comput. Electron. Agric.",
  volume   =  75,
  number   =  1,
  pages    = "75--83",
  abstract = "One important issue emerging strongly in agriculture is related
              with the automatization of tasks, where the optical sensors play
              an important role. They provide images that must be conveniently
              processed. The most relevant image processing procedures require
              the identification of green plants, in our experiments they come
              from barley and corn crops including weeds, so that some types of
              action can be carried out, including site-specific treatments with
              chemical products or mechanical manipulations. Also the
              identification of textures belonging to the soil could be useful
              to know some variables, such as humidity, smoothness or any
              others. Finally, from the point of view of the autonomous robot
              navigation, where the robot is equipped with the imaging system,
              some times it is convenient to know not only the soil information
              and the plants growing in the soil but also additional information
              supplied by global references based on specific areas. This
              implies that the images to be processed contain textures of three
              main types to be identified: green plants, soil and sky if any.
              This paper proposes a new automatic approach for segmenting these
              main textures and also to refine the identification of
              sub-textures inside the main ones. Concerning the green
              identification, we propose a new approach that exploits the
              performance of existing strategies by combining them. The
              combination takes into account the relevance of the information
              provided by each strategy based on the intensity variability. This
              makes an important contribution. The combination of thresholding
              approaches, for segmenting the soil and the sky, makes the second
              contribution; finally the adjusting of the supervised fuzzy
              clustering approach for identifying sub-textures automatically,
              makes the third finding. The performance of the method allows to
              verify its viability for automatic tasks in agriculture based on
              image processing. © 2010 Elsevier B.V.",
  year     =  2011,
  url      = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650512819&doi=10.1016%2fj.compag.2010.09.013&partnerID=40&md5=7f55d272ba1db6bf418de8e3b53d0952",
  keywords = "Automatic tasks in agriculture; Image segmentation; Machine
              vision; Texture identification in crops; Automatic segmentations;
              Automatic tasks in agriculture; Autonomous robot navigation;
              Chemical products; Green plants; Machine vision; Mechanical
              manipulation; New approaches; Plants growing; Processing
              procedures; Site-specific; Specific areas; Supervised fuzzy
              clustering; Thresholding; Agricultural machinery; Computer vision;
              Crops; Digital image storage; Imaging systems; Optical data
              processing; Robots; Soils; Textures; Image segmentation;
              agricultural soil; barley; humidity; image processing; maize;
              texture; Hordeum; Viridiplantae; Zea mays",
  doi      = "10.1016/j.compag.2010.09.013",
  issn     = "0168-1699"
}

@ARTICLE{Gee2008-yh,
  title    = "Crop/weed discrimination in perspective agronomic images",
  author   = "Gée, Ch and Bossu, J and Jones, G and Truchetet, F",
  journal  = "Comput. Electron. Agric.",
  volume   =  60,
  number   =  1,
  pages    = "49--59",
  abstract = "This paper presents a general method for weed infestation rate
              estimation for perspective wide-view images dedicated to real-time
              precision spraying. A colour camera was positioned above crop
              fields in order to get a wide angle view of crop rows in
              perspective. Before to test it on in-field images, the algorithm
              has been optimized on simulated images and its robustness face to
              different weed infestation rates is analysed. The proposed method
              can be divided into the two following steps. Firstly a crop row
              detection is performed from the identification of the vanishing
              point taking the opportunity of the perspective geometry of the
              scene. Hence, an algorithm based on a double Hough transform (DHT)
              is applied. Afterwards, the discrimination between crop and weeds
              is done by a region-based segmentation method using a blob
              colouring analysis. The DHT was proved to be applicable to
              different perspective angles and different spatial frequencies of
              crop seedlings. Based on the geometrical properties of the scene,
              the results showed that the DHT has been proved to be a reliable
              crop row detection method but the crop/weed discrimination
              algorithm needs to be optimized. The discussion focuses on the
              efficiency and the limits of this spatial method. © 2007 Elsevier
              B.V. All rights reserved.",
  year     =  2008,
  url      = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-36749104341&doi=10.1016%2fj.compag.2007.06.003&partnerID=40&md5=29e73f22722c5f0ae7569c2bd1abf8a0",
  keywords = "Blob colouring; Crop row; Double Hough transform; Simulated
              images; Vanishing point; Weed infestation rate; Cameras;
              Computational geometry; Computer simulation; Crops; Hough
              transforms; Optimization; Real time control; Spraying; Weed
              control; Blob coloring; Double Hough transforms; Simulated images;
              Vanishing point; Weed infestation rate; Agronomy; algorithm;
              color; crop; detection method; geometry; precision; weed",
  doi      = "10.1016/j.compag.2007.06.003",
  issn     = "0168-1699"
}

@ARTICLE{Hasan2021-gx,
  title     = "A survey of deep learning techniques for weed detection from
               images",
  author    = "Hasan, A S M M and Sohel, F and Diepeveen, D and Laga, H and
               Jones, M G K",
  journal   = "Comput. Electron. Agric.",
  publisher = "Elsevier B.V.",
  volume    =  184,
  abstract  = "The rapid advances in Deep Learning (DL) techniques have enabled
               rapid detection, localisation, and recognition of objects from
               images or videos. DL techniques are now being used in many
               applications related to agriculture and farming. Automatic
               detection and classification of weeds can play an important role
               in weed management and so contribute to higher yields. Weed
               detection in crops from imagery is inherently a challenging
               problem because both weeds and crops have similar colours
               (‘green-on-green’), and their shapes and texture can be very
               similar at the growth phase. Also, a crop in one setting can be
               considered a weed in another. In addition to their detection, the
               recognition of specific weed species is essential so that
               targeted controlling mechanisms (e.g. appropriate herbicides and
               correct doses) can be applied. In this paper, we review existing
               deep learning-based weed detection and classification techniques.
               We cover the detailed literature on four main procedures, i.e.,
               data acquisition, dataset preparation, DL techniques employed for
               detection, location and classification of weeds in crops, and
               evaluation metrics approaches. We found that most studies applied
               supervised learning techniques, they achieved high classification
               accuracy by fine-tuning pre-trained models on any plant dataset,
               and past experiments have already achieved high accuracy when a
               large amount of labelled data is available. © 2021 Elsevier B.V.",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102421820&doi=10.1016%2fj.compag.2021.106067&partnerID=40&md5=0c28404b95433664c39285bac24c8976",
  keywords  = "Deep learning; Digital agriculture; Machine learning; Weed
               classification; Weed detection; Crops; Data acquisition; Deep
               learning; Large dataset; Learning algorithms; Object detection;
               Supervised learning; Textures; Weed control; Automatic
               classification; Deep learning; Digital agriculture; Learning
               techniques; Localisation; Machine-learning; Rapid detection;
               Recognition of objects; Weed classification; Weed detection;
               Classification (of information); accuracy assessment; data
               acquisition; data set; image classification; numerical model;
               satellite imagery; supervised learning",
  doi       = "10.1016/j.compag.2021.106067",
  issn      = "0168-1699"
}

@ARTICLE{Ong2023-lm,
  title     = "{UAV}-based weed detection in Chinese cabbage using deep learning",
  author    = "Ong, P and Teo, K S and Sia, C K",
  journal   = "Smart Agricultural Technology",
  publisher = "Elsevier B.V.",
  volume    =  4,
  abstract  = "Weeds are unwanted plants on agricultural soil. They always
               competing for sunlight, nutrient, space and water with economic
               crops. Uncontrolled weed growth can cause both significant
               economic and ecological loss. Hence, weeds should be efficiently
               differentiated from the crops for the smart spraying solution. In
               this study, the Convolutional Neural Network (CNN) was used to
               perform weed detection amongst the commercial crop of Chinese
               cabbage, using the acquired images by Unmanned Aerial Vehicles.
               The acquired images were pre-processed and subsequently segmented
               into the crop, soil, and weed classes using the Simple Linear
               Iterative Clustering Superpixel algorithm. The segmented images
               were then used to construct the CNN-based classifier. The Random
               Forest (RF) was applied to compare with the performance of CNN.
               The results showed that the CNN achieved a higher overall
               accuracy of 92.41\% than the 86.18\% attained by RF. © 2023 The
               Author(s)",
  year      =  2023,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146181058&doi=10.1016%2fj.atech.2023.100181&partnerID=40&md5=fba5675f6430837fd200af789f5109dd",
  keywords  = "Chinese cabbage; Convolutional neural network; Deep learning;
               Random forest; Weed detection",
  doi       = "10.1016/j.atech.2023.100181",
  issn      = "2772-3755"
}

@ARTICLE{Tekin2020-ww,
  title     = "New local binary pattern approaches based on color channels in
               texture classification",
  author    = "Tekin, Ramazan and Ertuğrul, Ömer Faruk and Kaya, Yılmaz",
  journal   = "Multimed. Tools Appl.",
  publisher = "Springer US",
  address   = "New York",
  volume    =  79,
  number    = "43-44",
  pages     = "32541--32561",
  abstract  = "In this paper, four novel, simple and robust approaches, which
               are left to right local binary patterns ( LBPL L2R ), top to down
               local binary patterns ( LBP T2D ), cube surface local binary
               pattern ( LBP Surfaces ), and cube diagonal local binary pattern
               ( LBP Diagonal ), were proposed in order to exact texture
               features in color images. These approaches were based on the
               local binary pattern (LBP), which is an effective statistical
               texture descriptor and can be employed in gray images. Proposed
               approaches were evaluated and validated in four datasets, which
               are Outex, KTH\_TIPS, KTH\_TIPS2, and USPtex datasets. The images
               in these datasets are in RGB, HSV, YIQ, and YCbCr color formats.
               Achieved results by these approaches were compared with the
               obtained results by the classical LBP and literature findings. As
               a result, the proposed approaches performed better than the
               traditional LBP method and they found effective in the
               classification of color texture images, especially in images,
               which are in RGB and HSV formats. Furthermore, noise robustness
               and time complexity of the proposed approaches were validated.",
  month     =  nov,
  year      =  2020,
  url       = "http://dx.doi.org/10.1007/s11042-020-09698-5",
  keywords  = "Computer Communication Networks;Computer Science;Data Structures
               and Information Theory;Multimedia Information Systems;Special
               Purpose and Application-Based Systems",
  doi       = "10.1007/s11042-020-09698-5",
  issn      = "1380-7501,1573-7721"
}

@ARTICLE{Tekin2020-ie,
  title    = "New local binary pattern approaches based on color channels in
              texture classification",
  author   = "Tekin, Ramazan and Ertuğrul, Ömer Faruk and Kaya, Yılmaz",
  journal  = "Multimed. Tools Appl.",
  volume   =  79,
  number   =  43,
  pages    = "32541--32561",
  abstract = "In this paper, four novel, simple and robust approaches, which are
              left to right local binary patterns (LBPLL2R), top to down local
              binary patterns (LBPT2D), cube surface local binary pattern
              (LBPSurfaces), and cube diagonal local binary pattern
              (LBPDiagonal), were proposed in order to exact texture features in
              color images. These approaches were based on the local binary
              pattern (LBP), which is an effective statistical texture
              descriptor and can be employed in gray images. Proposed approaches
              were evaluated and validated in four datasets, which are Outex,
              KTH\_TIPS, KTH\_TIPS2, and USPtex datasets. The images in these
              datasets are in RGB, HSV, YIQ, and YCbCr color formats. Achieved
              results by these approaches were compared with the obtained
              results by the classical LBP and literature findings. As a result,
              the proposed approaches performed better than the traditional LBP
              method and they found effective in the classification of color
              texture images, especially in images, which are in RGB and HSV
              formats. Furthermore, noise robustness and time complexity of the
              proposed approaches were validated.",
  month    =  nov,
  year     =  2020,
  url      = "https://doi.org/10.1007/s11042-020-09698-5",
  doi      = "10.1007/s11042-020-09698-5",
  issn     = "1380-7501,1573-7721"
}

@UNPUBLISHED{Clynch2002-lc,
  title  = "Coordinates",
  author = "Clynch, James R",
  year   =  2002,
  url    = "https://www.oc.nps.edu/oc2902w/coord/coord.pdf"
}

@ARTICLE{Haralick1973-gr,
  title     = "Textural Features for Image Classification",
  author    = "Haralick, Robert M and Shanmugam, K and Dinstein, Its'hak",
  journal   = "IEEE Trans. Syst. Man Cybern.",
  publisher = "IEEE",
  volume    = "SMC-3",
  number    =  6,
  pages     = "610--621",
  abstract  = "Texture is one of the important characteristics used in
               identifying objects or regions of interest in an image, whether
               the image be a photomicrograph, an aerial photograph, or a
               satellite image. This paper describes some easily computable
               textural features based on gray-tone spatial dependancies, and
               illustrates their application in category-identification tasks of
               three different kinds of image data: photomicrographs of five
               kinds of sandstones, 1:20 000 panchromatic aerial photographs of
               eight land-use categories, and Earth Resources Technology
               Satellite (ERTS) multispecial imagery containing seven land-use
               categories. We use two kinds of decision rules: one for which the
               decision regions are convex polyhedra (a piecewise linear
               decision rule), and one for which the decision regions are
               rectangular parallelpipeds (a min-max decision rule). In each
               experiment the data set was divided into two parts, a training
               set and a test set. Test set identification accuracy is 89
               percent for the photomicrographs, 82 percent for the aerial
               photographic imagery, and 83 percent for the satellite imagery.
               These results indicate that the easily computable textural
               features probably have a general applicability for a wide variety
               of image-classification applications.",
  month     =  nov,
  year      =  1973,
  url       = "https://ieeexplore.ieee.org/document/4309314",
  keywords  = "Application software;Crops;Earth;Humans;Image
               classification;Image resolution;Piecewise linear
               techniques;Satellites;Spatial resolution;Testing",
  doi       = "10.1109/TSMC.1973.4309314",
  issn      = "0018-9472,2168-2909"
}

@ARTICLE{Abouzahir2021-sd,
  title     = "Bag-of-visual-words-augmented Histogram of Oriented Gradients for
               efficient weed detection",
  author    = "Abouzahir, S and Sadik, M and Sabir, E",
  journal   = "Biosystems Eng.",
  publisher = "Academic Press",
  volume    =  202,
  pages     = "179--194",
  abstract  = "As season-long weeds competition produces important yield losses,
               early detection of these plants is essential to sustain
               productivity. Machine vision as a non-destructive surveying
               technique requires features that can describe weeds in a real
               field case. Colours and shapes provide good results in controlled
               conditions. However, when different crops or weeds appear in
               clusters, such solutions fail to meet satisfactory performance.
               Therefore, considering features that are less specific to field
               conditions is crucial for integrated weed management. In this
               study, we provide effective use of the Histogram of Oriented
               Gradients (HOG) to improve its performance for weed detection.
               The concept is based on the Bag-of-Visual-Words (BOVW) approach.
               We use the HOG blocks as keypoints to generate the visual-words,
               and the features vectors are the histograms of these
               visual-words. Next, we use the Backpropagation Neural Network to
               detect weeds and classify plants for three different crop fields.
               Namely, we consider sugar-beet, soybean, and carrot as target
               crops. Results demonstrate that the proposed weed detection
               system can locate weeds for site-specific treatment and selective
               spraying of herbicides. The proposed BOVW-based HOG can
               discriminate between weeds and crops with an accuracy of 97.7\%,
               93\%, and 96.6\% in sugar-beet, carrot and soybean fields
               respectively. For plant classification, our method can classify
               plants with an accuracy of 90.4\%, 92.4\%, and 94.1\% in
               sugar-beet, carrot and soybean fields respectively. Our results
               turn out 37.6\% better than the classical HOG that produces an
               accuracy ranging from 71.2\% to 83.3\% in weed detection and
               49.1\%–82.1\% in plant classification. © 2020 IAgrE",
  year      =  2021,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099185136&doi=10.1016%2fj.biosystemseng.2020.11.005&partnerID=40&md5=ea5a92351214e43e8e2517ee32913145",
  keywords  = "Bag of visual words; Computer vision; Histogram of oriented
               gradients; Neural Network; Weed detection; Backpropagation;
               Crops; Graphic methods; Sugar beets; Back propagation neural
               networks; Bag-of-visual-words; Controlled conditions; Field
               conditions; Histogram of oriented gradients; Histogram of
               oriented gradients (HOG); Non destructive; Plant classification;
               Weed control",
  doi       = "10.1016/j.biosystemseng.2020.11.005",
  issn      = "1537-5110"
}

@ARTICLE{Bossu2009-yf,
  title    = "Wavelet transform to discriminate between crop and weed in
              perspective agronomic images",
  author   = "Bossu, J and Gée, Ch and Jones, G and Truchetet, F",
  journal  = "Comput. Electron. Agric.",
  volume   =  65,
  number   =  1,
  pages    = "133--143",
  abstract = "We proposed testing and validating the accuracy of four image
              processing algorithms (wavelet transforms and Gabor filtering) for
              crop/weed discrimination in synthetic and real images. A large
              panel of wavelet bases (33) was tested and the two best wavelets
              and the worst one were selected for detailed study. Based on a
              confusion matrix the crop/weed classification results of wavelet
              transforms were compared to the results of Gabor filtering that
              was initially chosen to develop a machine vision system for a
              real-time precision sprayer. The accuracy of these algorithms was
              compared and showed that wavelets were well adapted for
              perspective images: the best results were with Daubechies 25 and
              discrete approximation Meyer wavelets. They provided better
              results than Gabor filtering not only for crop/weed classification
              but also in processing time.",
  month    =  jan,
  year     =  2009,
  url      = "https://www.sciencedirect.com/science/article/pii/S0168169908001981",
  keywords = "Image processing; Wavelet transform; Gabor filtering; Weed
              infestation rate; Synthetic images",
  doi      = "10.1016/j.compag.2008.08.004",
  issn     = "0168-1699"
}

@ARTICLE{Haryanto2020-gw,
  title     = "Multipatch-{GLCM} for Texture Feature Extraction on
               Classification of the Colon Histopathology Images using Deep
               Neural Network with {GPU} Acceleration",
  author    = "Haryanto, Toto and Pratama, Adib and Suhartanto, Heru and Murni,
               Aniati and Pidanic, Jan",
  journal   = "Journal of Computer Science",
  publisher = "Science Publications",
  volume    =  16,
  number    =  3,
  pages     = "280--294",
  abstract  = "Cancer is one of the leading causes of death in the world. It is
               the main reason why research in this field becomes challenging.
               Not only for the pathologist but also from the view of a computer
               scientist. Hematoxylin and Eosin (H\&E) images are the most
               common modalities used by the pathologist for cancer detection.
               The status of cancer with histopathology images can be classified
               based on the shape, morphology, intensity, and texture of the
               image. The use of full high-resolution histopathology images will
               take a longer time for the extraction of all information due to
               the huge amount of data. This study proposed advance texture
               extraction by multi-patch images pixel method with sliding
               windows that minimize loss of information in each pixel patch. We
               use texture feature Gray Level Co-Occurrence Matrix (GLCM) with a
               meanshift filter as the data pre-processing of the images. The
               mean-shift filter is a low-pass filter technique that considers
               the surrounding pixels of the images. The proposed GLCM method is
               then trained using Deep Neural Networks (DNN) and compared to
               other classification techniques for benchmarking. For training,
               we use two hardware: NVIDIA GPU GTX-980 and TESLA K40c. According
               to the study, Deep Neural Network outperforms other classifiers
               with the highest accuracy and deviation standard 96.72±0.48 for
               four cross-validations. The additional information is that
               training using Theano framework is faster than Tensorflow for
               both in GTX-980 and Tesla K40c",
  month     =  mar,
  year      =  2020,
  url       = "https://www.researchgate.net/publication/340484256_Multipatch-GLCM_for_Texture_Feature_Extraction_on_Classification_of_the_Colon_Histopathology_Images_using_Deep_Neural_Network_with_GPU_Acceleration",
  doi       = "10.3844/jcssp.2020.280.294",
  issn      = "1549-3636"
}

@ARTICLE{Lahdenoja2013-nb,
  title     = "Towards Understanding the Formation of Uniform Local Binary
               Patterns",
  author    = "Lahdenoja, Olli and Poikonen, Jonne and Laiho, Mika",
  journal   = "International Scholarly Research Notices",
  publisher = "Hindawi",
  volume    =  2013,
  abstract  = "The research reported in this paper focuses on the modeling of
               Local Binary Patterns (LBPs) and presents an a priori model where
               LBPs are considered as combinations of permutations. The aim is
               to increase the understanding of the mechanisms related to the
               formation of uniform LBPs. Uniform patterns are known to exhibit
               high discriminative capability; however, so far the reasons for
               this have not been fully explored. We report an observation that
               although the overall a priori probability of uniform LBPs is
               high, it is mostly due to the high probability of only certain
               classes of patterns, while the a priori probability of other
               patterns is very low. In order to examine this behavior, the
               relationship between the runs up and down test for randomness of
               permutations and the uniform LBPs was studied. Quantitative
               experiments were then carried out to show that the relative
               effect of uniform patterns to the LBP histogram is strengthened
               with deterministic data, in comparison with the i.i.d. model.
               This was verified by using an a priori model as well as through
               experiments with natural image data. It was further illustrated
               that specific uniform LBP codes can also provide responses to
               salient shapes, that is, to monotonically changing intensity
               functions and edges within the image microstructure.",
  month     =  jul,
  year      =  2013,
  url       = "https://www.hindawi.com/journals/isrn/2013/429347/",
  doi       = "10.1155/2013/429347",
  language  = "en"
}

@MISC{Ecma2019-yo,
  title    = "{ECMA} {TR}/98",
  author   = "{ECMA}",
  abstract = "JPEG File Interchange Format (JFIF) - This document specifies the
              file format for file-based interchange of images encoded according
              to the JPEG standard",
  month    =  aug,
  year     =  2019,
  url      = "https://www.ecma-international.org/publications-and-standards/technical-reports/ecma-tr-98/",
  language = "en"
}

@PROCEEDINGS{Elhariri2014-eo,
  title     = "Plant classification system based on leaf features",
  author    = "Elhariri, E and El-Bendary, N and Hassanien, A E",
  editor    = "{Wahba A.M.} and {El-Kharashi M.W.} and {Taher M.} and {Bahaa
               El-Din A.M.} and {Zaki A.M.}",
  publisher = "Institute of Electrical and Electronics Engineers Inc.",
  abstract  = "This paper presents a classification approach based on Random
               Forests (RF) and Linear Discriminant Analysis (LDA) algorithms
               for classifying the different types of plants. The proposed
               approach consists of three phases that are pre-processing,
               feature extraction, and classification phases. Since most types
               of plants have unique leaves, so the classification approach
               presented in this research depends on plants leave. Leaves are
               different from each other by characteristics such as the shape,
               color, texture and the margin. The used dataset for this
               experiments is a database of different plant species with total
               of only 340 leaf images, was downloaded from UCI- Machine
               Learning Repository. It was used for both training and testing
               datasets with 10-fold cross-validation. Experimental results
               showed that LDA achieved classification accuracy of (92.65\%)
               against the RF that achieved accuracy of (88.82\%) with
               combination of shape, first order texture, Gray Level
               Co-occurrence Matrix (GLCM), HSV color moments, and vein
               features. © 2014 IEEE.",
  year      =  2014,
  url       = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946688740&doi=10.1109%2fICCES.2014.7030971&partnerID=40&md5=8c4f7dca64966478358e3df988c0051d",
  keywords  = "features extraction; gray level co-occurrence matrix (GLCM);
               image classification; leaves; linear discriminant analysis (LDA);
               plants; random forests (RF); Artificial intelligence; Decision
               trees; Discriminant analysis; Extraction; Feature extraction;
               Image classification; Learning systems; Matrix algebra; Plants
               (botany); Textures; Features extraction; Gray level co occurrence
               matrix(GLCM); leaves; Linear discriminant analysis; plants;
               Random forests; Classification (of information)",
  doi       = "10.1109/ICCES.2014.7030971",
  isbn      =  9781479965946
}

@INCOLLECTION{Han2005-ui,
  title     = "Borderline-{SMOTE}: A new over-sampling method in imbalanced data
               sets learning",
  author    = "Han, Hui and Wang, Wen-Yuan and Mao, Bing-Huan",
  booktitle = "Lecture Notes in Computer Science",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "878--887",
  abstract  = "In recent years, mining with imbalanced data sets receives more
               and more attentions in both theoretical and practical aspects.
               This paper introduces the importance of imbalanced data sets and
               their broad application domains in data mining, and then
               summarizes the evaluation metrics and the existing methods to
               evaluate and solve the imbalance problem. Synthetic minority
               over-sampling technique (SMOTE) is one of the over-sampling
               methods addressing this problem. Based on SMOTE method, this
               paper presents two new minority over-sampling methods,
               borderline-SMOTE1 and borderline-SMOTE2, in which only the
               minority examples near the borderline are over-sampled. For the
               minority class, experiments show that our approaches achieve
               better TP rate and F-value than SMOTE and random over-sampling
               methods.",
  series    = "Lecture notes in computer science",
  year      =  2005,
  url       = "https://link.springer.com/chapter/10.1007/11538059_91",
  doi       = "10.1007/11538059\_91",
  isbn      = "9783540282266,9783540319023",
  issn      = "1611-3349,0302-9743",
  language  = "en"
}

@INPROCEEDINGS{Wang2008-py,
  title     = "Combination approach of {SMOTE} and biased-{SVM} for imbalanced
               datasets",
  author    = "Wang, He-Yong",
  booktitle = "2008 IEEE International Joint Conference on Neural Networks (IEEE
               World Congress on Computational Intelligence)",
  publisher = "IEEE",
  pages     = "228--231",
  abstract  = "A new approach to construct the classifiers from imbalanced
               datasets is proposed by combining SMOTE (synthetic minority
               over-sampling technique) and Biased-SVM (biased support vector
               machine) approaches. A dataset is imbalanced if the
               classification categories are not approximately equally
               represented. Often real-world data sets are predominately
               composed of ldquonormalrdquo examples with only a small
               percentage of ldquoabnormalrdquo or ldquointerestingrdquo
               examples. The cost of misclassifying an abnormal (interesting)
               example into a normal example is often much higher than that of
               the reverse error. It was known as a means of increasing the
               sensitivity of a classifier to the minority class using SMOTE
               over-sampling in minority class. But in this paper, it gives a
               good means of increasing the sensitivity of a classifier to the
               minority class by using SMOTE approaches within support vectors.
               As for support vector over-sampling, this paper proposes two
               different over-sampling algorithms to deal with the support
               vectors being over-sampled by its neighbors from the k nearest
               neighbors, not only within the support vectors but also within
               the entire minority class. Some experimental results confirms
               that the proposed combination approach of SMOTE and biased-SVM
               can achieve better classifier performance.",
  month     =  jun,
  year      =  2008,
  url       = "https://ieeexplore.ieee.org/document/4633794",
  doi       = "10.1109/ijcnn.2008.4633794",
  isbn      = "9781424418206,9781424418213",
  issn      = "2161-4393,2161-4407",
  language  = "en"
}

@ARTICLE{Zhang2024-br,
  title     = "{SDCINet}: A novel cross-task integration network for
               segmentation and detection of damaged/changed building targets
               with optical remote sensing imagery",
  author    = "Zhang, Haiming and Ma, Guorui and Fan, Hongyang and Gong, Hongyu
               and Wang, Di and Zhang, Yongxian",
  journal   = "ISPRS J. Photogramm. Remote Sens.",
  publisher = "Elsevier BV",
  volume    =  218,
  pages     = "422--446",
  abstract  = "Elsevier’s Scopus, the largest abstract and citation database of
               peer-reviewed literature. Search and access research from the
               science, technology, medicine, social sciences and arts and
               humanities fields.",
  month     =  dec,
  year      =  2024,
  url       = "http://dx.doi.org/10.1016/j.isprsjprs.2024.09.024",
  doi       = "10.1016/j.isprsjprs.2024.09.024",
  issn      = "0924-2716,1872-8235",
  language  = "en"
}

@ARTICLE{Ghazali2022-qj,
  title     = "Drone implementation in precision agriculture – A survey",
  author    = "Ghazali, Mohamad Hazwan Mohd and {School of Electrical and
               Electronic Engineering, Universiti Sains Malaysia Engineering
               Campus, 14300 Nibong Tebal, Penang, Malaysia} and Azmin, Azwati
               and Rahiman, Wan",
  journal   = "International Journal of Emerging Technology and Advanced
               Engineering",
  publisher = "IJETAE Publication House",
  volume    =  12,
  number    =  4,
  pages     = "67--77",
  abstract  = "Abstract— Drones have been widely applied in the precision
               agriculture sector in the past few years. Incorporating
               artificial intelligence (AI), sensors, microcontrollers, and the
               Internet of Things (IoT) into the drones can help overcome the
               challenges faced by the farmers, such as livestock monitoring,
               wide land area, crop spraying, and in-depth crop health analysis.
               In this paper, several drone applications in precision
               agriculture are discussed, including the hardware and techniques
               involved. In addition, commercial agricultural drones available
               in the market to date are presented. The publications trend
               regarding drone application in precision agriculture is also
               included and based on reviewing more than 50 articles, a
               quadcopter-type drone is the most used drone in this sector, and
               seed planting is the least explored drone application area.
               Keywords—camera, crop monitoring, drone, mapping, spraying system",
  month     =  apr,
  year      =  2022,
  url       = "https://www.scopus.com/record/display.uri?eid=2-s2.0-85129130361&origin=resultslist&sort=plf-f&src=s&sid=65f17ce560c243c779ba4fde9caf2eb7&sot=b&sdt=b&s=TITLE%28Drone+Implementation+in+Precision+Agriculture%29&sl=52&sessionSearchId=65f17ce560c243c779ba4fde9caf2eb7&relpos=0",
  doi       = "10.46338/ijetae0422\_10",
  issn      = "2250-2459",
  language  = "en"
}

@ARTICLE{Tomek1976-bg,
  title     = "Two modifications of {CNN}",
  author    = "Tomek, I",
  journal   = "IEEE Trans. Syst. Man Cybern.",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    = "SMC-6",
  number    =  11,
  pages     = "769--772",
  abstract  = "IEEE Xplore, delivering full text access to the world's highest
               quality technical literature in engineering and technology. |
               IEEE Xplore",
  month     =  nov,
  year      =  1976,
  url       = "https://ieeexplore.ieee.org/document/4309452",
  doi       = "10.1109/tsmc.1976.4309452",
  issn      = "0018-9472,2168-2909",
  language  = "en"
}

@ARTICLE{Batista2004-qz,
  title     = "A study of the behavior of several methods for balancing machine
               learning training data",
  author    = "Batista, Gustavo E A P A and Prati, Ronaldo C and Monard, Maria
               Carolina",
  journal   = "SIGKDD Explor.",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  6,
  number    =  1,
  pages     = "20--29",
  abstract  = "There are several aspects that might influence the performance
               achieved by existing learning systems. It has been reported that
               one of these aspects is related to class imbalance in which
               examples in training data belonging to one class heavily
               outnumber the examples in the other class. In this situation,
               which is found in real world data describing an infrequent but
               important event, the learning system may have difficulties to
               learn the concept related to the minority class. In this work we
               perform a broad experimental evaluation involving ten methods,
               three of them proposed by the authors, to deal with the class
               imbalance problem in thirteen UCI data sets. Our experiments
               provide evidence that class imbalance does not systematically
               hinder the performance of learning systems. In fact, the problem
               seems to be related to learning with too few minority class
               examples in the presence of other complicating factors, such as
               class overlapping. Two of our proposed methods deal with these
               conditions directly, allying a known over-sampling method with
               data cleaning methods in order to produce better-defined class
               clusters. Our comparative experiments show that, in general,
               over-sampling methods provide more accurate results than
               under-sampling methods considering the area under the ROC curve
               (AUC). This result seems to contradict results previously
               published in the literature. Two of our proposed methods, Smote +
               Tomek and Smote + ENN, presented very good results for data sets
               with a small number of positive examples. Moreover, Random
               over-sampling, a very simple over-sampling method, is very
               competitive to more complex over-sampling methods. Since the
               over-sampling methods provided very good performance results, we
               also measured the syntactic complexity of the decision trees
               induced from over-sampled data. Our results show that these trees
               are usually more complex then the ones induced from original
               data. Random over-sampling usually produced the smallest increase
               in the mean number of induced rules and Smote + ENN the smallest
               increase in the mean number of conditions per rule, when compared
               among the investigated over-sampling methods.",
  month     =  jun,
  year      =  2004,
  url       = "https://www.researchgate.net/publication/220520041_A_Study_of_the_Behavior_of_Several_Methods_for_Balancing_machine_Learning_Training_Data",
  doi       = "10.1145/1007730.1007735",
  issn      = "1931-0145,1931-0153",
  language  = "en"
}

@INCOLLECTION{Bankman2009-wq,
  title     = "Two-dimensional shape and texture quantification",
  author    = "Bankman, I",
  booktitle = "Handbook of Medical Image Processing and Analysis",
  publisher = "Elsevier",
  pages     = "261--277",
  month     =  jan,
  year      =  2009,
  url       = "http://dx.doi.org/10.1016/B978-012373904-9.50024-6",
  doi       = "10.1016/b978-012373904-9.50024-6",
  isbn      =  9780123739049
}
