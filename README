Weed/Crop Classification
------------------------
This project concerns the classification of blobs in images as either crop or a weed.

This project requires
Python 3.7.9
Cygwin base + make

Python requirements are given in requirements.txt, but really just come down to a few things
numpy
pandas
opencv
scikit-learn
pyqt5

All interactions are with make, which makes calls to the cygpath program as the only known dependancy on cygwin.
As this can be ported to Ubuntu, this is not a requirement that is difficult to overcome.

The examples here are for the cygwin shell, but there is no dependancy on the shell, and equivalents for ubuntu or powershell should execute as well.

Directories
-----------
drwxrwxr-x+ 1 None      0 May  7  2024  435

Code for the Intel D435 Depth sensor.  Can be ignored for this project.

drwxrwxr-x+ 1 None      0 Sep 13  2024  altitude

Find the blob closest to the disk in the image. Can be ignored for this project

drwxrwxr-x+ 1 None      0 Apr  4  2023  calibration

Code for Basler camera calibration. Can be ignored for this project

drwxrwxr-x+ 1 None      0 Apr  4  2023  composed-with-weeds

Test images where various weeds are inserted.

drwxrwxr-x+ 1 None      0 May 20  2024  comprehensive

Test programs for C++. Can be ignored for this project

drwxrwxr-x+ 1 None      0 Aug 13  2023  deploy
drwxrwxr-x+ 1 None      0 Jul 18  2023  docker

Docker definitions. Can be ignored for this project

drwxrwxr-x+ 1 None      0 Jul  5 12:41  documents

Latex dissertation & PDFs for research

drwxrwxr-x+ 1 None      0 Jun 16  2023  gabor

Gabor filters

drwxrwxr-x+ 1 None      0 Jul 30  2023  hpcc

Slurm definitions for UA Supercomputer

drwxrwxr-x+ 1 None      0 Dec  5  2022  idea

Project files for PyCharms IDE

drwxrwxr-x+ 1 None      0 Jul  4 16:49  jetson

Image processing -- this is the main directory for all code

drwxrwxr-x+ 1 None      0 Jun 27 15:25  lib

Various libraries for the project.  Most .py files have a main defined for testing purposes

For instance:
python VegetationIndex.py --help
usage: Show various vegetation indices [-h] [-e {jpg,png}] -i INPUT -o OUTPUT
                                       -m MASKS [-nm]
                                       [-n [{ndi,tgi,ngrdi,exgexr,exg,exr,cive,veg,com1,mexg,com2,tgi,r
gd,si,di,ycbcri,hv,all} [{ndi,tgi,ngrdi,exgexr,exg,exr,cive,veg,com1,mexg,com2,tgi,rgd,si,di,ycbcri,hv,
all} ...]]]
                                       [-p] [-r] [-s] [-t THRESHOLD] [-c CSV]

optional arguments:
  -h, --help            show this help message and exit
  -e {jpg,png}, --encoding {jpg,png}
                        Image encoding for output
  -i INPUT, --input INPUT
                        Image or directory to process
  -o OUTPUT, --output OUTPUT
                        Output directory for processed images
  -m MASKS, --masks MASKS
                        Output directory for masks
  -nm, --no-mask        Don't output mask
  -n [{ndi,tgi,ngrdi,exgexr,exg,exr,cive,veg,com1,mexg,com2,tgi,rgd,si,di,ycbcri,hv,all} [{ndi,tgi,ngrd
i,exgexr,exg,exr,cive,veg,com1,mexg,com2,tgi,rgd,si,di,ycbcri,hv,all} ...]], --name [{ndi,tgi,ngrdi,exg
exr,exg,exr,cive,veg,com1,mexg,com2,tgi,rgd,si,di,ycbcri,hv,all} [{ndi,tgi,ngrdi,exgexr,exg,exr,cive,ve
g,com1,mexg,com2,tgi,rgd,si,di,ycbcri,hv,all} ...]]
                        Index name or all
  -p, --plot            Plot the index
  -r, --refine          Refine the mask before application
  -s, --show            Show intermediate images
  -t THRESHOLD, --threshold THRESHOLD
                        Calculate thresholds
  -c CSV, --csv CSV     Performance CSV

drwxrwxr-x+ 1 None      0 Dec  2  2022  licenses

License definition for various libraries used in this project

drwxrwxr-x+ 1 None      0 Jul  5 14:00  post

Post processing utilities

drwxrwxr-x+ 1 None      0 Dec 25  2024  pre

Pre processing utilities

drwxrwxr-x+ 1 None      0 Jun 24 11:55  presentations

Presentations for this project

drwxrwxr-x+ 1 None      0 Aug  8  2023  rio

Code for National Instruments RIO -- Can be ignored

drwxrwxr-x+ 1 None      0 Dec 29  2024  sam

Segment anything -- not directly used in this project

drwxrwxr-x+ 1 None      0 Apr  4  2023  samples

Examples for using Zero-MQ -- not used for this project

drwxrwxr-x+ 1 None      0 Nov 30  2024  test-images

Test images

drwxrwxr-x+ 1 None      0 May  5  2023  tests

Test scripts

drwxrwxr-x+ 1 None      0 Dec 31  2024  u-net

U-Net code for segmentation

drwxrwxr-x+ 1 None      0 Apr 13 16:01  util

Various utilities

Images and Preprocessing
------------------------
The images of crop and weeds are held in these repos:

These images are in a RAW format, and must be converted to JPG before processing. Adobe Ligthroom was used for this task, but is not a requirement.

Correcting the color of the images is a task best executed by something like Adobe Lightroom, although using that package is not a requirement, it is what was used.  A photo of the color correction chart for each image set is included as the first image.

Preparing the training data
---------------------------
Each of the images of the training data must be classified by a human to create a usable training set.

The first step is to processes the images to extract the features and produce an initial guess as to what the blobs are.
The guess will (probably) be wrong, of course, but that is of no concern here.

Process the image initally with the weeds.py command in the jetson directory

In the directory post, use the review.py command.

$ python review.py --help
usage: Image Reviewer [-h] [-i INPUT] [-p PATTERN] [-o OUTPUT] [-a ATTRIBUTES]
                      [-t] [-l LOGGING]

optional arguments:
  -h, --help            show this help message and exit
  -i INPUT, --input INPUT
                        Input directory
  -p PATTERN, --pattern PATTERN
                        Pattern, i.e., processed-*.jpg
  -o OUTPUT, --output OUTPUT
                        Output CSV
  -a ATTRIBUTES, --attributes ATTRIBUTES
                        Classification CSV
  -t, --type            Correct the type and don't write actual column
  -l LOGGING, --logging LOGGING
                        Logging configuration

For example:
python review.py -i /cygdrive/d/maricopa/corrected/2024-05-01/drip-iphone/processed/final/ -p processed-\*jpg -o /cygdrive/c/tmp/2024-05-01.csv -a /cygdrive/d/maricopa/corrected/2024-05-01/drip-iphone/processed/final/corrected.csv

This will present the images and classifications, allowing the user to assign the correct class.

The output file (here, 2024-05-01.csv) is the training data for that one image set.

This process must be repeated for each image set and all image sets must be combined into one training/testing set.

The utility combine.py will perform this combining in the format required by other steps (a single header row)

 python combine.py --help
usage: Combine CSVs [-h] -i [INPUT [INPUT ...]] -o OUTPUT [-f]

optional arguments:
  -h, --help            show this help message and exit
  -i [INPUT [INPUT ...]], --input [INPUT [INPUT ...]]
                        Input CSV
  -o OUTPUT, --output OUTPUT
                        Output CSV
  -f, --force           Force overwrite of output file


Processing the images
----------------------

Producing the data
------------------
To produce the data that can subsequently be interpreted, use the Selection.py script.  For example, this command will produce the results considering all textural attributes.

python Selection.py -df `cygpath -w /cygdrive/d/dissertation/cantaloupe/season.csv` -fs ALL -f 4 -l -lg standalone-logging.ini -p cantaloupe_texture -o -ty TEXTURE -s all -od `cygpath -w /cygdrive/c/tmp/dissertation/data`

This will search for the optimal set of parameters for a given type and subtype and produce a pickle file that can then be used to produce a results table or plot. The types/subtypes are TEXTURE/[all|GLCM|LBP] or SHAPE/all or COLOR/all or all/all.



Producing the results
---------------------
The results come in two forms: tables and plots.  Tables are just a summary of various scores for each of the techniques, but the plots are focused on ROC curves for the tecniques.

For example, this will produce a tex table if only GLCM is considered, and includes columns for auc, f1, precision, and recall

python results.py --prefix  cantaloupe_glcm_auc -c `cygpath -w parameters.pickle` -o latex --type TEXTURE --subtype GLCM -lg tucson-logging.ini --directory `cygpath -w /cygdrive/c/tmp/dissertation/data/` --long "Classification using GLCM "  --short "Classification using GLCM " --label table:glcm-summary --table  --output `cygpath -w /cygdrive/c/tmp/dissertation/tables/generated-results-glcm.tex`  --include auc f1 precision recall


$ python results.py --help
usage: Results file operation [-h] -c COMPUTED
                              [-cr {ACCURACY,AUC,PRECISION,RECALL,F1,MAP,all}]
                              [-cl LONG] [-cs SHORT] [-te {binary,occ,all}]
                              [-df DATA] [-f] [-l LABEL] [-lg LOGGING] [-n N]
                              [-fo {latex,text,csv}] -od DIRECTORY
                              [-i [{parameters,auc,f1,precision,recall,map} [{parameters,auc,f1,precisi
on,recall,map} ...]]]
                              [-p PREFIX | -r RESULTS] [-su]
                              [-si SIMILARITY | -ct | -roc | -rt | -table | -pc]
                              [-se] [-so SOURCE] [-co] [-t TARGET]
                              [-th THRESHOLD] [-graph GRAPH] [-o OUTPUT]
                              [-s [{NONE,LBP,GLCM,HOG,all} [{NONE,LBP,GLCM,HOG,all} ...]]]
                              [-ty [{COLOR,SHAPE,TEXTURE,POSITION,all} [{COLOR,SHAPE,TEXTURE,POSITION,a
ll} ...]]]

optional arguments:
  -h, --help            show this help message and exit
  -c COMPUTED, --computed COMPUTED
                        Pickle format file with computed parameters
  -cr {ACCURACY,AUC,PRECISION,RECALL,F1,MAP,all}, --criteria {ACCURACY,AUC,PRECISION,RECALL,F1,MAP,all}
                        Criteria to determine maximum
  -cl LONG, --long LONG
                        (latex) Table long caption
  -cs SHORT, --short SHORT
                        (latex) Table short caption
  -te {binary,occ,all}, --technique {binary,occ,all}
                        Classification Approach
  -df DATA, --data DATA
                        Name of the data in CSV format (required for --roc
  -f, --factors         Show only the factors
  -l LABEL, --label LABEL
                        (latex) Label for generated table
  -lg LOGGING, --logging LOGGING
                        logging configuration
  -n N, --n N           Number of combinations
  -fo {latex,text,csv}, --format {latex,text,csv}
                        Output format
  -od DIRECTORY, --directory DIRECTORY
                        Results file directory
  -i [{parameters,auc,f1,precision,recall,map} [{parameters,auc,f1,precision,recall,map} ...]], --inclu
de [{parameters,auc,f1,precision,recall,map} [{parameters,auc,f1,precision,recall,map} ...]]
                        Include in table
  -p PREFIX, --prefix PREFIX
                        File prefix
  -r RESULTS, --results RESULTS
                        Pickle file for technique
  -su, --summary        Show a summary of the results
  -si SIMILARITY, --similarity SIMILARITY
                        Show items where similarity matches
  -ct, --close          Show count of results close to maximum
  -roc, --roc           Show ROC curves
  -rt, --roc-thresholds
                        Produce table of thresholds based on ROC curves
  -table, --table       Generate results table
  -pc, --parameter-counts
                        Generate parameter counts table
  -se, --seasonality    Show seasonality instead of attribute names
  -so SOURCE, --source SOURCE
                        The original data for these results
  -co, --compare        Compare results to specified set
  -t TARGET, --target TARGET
                        Compare results to this file (required if --compare is
  -th THRESHOLD, --threshold THRESHOLD
                        Threshold for --close option
  -graph GRAPH, --graph GRAPH
                        Output file for graph
  -o OUTPUT, --output OUTPUT
                        Output file for table
  -s [{NONE,LBP,GLCM,HOG,all} [{NONE,LBP,GLCM,HOG,all} ...]], --subtypes [{NONE,LBP,GLCM,HOG,all} [{NON
E,LBP,GLCM,HOG,all} ...]]
                        Attribute types used
  -ty [{COLOR,SHAPE,TEXTURE,POSITION,all} [{COLOR,SHAPE,TEXTURE,POSITION,all} ...]], --types [{COLOR,SH
APE,TEXTURE,POSITION,all} [{COLOR,SHAPE,TEXTURE,POSITION,all} ...]]
                        Attribute types used



